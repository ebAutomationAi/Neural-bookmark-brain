================================================================================
üîí AUDIT CONTEXT - BOOKMARKS SYSTEM (DATOS SENSIBLES ENMASCARADOS)
================================================================================

‚ö†Ô∏è  ADVERTENCIA DE SEGURIDAD:
   Todos los datos sensibles (API keys, passwords, tokens, etc.)
   han sido autom√°ticamente enmascarados con 'xxxxxxxxxx'
   para proteger la informaci√≥n confidencial del proyecto.

## üìã RESUMEN EJECUTIVO

**Tipo de Proyecto:** Sistema de Bookmarks con Scraping y API
**Tecnolog√≠as Principales:**
- Backend: FastAPI, Python 3.12
- Base de Datos: PostgreSQL (asyncpg, SQLAlchemy)
- Scraping: Trafilatura, Courlan, Fake UserAgent
- ML/AI: Transformers, Torch, Scikit-learn
- Frontend: React, TypeScript, Vite
- Testing: Pytest, Pytest-asyncio
- Validaci√≥n: Pydantic v2

## üìÇ ESTRUCTURA DE DIRECTORIOS

```
ARCHITECTURE.md
AUDITORIA_TECNICA.md
Dockerfile
INDEX.md
LICENSE
Makefile
QUICKSTART.md
README.md
app/
bookmarks.csv
bookmarks_old.csv
contexto_auditoria_wsl.txt
data/
doc_txt/
docker-compose.yml
docs/
env.example
estado-proyecto.txt
filtrar_csv.py
neural-bookmark-ui/
path/
procesamiento_20260209_231453.log
progress_log.md
prototype.html
pytest.ini
recopila_codigos_wsl.py
requirements.txt
scripts/
sprint1/
tests/
tree.txt
```

## üìñ TABLA DE CONTENIDOS

1. `.env.example`
2. `.github/dependabot.yml`
3. `.github/workflow/security_audit.yml`
4. `app/__init__.py`
5. `app/agents.py`
6. `app/config.py`
7. `app/database.py`
8. `app/main.py`
9. `app/models.py`
10. `app/schemas.py`
11. `app/services/__init__.py`
12. `app/services/classifier.py`
13. `app/services/embeddings.py`
14. `app/services/scraper.py`
15. `app/services/url_cleaner.py`
16. `app/utils/__init__.py`
17. `app/utils/validators.py`
18. `docker-compose.yml`
19. `filtrar_csv.py`
20. `neural-bookmark-ui/.env.example`
21. `neural-bookmark-ui/eslint.config.js`
22. `neural-bookmark-ui/index.html`
23. `neural-bookmark-ui/package.json`
24. `neural-bookmark-ui/playwright.config.ts`
25. `neural-bookmark-ui/postcss.config.js`
26. `neural-bookmark-ui/src/App.css`
27. `neural-bookmark-ui/src/App.tsx`
28. `neural-bookmark-ui/src/components/bookmarks/BookmarkActions.tsx`
29. `neural-bookmark-ui/src/components/bookmarks/BookmarkCard.tsx`
30. `neural-bookmark-ui/src/components/bookmarks/BookmarkGrid.tsx`
31. `neural-bookmark-ui/src/components/layout/Header.tsx`
32. `neural-bookmark-ui/src/components/layout/Layout.tsx`
33. `neural-bookmark-ui/src/components/layout/Sidebar.tsx`
34. `neural-bookmark-ui/src/components/modals/AddBookmarkModal.tsx`
35. `neural-bookmark-ui/src/components/search/SearchBar.tsx`
36. `neural-bookmark-ui/src/components/stats/ProcessingProgress.tsx`
37. `neural-bookmark-ui/src/components/stats/StatCard.tsx`
38. `neural-bookmark-ui/src/components/ui/Badge.tsx`
39. `neural-bookmark-ui/src/components/ui/Button.tsx`
40. `neural-bookmark-ui/src/components/ui/Input.tsx`
41. `neural-bookmark-ui/src/components/ui/Toast.tsx`
42. `neural-bookmark-ui/src/hooks/useBookmarks.ts`
43. `neural-bookmark-ui/src/hooks/useToast.ts`
44. `neural-bookmark-ui/src/index.css`
45. `neural-bookmark-ui/src/main.tsx`
46. `neural-bookmark-ui/src/pages/Bookmarks.tsx`
47. `neural-bookmark-ui/src/pages/Dashboard.tsx`
48. `neural-bookmark-ui/src/pages/Search.tsx`
49. `neural-bookmark-ui/src/pages/Statistics.tsx`
50. `neural-bookmark-ui/src/services/api.ts`
51. `neural-bookmark-ui/src/types/index.ts`
52. `neural-bookmark-ui/src/utils/formatters.ts`
53. `neural-bookmark-ui/tailwind.config.js`
54. `neural-bookmark-ui/test-results.json`
55. `neural-bookmark-ui/tests/e2e/full-flow.spec.ts`
56. `neural-bookmark-ui/tests/setup.ts`
57. `neural-bookmark-ui/tests/ui/bookmarks-api.spec.ts`
58. `neural-bookmark-ui/tests/ui/bookmarks.spec.ts`
59. `neural-bookmark-ui/tests/ui/comprehensive-ui.spec.ts`
60. `neural-bookmark-ui/tests/ui/home.spec.ts`
61. `neural-bookmark-ui/tests/ui/navigation.spec.ts`
62. `neural-bookmark-ui/tests/ui/search.spec.ts`
63. `neural-bookmark-ui/tsconfig.app.json`
64. `neural-bookmark-ui/tsconfig.json`
65. `neural-bookmark-ui/tsconfig.node.json`
66. `neural-bookmark-ui/vite.config.ts`
67. `prototype.html`
68. `pytest.ini`
69. `requirements.txt`
70. `scripts/__init__.py`
71. `scripts/analyze_tracking.py`
72. `scripts/check_env.py`
73. `scripts/check_security.py`
74. `scripts/check_url_clean.py`
75. `scripts/example_api_usage.py`
76. `scripts/import_csv.py`
77. `scripts/init_db.py`
78. `scripts/init_db.sql`
79. `scripts/quick_stats.py`
80. `scripts/reprocess_failed.py`
81. `scripts/stats.py`
82. `scripts/test_scraper_limits.py`
83. `scripts/verify_installation.py`
84. `scripts/verify_pipeline.py`
85. `scripts/verify_urls.py`
86. `sprint1/agents_resilient.py`
87. `sprint1/migration_001_add_resilience_fields.sql`
88. `sprint1/models_updated.py`
89. `sprint1/scraper_resilient.py`
90. `sprint1/test_sprint1_resilient.py`
91. `tests/__init__.py`
92. `tests/conftest.py`
93. `tests/e2e/__init__.py`
94. `tests/e2e/test_import_flow.py`
95. `tests/integration/__init__.py`
96. `tests/integration/test_agents.py`
97. `tests/integration/test_api.py`
98. `tests/integration/test_database.py`
99. `tests/test_rate_limiting.py`
100. `tests/test_rate_limiting_api.py`
101. `tests/unit/__init__.py`
102. `tests/unit/test_classifier.py`
103. `tests/unit/test_embeddings.py`
104. `tests/unit/test_scraper.py`
105. `tests/unit/test_validators.py`

**Total de archivos:** 105

================================================================================


================================================================================
üìÑ ARCHIVO: .env.example
üìè Tama√±o: 0.9 KB
‚ö†Ô∏è  DATOS SENSIBLES ENMASCARADOS:
  ‚ö†Ô∏è  Encontrado 1 coincidencia(s) de tipo: (?i)(api
  ‚ö†Ô∏è  Encontrado 1 coincidencia(s) de tipo: (?i)(password|passwd|pwd)
  ‚ö†Ô∏è  Encontrado 1 coincidencia(s) de tipo: (?i)(database
  ‚ö†Ô∏è  Encontrado 1 coincidencia(s) de tipo: (?i)^(
================================================================================

# Database Configuration (obligatorio: sin DATABASE_URL la app no arranca)
DATABASE_URL: "postgresql+asyncpg://bookmark_user:xxxxxxxxxx@localhost:5432/neural_bookmarks

# Docker Compose: usuario y contrase√±a de PostgreSQL (definir en .env)
POSTGRES_USER=bookmark_user
POSTGRES_PASSWORD: "xxxxxxxxxx"
POSTGRES_DB=neural_bookmarks

# CORS: or√≠genes permitidos separados por coma; * = todos (solo desarrollo)
CORS_ORIGINS=*

# AI Configuration
GROQ_API_KEY: "xxxxxxxxxx"
GROQ_MODEL=llama-3.1-70b-versatile

# Embedding Configuration
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Application Settings
ENVIRONMENT=development
LOG_LEVEL=INFO
MAX_CONCURRENT_REQUESTS=10

# Scraping Configuration
SCRAPER_TIMEOUT=30
SCRAPER_MAX_RETRIES=3
SCRAPER_DELAY_BETWEEN_REQUESTS=1.0
SCRAPER_MAX_REDIRECTS=5
SCRAPER_USER_AGENT=Mozilla/5.0 (compatible; NeuralBookmarkBot/1.0)

# Safety Configuration
NSFW_KEYWORDS=xxxxxxxxxx


================================================================================
üìÑ ARCHIVO: .github/dependabot.yml
üìè Tama√±o: 0.3 KB
================================================================================


updates:
  # Analiza las dependencias de Python (requirements.txt)
  - package-ecosystem: "pip"
    directory: "/"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 5

  # Analiza la imagen base en el Dockerfile
  - package-ecosystem: "docker"
    directory: "/"
    schedule:
      interval: "weekly"


================================================================================
üìÑ ARCHIVO: .github/workflow/security_audit.yml
üìè Tama√±o: 0.7 KB
================================================================================

name: Security Audit

on:
  push:
    branches: [ "main", "develop" ]
  pull_request:
    branches: [ "main", "develop" ]

jobs:
  dependency-audit:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout del c√≥digo
        uses: actions/checkout@v4
      
      - name: Configurar Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Instalar herramientas de seguridad
        run: |
          python -m pip install --upgrade pip
          pip install safety pip-audit
          
      - name: Auditar dependencias con Safety
        run: safety check -r requirements.txt --full-report
        
      - name: Auditar dependencias con pip-audit
        run: pip-audit -r requirements.txt


================================================================================
üìÑ ARCHIVO: app/__init__.py
üìè Tama√±o: 0.1 KB
================================================================================

"""
Neural Bookmark Brain - AI-Powered Semantic Knowledge Base
"""

__version__ = "1.0.0"
__author__ = "Neural Bookmark Team"



================================================================================
üìÑ ARCHIVO: app/agents.py
üìè Tama√±o: 26.0 KB
================================================================================

# app/agents.py - VERSI√ìN CON RESILIENCIA Y ESTADOS PARCIALES

from groq import AsyncGroq
from typing import Dict, List, Optional, Tuple
from loguru import logger
import json
import re
from datetime import datetime
from urllib.parse import urlparse
import tldextract

from app.config import get_settings
from app.services.scraper import scraper
from app.services.classifier import classifier
from app.services.embeddings import get_embedding_service

settings = get_settings()


class ArchivistAgent:
    """
    Agente 1: El Archivista (The Gatekeeper) - VERSI√ìN RESILIENTE
    
    Responsabilidades:
    - Validar URLs
    - Scraping resiliente con m√∫ltiples estrategias
    - Clasificaci√≥n de seguridad (NSFW)
    - Limpieza de t√≠tulos gen√©ricos
    - Detecci√≥n de URLs locales
    - Clasificaci√≥n de errores
    """
    
    def __init__(self):
        self.name = "Archivist"
        try:
            if not settings.GROQ_API_KEY:
                raise ValueError("GROQ_API_KEY no est√° configurada")
            self.groq_client = AsyncGroq(api_key=settings.GROQ_API_KEY)
        except Exception as e:
            print(f"Error inicializando cliente Groq: {e}")
            logger.error(f"Error inicializando cliente Groq: {e}")
            raise
        self.embedding_service = get_embedding_service()
    
    async def process(self, url: str, original_title: str) -> Dict:
        """
        Procesa un bookmark a trav√©s del Agente Archivista
        
        Returns:
            Dict con: clean_title, full_text, is_nsfw, scraping_status, error_type, etc.
        """
        logger.info(f"[{self.name}] Procesando: {url}")
        
        result = {
            "success": False,
            "clean_title": original_title,
            "full_text": None,
            "is_nsfw": False,
            "nsfw_reason": None,
            "is_local": False,
            "domain": None,
            "language": None,
            "word_count": 0,
            "error": None,
            # Nuevos campos de resiliencia
            "scraping_status": "pending",
            "scraping_strategy": None,
            "scraping_error_type": None,
            "scraping_attempts": 0,
        }
        
        try:
            # 1. Scraping del contenido con estrategias resilientes
            scraped = await scraper.scrape_url(url)
            
            result["domain"] = scraped.get("domain")
            result["language"] = scraped.get("language")
            result["word_count"] = scraped.get("word_count", 0)
            result["scraping_strategy"] = scraped.get("strategy")
            result["scraping_error_type"] = scraped.get("error_type")
            result["scraping_attempts"] = scraped.get("attempts", 0)
            
            # Si es URL local
            if scraped.get("error_type") == "local_url":
                result["is_local"] = True
                result["scraping_status"] = "skipped"
                result["error"] = scraped["error_message"]
                logger.warning(f"[{self.name}] URL local detectada: {url}")
                return result
            
            # Si scraping fue exitoso
            if scraped["success"]:
                result["scraping_status"] = "success"
                result["full_text"] = scraped.get("text", "")
                
                # 2. Obtener t√≠tulo limpio
                scraped_title = scraped.get("title", original_title)
                clean_title = scraper.extract_clean_title(
                    scraped_title or original_title,
                    result["domain"]
                )
                result["clean_title"] = clean_title
                
                # 3. Clasificaci√≥n de seguridad (NSFW)
                is_nsfw, nsfw_reason = classifier.classify(
                    url=url,
                    title=clean_title,
                    text=result["full_text"]
                )
                
                result["is_nsfw"] = is_nsfw
                result["nsfw_reason"] = nsfw_reason
                
                if is_nsfw:
                    logger.warning(
                        f"[{self.name}] Contenido NSFW detectado: {url} "
                        f"(Raz√≥n: {nsfw_reason})"
                    )
                
                # 4. Si el t√≠tulo sigue siendo gen√©rico, mejorar con AI
                if self._is_generic_title(clean_title) and result["full_text"]:
                    logger.info(f"[{self.name}] Mejorando t√≠tulo gen√©rico con AI")
                    enhanced_title = await self._enhance_title_with_ai(
                        clean_title, result["full_text"][:1000]
                    )
                    if enhanced_title:
                        result["clean_title"] = enhanced_title
                
                result["success"] = True
                logger.info(
                    f"[{self.name}] ‚úÖ Procesamiento exitoso: {url} "
                    f"({result['word_count']} palabras, estrategia: {result['scraping_strategy']})"
                )
            
            else:
                # Scraping fall√≥ pero tenemos metadata de error
                result["scraping_status"] = "failed"
                result["error"] = scraped.get("error_message", "Error desconocido en scraping")
                
                logger.warning(
                    f"[{self.name}] ‚ö†Ô∏è Scraping fallido: {url} "
                    f"(Tipo: {result['scraping_error_type']}, Intentos: {result['scraping_attempts']})"
                )
                
                # A√∫n as√≠ intentamos limpiar el t√≠tulo original
                result["clean_title"] = scraper.extract_clean_title(
                    original_title,
                    result["domain"]
                )
        
        except Exception as e:
            result["error"] = str(e)
            result["scraping_status"] = "failed"
            result["scraping_error_type"] = "unexpected_error"
            logger.error(f"[{self.name}] Error procesando {url}: {e}")
        
        return result
    
    def _is_generic_title(self, title: str) -> bool:
        """Verifica si el t√≠tulo sigue siendo gen√©rico"""
        generic_patterns = [
            r"p√°gina principal",
            r"main page",
            r"home",
            r"index",
            r"welcome",
            r"^[a-z0-9\-]+\.(com|net|org)",  # Solo dominio
        ]
        
        title_lower = title.lower()
        
        for pattern in generic_patterns:
            if re.search(pattern, title_lower):
                return True
        
        return False
    
    async def _enhance_title_with_ai(
        self,
        original_title: str,
        text_sample: str
    ) -> Optional[str]:
        """Mejora el t√≠tulo usando AI si es gen√©rico"""
        try:
            prompt = f"""Analiza el siguiente contenido web y genera un t√≠tulo descriptivo y conciso (m√°ximo 60 caracteres).

T√≠tulo original: {original_title}

Contenido:
{text_sample}

Responde SOLO con el nuevo t√≠tulo, nada m√°s."""

            response = await self.groq_client.chat.completions.create(
                model=settings.GROQ_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=getattr(settings, 'GROQ_TEMPERATURE', 0.3),
                max_tokens=100,
            )
            
            enhanced_title = response.choices[0].message.content.strip()
            
            # Validar que no sea muy largo
            if len(enhanced_title) > 100:
                enhanced_title = enhanced_title[:97] + "..."
            
            logger.info(f"[{self.name}] T√≠tulo mejorado: {enhanced_title}")
            return enhanced_title
        
        except Exception as e:
            print(f"Error mejorando t√≠tulo con AI: {e}")
            logger.error(f"[{self.name}] Error mejorando t√≠tulo con AI: {e}")
            return None


class CuratorAgent:
    """
    Agente 2: El Curador (The Librarian) - VERSI√ìN CON MODO FALLBACK
    
    Responsabilidades:
    - Generar resumen (3 oraciones)
    - Crear tags tem√°ticos
    - Asignar categor√≠a
    - Generar embeddings sem√°nticos
    - NUEVO: Modo fallback para URLs sin contenido
    """
    
    def __init__(self):
        self.name = "Curator"
        try:
            if not settings.GROQ_API_KEY:
                raise ValueError("GROQ_API_KEY no est√° configurada")
            self.groq_client = AsyncGroq(api_key=settings.GROQ_API_KEY)
        except Exception as e:
            print(f"Error inicializando cliente Groq: {e}")
            logger.error(f"Error inicializando cliente Groq: {e}")
            raise
        self.embedding_service = get_embedding_service()
    
    async def process(
        self,
        clean_title: str,
        full_text: Optional[str],
        url: str
    ) -> Dict:
        """
        Procesa contenido a trav√©s del Agente Curador
        AUTOM√ÅTICAMENTE decide entre modo full_text o url_only
        
        Returns:
            Dict con: summary, tags, category, embedding, curation_mode, confidence
        """
        logger.info(f"[{self.name}] Curando contenido de: {url}")
        
        result = {
            "success": False,
            "summary": None,
            "tags": [],
            "category": None,
            "embedding": None,
            "error": None,
            "curation_status": "pending",
            "curation_mode": None,
            "confidence": 0.0,
        }
        
        try:
            # Decidir modo basado en disponibilidad de texto
            if full_text and len(full_text.strip()) >= 50:
                # MODO NORMAL: Texto completo disponible
                logger.info(f"[{self.name}] Modo: full_text ({len(full_text)} chars)")
                ai_result = await self._process_full_text(clean_title, full_text, url)
                result["curation_mode"] = "full_text"
                result["confidence"] = 1.0  # Alta confianza
            else:
                # MODO FALLBACK: Solo URL + t√≠tulo
                logger.warning(f"[{self.name}] Modo: url_only (texto insuficiente)")
                ai_result = await self._process_url_only(clean_title, url)
                result["curation_mode"] = "url_only"
                result["confidence"] = ai_result.get("confidence", 0.5)
            
            if ai_result and ai_result.get("success"):
                result["summary"] = ai_result.get("summary")
                result["tags"] = ai_result.get("tags", [])
                result["category"] = ai_result.get("category")
                
                # Generar embedding
                text_for_embedding = f"{clean_title}. {result['summary']}"
                embedding = self.embedding_service.generate_embedding(text_for_embedding)
                result["embedding"] = embedding
                
                result["success"] = True
                result["curation_status"] = "success" if result["curation_mode"] == "full_text" else "fallback"
                
                logger.info(
                    f"[{self.name}] ‚úÖ Curaci√≥n exitosa: {url} "
                    f"(Modo: {result['curation_mode']}, Categor√≠a: {result['category']}, "
                    f"Confidence: {result['confidence']:.2f})"
                )
            else:
                result["error"] = ai_result.get("error", "Error en an√°lisis AI")
                result["curation_status"] = "failed"
                logger.error(f"[{self.name}] Error en an√°lisis AI: {url}")
        
        except Exception as e:
            result["error"] = str(e)
            result["curation_status"] = "failed"
            logger.error(f"[{self.name}] Error curando {url}: {e}")
        
        return result
    
    async def _process_full_text(
        self,
        title: str,
        text: str,
        url: str
    ) -> Optional[Dict]:
        """Modo normal: an√°lisis con texto completo"""
        try:
            # Truncar texto para no exceder l√≠mites
            text_truncated = text[:3000]
            
            prompt = f"""Analiza el siguiente contenido web y genera metadata estructurada.

T√≠tulo: {title}

Contenido:
{text_truncated}

Responde en formato JSON con esta estructura exacta:
{{
  "summary": "Resumen de exactamente 3 oraciones que capture la esencia del contenido",
  "tags": ["tag1", "tag2", "tag3", "tag4", "tag5"],
  "category": "una categor√≠a principal"
}}

Categor√≠as v√°lidas: Tecnolog√≠a, Negocios, Educaci√≥n, Entretenimiento, Salud, Ciencia, Arte, Deportes, Noticias, Programaci√≥n, Dise√±o, Marketing, Finanzas, Productividad, Transporte, Otros

Tags: Genera 5-7 tags relevantes, espec√≠ficos y descriptivos.

Responde SOLO con el JSON, sin explicaciones adicionales."""

            response = await self.groq_client.chat.completions.create(
                model=settings.GROQ_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=getattr(settings, 'GROQ_TEMPERATURE', 0.3),
                max_tokens=getattr(settings, 'GROQ_MAX_TOKENS', 2048),
            )
            
            content = response.choices[0].message.content.strip()
            
            # Extraer JSON del contenido
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                analysis = json.loads(json_str)
                
                # Validar estructura
                if all(key in analysis for key in ["summary", "tags", "category"]):
                    # Limpiar tags (lowercase, sin duplicados)
                    analysis["tags"] = list(set(
                        tag.lower().strip() for tag in analysis["tags"]
                    ))
                    
                    analysis["success"] = True
                    logger.info(f"[{self.name}] An√°lisis AI completado (full_text)")
                    return analysis
            
            logger.error(f"[{self.name}] JSON inv√°lido en respuesta AI")
            return {"success": False, "error": "JSON inv√°lido"}
        
        except json.JSONDecodeError as e:
            print(f"Error parseando JSON de AI: {e}")
            logger.error(f"[{self.name}] Error parseando JSON: {e}")
            return {"success": False, "error": f"JSON parse error: {e}"}
        
        except Exception as e:
            print(f"Error en an√°lisis AI full_text: {e}")
            logger.error(f"[{self.name}] Error en an√°lisis AI: {e}")
            return {"success": False, "error": str(e)}
    
    async def _process_url_only(
        self,
        title: str,
        url: str
    ) -> Optional[Dict]:
        """
        MODO FALLBACK: Categorizaci√≥n solo con URL + t√≠tulo
        Usa an√°lisis estructurado de la URL y conocimiento de dominios
        """
        try:
            # Analizar URL de forma estructurada
            domain_info = self._analyze_domain(url)
            path_info = self._analyze_path(url)
            
            prompt = f"""Analiza esta informaci√≥n limitada de un bookmark:

URL: {url}
T√≠tulo original: {title}

Informaci√≥n del dominio:
- Dominio: {domain_info['domain']}
- TLD: {domain_info['tld']}
- Subdominios: {domain_info['subdomains']}

Informaci√≥n del path:
- Segmentos: {path_info['segments']}
- Keywords detectadas: {path_info['keywords']}

CONTEXTO IMPORTANTE: No pudimos acceder al contenido de la p√°gina (bloqueado, timeout o error).
Usa tu conocimiento previo sobre este dominio y los patrones en la URL para hacer una inferencia educada.

Genera metadata en formato JSON:
{{
  "summary": "Resumen de 2 oraciones sobre qu√© probablemente contiene esta p√°gina",
  "tags": ["tag1", "tag2", "tag3", "tag4"],
  "category": "una categor√≠a principal",
  "confidence": 0.7
}}

Categor√≠as v√°lidas: Tecnolog√≠a, Negocios, Educaci√≥n, Entretenimiento, Salud, Ciencia, Arte, Deportes, Noticias, Programaci√≥n, Dise√±o, Marketing, Finanzas, Productividad, Transporte, Otros

EJEMPLOS de buenas inferencias:
- URL "https://www.tmb.cat/es/horarios-metro" ‚Üí Category: "Transporte", Tags: ["transporte p√∫blico", "metro", "barcelona"], Confidence: 0.8
- URL "https://www.coursera.org/learn/machine-learning" ‚Üí Category: "Educaci√≥n", Tags: ["educaci√≥n online", "machine learning"], Confidence: 0.9
- URL "https://github.com/user/awesome-python" ‚Üí Category: "Programaci√≥n", Tags: ["python", "github", "recursos"], Confidence: 0.9

Confidence:
- 0.9-1.0: Dominio muy conocido (google.com, github.com, wikipedia.org)
- 0.7-0.8: Dominio reconocible o path muy descriptivo
- 0.5-0.6: Dominio desconocido pero path informativo
- 0.3-0.4: Muy poca informaci√≥n disponible

Responde SOLO con el JSON."""

            response = await self.groq_client.chat.completions.create(
                model=settings.GROQ_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,  # M√°s conservadora para inferencias
                max_tokens=500,
            )
            
            content = response.choices[0].message.content.strip()
            
            # Parsear JSON
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                analysis = json.loads(json_str)
                
                if all(key in analysis for key in ["summary", "tags", "category"]):
                    analysis["tags"] = list(set(
                        tag.lower().strip() for tag in analysis["tags"]
                    ))
                    analysis["success"] = True
                    
                    logger.info(
                        f"[{self.name}] An√°lisis AI completado (url_only) - "
                        f"Confidence: {analysis.get('confidence', 0.5):.2f}"
                    )
                    return analysis
            
            return {"success": False, "error": "JSON inv√°lido"}
        
        except Exception as e:
            print(f"Error en an√°lisis AI url_only: {e}")
            logger.error(f"[{self.name}] Error en an√°lisis url_only: {e}")
            return {"success": False, "error": str(e)}
    
    def _analyze_domain(self, url: str) -> Dict:
        """Extrae informaci√≥n estructurada del dominio"""
        try:
            extracted = tldextract.extract(url)
            
            return {
                "domain": extracted.domain,
                "tld": extracted.suffix,
                "subdomains": extracted.subdomain.split('.') if extracted.subdomain else [],
                "full_domain": f"{extracted.domain}.{extracted.suffix}"
            }
        
        except Exception as e:
            print(f"Error analizando dominio: {e}")
            logger.error(f"Error analizando dominio: {e}")
            return {
                "domain": "",
                "tld": "",
                "subdomains": [],
                "full_domain": ""
            }
    
    def _analyze_path(self, url: str) -> Dict:
        """Analiza el path de la URL para extraer keywords"""
        try:
            parsed = urlparse(url)
            segments = [s for s in parsed.path.split('/') if s]
            
            # Keywords comunes en URLs por categor√≠a
            category_keywords = {
                'transporte': ['bus', 'metro', 'tren', 'transport', 'horario', 'schedule', 'tmb', 'renfe'],
                'educaci√≥n': ['curso', 'clase', 'university', 'edu', 'learning', 'tutorial', 'coursera'],
                'programaci√≥n': ['github', 'code', 'dev', 'api', 'docs', 'python', 'javascript'],
                'noticias': ['news', 'noticias', 'article', 'post', 'blog'],
            }
            
            found_keywords = []
            for segment in segments:
                segment_lower = segment.lower()
                for category, keywords in category_keywords.items():
                    if any(kw in segment_lower for kw in keywords):
                        found_keywords.append(category)
                        break
            
            return {
                "segments": segments,
                "keywords": list(set(found_keywords))  # Sin duplicados
            }
        
        except Exception as e:
            print(f"Error analizando path de URL: {e}")
            logger.error(f"Error analizando path de URL: {e}")
            return {
                "segments": [],
                "keywords": []
            }


def _default_orchestrator_result(url: str, original_title: str) -> Dict:
    """Construye el diccionario de resultado inicial del orquestador."""
    return {
        "success": False,
        "url": url,
        "original_title": original_title,
        "clean_title": original_title,
        "summary": None,
        "full_text": None,
        "tags": [],
        "category": None,
        "is_nsfw": False,
        "nsfw_reason": None,
        "is_local": False,
        "domain": None,
        "language": None,
        "word_count": 0,
        "embedding": None,
        "status": "failed",
        "scraping_status": "pending",
        "scraping_strategy": None,
        "scraping_error_type": None,
        "scraping_attempts": 0,
        "curation_status": "pending",
        "curation_mode": None,
        "confidence_score": 0.0,
        "error": None,
        "processing_time": 0,
    }


def _merge_archivist_into_result(result: Dict, archivist_result: Dict, original_title: str) -> None:
    """Actualiza result con los campos del agente archivista."""
    result.update({
        "clean_title": archivist_result.get("clean_title", original_title),
        "full_text": archivist_result.get("full_text"),
        "is_nsfw": archivist_result.get("is_nsfw", False),
        "nsfw_reason": archivist_result.get("nsfw_reason"),
        "is_local": archivist_result.get("is_local", False),
        "domain": archivist_result.get("domain"),
        "language": archivist_result.get("language"),
        "word_count": archivist_result.get("word_count", 0),
        "scraping_status": archivist_result.get("scraping_status", "failed"),
        "scraping_strategy": archivist_result.get("scraping_strategy"),
        "scraping_error_type": archivist_result.get("scraping_error_type"),
        "scraping_attempts": archivist_result.get("scraping_attempts", 0),
    })


class AgentOrchestrator:
    """
    Orquestador de Agentes - VERSI√ìN CON ESTADOS PARCIALES

    Coordina el flujo de procesamiento entre Archivista y Curador
    Permite procesamiento parcial exitoso
    """

    def __init__(self):
        self.archivist = ArchivistAgent()
        self.curator = CuratorAgent()

    async def _run_archivist(self, url: str, original_title: str) -> Dict:
        """Ejecuta el agente archivista y devuelve su resultado (nunca lanza)."""
        try:
            return await self.archivist.process(url, original_title)
        except Exception as e:
            logger.exception("Error en Agente Archivista")
            return {"error": str(e)}

    async def _run_curator(self, clean_title: str, full_text: Optional[str], url: str) -> Dict:
        """Ejecuta el agente curador y devuelve su resultado (nunca lanza)."""
        try:
            return await self.curator.process(clean_title, full_text, url)
        except Exception as e:
            logger.exception("Error en Agente Curador")
            return {"success": False, "error": str(e)}

    def _apply_curator_success(
        self,
        result: Dict,
        curator_result: Dict,
        archivist_result: Dict,
        url: str,
    ) -> None:
        """Aplica el resultado exitoso del curador y determina estado final."""
        result.update({
            "summary": curator_result.get("summary"),
            "tags": curator_result.get("tags", []),
            "category": curator_result.get("category"),
            "embedding": curator_result.get("embedding"),
            "curation_status": curator_result.get("curation_status"),
            "curation_mode": curator_result.get("curation_mode"),
            "confidence_score": curator_result.get("confidence", 0.0),
        })
        if result["scraping_status"] == "success":
            result["status"] = "completed"
            result["success"] = True
        else:
            result["status"] = "completed_partial"
            result["success"] = True
            result["error"] = archivist_result.get("error")
        logger.info(
            "[Orchestrator] ‚úÖ Procesamiento exitoso: %s (Status: %s, Confidence: %.2f)",
            url, result["status"], result["confidence_score"],
        )

    async def process_bookmark(self, url: str, original_title: str) -> Dict:
        """
        Procesa un bookmark completo a trav√©s de ambos agentes.
        Garantiza que siempre se intenta la curaci√≥n, incluso si scraping falla.
        """
        start_time = datetime.now()
        logger.info("[Orchestrator] Iniciando procesamiento: %s", url)
        result = _default_orchestrator_result(url, original_title)

        try:
            archivist_result = await self._run_archivist(url, original_title)
            _merge_archivist_into_result(result, archivist_result, original_title)

            if result["is_local"]:
                result["status"] = "manual_required"
                result["error"] = archivist_result.get("error")
                logger.warning("[Orchestrator] URL local - Manual requerido: %s", url)
                return result

            curator_result = await self._run_curator(
                result["clean_title"], result["full_text"], url
            )

            if curator_result.get("success"):
                self._apply_curator_success(result, curator_result, archivist_result, url)
            else:
                result["status"] = "failed"
                result["curation_status"] = "failed"
                result["error"] = (
                    curator_result.get("error") or archivist_result.get("error")
                )
                logger.error("[Orchestrator] ‚ùå Procesamiento fallido: %s", url)
        except Exception as e:
            result["status"] = "failed"
            result["error"] = str(e)
            logger.exception("[Orchestrator] Error general")
        finally:
            result["processing_time"] = (datetime.now() - start_time).total_seconds()
            logger.info(
                "[Orchestrator] Procesamiento completado: %s (Status: %s, Tiempo: %.2fs)",
                url, result["status"], result["processing_time"],
            )
        return result


# Singleton
orchestrator = AgentOrchestrator()


================================================================================
üìÑ ARCHIVO: app/config.py
üìè Tama√±o: 2.7 KB
================================================================================

# app/config.py
from pydantic_settings import BaseSettings, SettingsConfigDict
from functools import lru_cache
from typing import List


class Settings(BaseSettings):
    # --- Base de Datos ---
    DATABASE_URL: str = ""
    EMBEDDING_DIMENSION: int = 384

    # --- API Keys ---
    GROQ_API_KEY: str = ""

    # --- CORS ---
    CORS_ORIGINS: str = "*"

    # --- Rate limiting ---
    RATE_LIMIT_GLOBAL: str = "100/minute"
    RATE_LIMIT_SEARCH: str = "10/minute"
    RATE_LIMIT_CREATE: str = "5/minute"

    # --- Configuraci√≥n del Scraper ---
    SCRAPER_USER_AGENT: str = (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )
    SCRAPER_TIMEOUT: int = 30
    SCRAPER_MAX_RETRIES: int = 3
    SCRAPER_MAX_REDIRECTS: int = 5
    SCRAPER_DELAY_BETWEEN_REQUESTS: float = 1.0

    # FIX: Mantener como str + @property para evitar que pydantic-settings
    # intente deserializar como JSON antes de que el validator pueda actuar.
    # pydantic-settings v2 falla con List[str] + validation_alias cuando el
    # valor en .env es una cadena CSV (no JSON).
    LOCAL_DOMAINS: str = "localhost,127.0.0.1,0.0.0.0"

    # --- Configuraci√≥n de IA y Agentes ---
    EMBEDDING_MODEL: str = "sentence-transformers/all-MiniLM-L6-v2"
    EMBEDDING_MODEL_NAME: str = "sentence-transformers/all-MiniLM-L6-v2"
    LLM_MODEL_NAME: str = "llama-3.1-8b-instant"
    GROQ_MODEL: str = "llama-3.1-8b-instant"
    CHUNK_SIZE: int = 1000
    CHUNK_OVERLAP: int = 200

    # --- Seguridad y Clasificaci√≥n ---
    # Igual que LOCAL_DOMAINS: str CSV + @property evita el problema de
    # pydantic-settings intentando JSON-decode en campos List[str].
    NSFW_KEYWORDS: str = "porn,sex,xxx,nude,casino,gambling"
    NSFW_DOMAINS: str = "pornhub.com,xvideos.com"
    ENABLE_SAFETY_FILTER: bool = True

    # --- Pydantic V2 Config ---
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        extra="ignore",
        case_sensitive=False,
    )

    # --- Propiedades derivadas (CSV str ‚Üí List[str]) ---
    @property
    def local_domains_list(self) -> List[str]:
        return [x.strip().lower() for x in self.LOCAL_DOMAINS.split(",") if x.strip()]

    @property
    def nsfw_keywords_list(self) -> List[str]:
        return [x.strip().lower() for x in self.NSFW_KEYWORDS.split(",") if x.strip()]

    @property
    def nsfw_domains_list(self) -> List[str]:
        return [x.strip().lower() for x in self.NSFW_DOMAINS.split(",") if x.strip()]

    @property
    def is_production(self) -> bool:
        return getattr(self, "ENVIRONMENT", "development").lower() == "production"



@lru_cache()
def get_settings() -> Settings:
    return Settings()


================================================================================
üìÑ ARCHIVO: app/database.py
üìè Tama√±o: 3.1 KB
================================================================================

from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy.orm import declarative_base
from sqlalchemy import text
from contextlib import asynccontextmanager
from typing import AsyncGenerator
from loguru import logger

from app.config import get_settings

try:
    settings = get_settings()
except Exception as e:
    print(f"Error cargando configuraci√≥n: {e}")
    raise

Base = declarative_base()

if not settings.DATABASE_URL or not settings.DATABASE_URL.strip():
    raise ValueError(
        "DATABASE_URL no est√° configurada. Config√∫rala en .env (ej: cp .env.example .env)"
    )

try:
    engine = create_async_engine(
        settings.DATABASE_URL,
        pool_size=10,
        max_overflow=20,
        pool_pre_ping=True,
        echo=False,
    )
except Exception as e:
    print(f"Error creando engine de base de datos: {e}")
    logger.error(f"Error creando engine de base de datos: {e}")
    raise

AsyncSessionLocal = async_sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False,
    autocommit=False,
    autoflush=False,
)

async def init_db():
    """Inicializa la base de datos"""
    try:
        async with engine.begin() as conn:
            # Crear extensi√≥n pgvector
            try:
                await conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))
                logger.info("Extensi√≥n pgvector habilitada")
            except Exception as e:
                print(f"Error habilitando extensi√≥n pgvector: {e}")
                logger.error(f"Error habilitando extensi√≥n pgvector: {e}")
                raise
            
            # Crear tablas (sin checkfirst para forzar error si hay problema)
            try:
                await conn.run_sync(Base.metadata.create_all)
                logger.info("‚úÖ Base de datos inicializada correctamente")
            except Exception as e:
                print(f"Error creando tablas: {e}")
                logger.error(f"Error creando tablas: {e}")
                raise
    except Exception as e:
        print("\n" + "="*60)
        print("‚ùå ERROR INICIALIZANDO BASE DE DATOS")
        print("="*60)
        print(f"Error: {e}")
        print("\nVerifica que:")
        print("1. PostgreSQL est√° corriendo")
        print("2. La base de datos existe")
        print("3. Las credenciales en DATABASE_URL son correctas")
        print("4. El usuario tiene permisos para crear extensiones")
        print("="*60 + "\n")
        raise

async def close_db():
    await engine.dispose()
    logger.info("Conexi√≥n a base de datos cerrada")

async def get_db() -> AsyncGenerator[AsyncSession, None]:
    async with AsyncSessionLocal() as session:
        try:
            yield session
            await session.commit()
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close()

@asynccontextmanager
async def get_db_context():
    async with AsyncSessionLocal() as session:
        try:
            yield session
            await session.commit()
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close()


================================================================================
üìÑ ARCHIVO: app/main.py
üìè Tama√±o: 19.7 KB
================================================================================

from fastapi import FastAPI, Depends, HTTPException, Query, status, BackgroundTasks, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, Response
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, and_, or_, text
from typing import List, Optional
from datetime import datetime
from loguru import logger
import sys
import numpy as np  # Necesario para el fix de arrays

from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

from app.config import get_settings
from app.database import get_db, init_db, close_db
from app.models import Bookmark, SearchHistory, ProcessingLog
from app.schemas import (
    BookmarkResponse,
    BookmarkCreate,  # Aseg√∫rate que esto est√© en schemas.py
    SearchRequest,
    SearchResponse,
    SearchResult,
    ProcessingStats,
    HealthResponse,
)
from app.services.embeddings import get_embedding_service
from app.agents import orchestrator
from app.utils.validators import URLValidator

# Configurar logging
logger.remove()
logger.add(
    sys.stdout,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan> - <level>{message}</level>",
    level="INFO"
)

settings = get_settings()

# Configurar rate limiter
limiter = Limiter(key_func=get_remote_address, default_limits=[settings.RATE_LIMIT_GLOBAL])

app = FastAPI(
    title="Neural Bookmark Brain",
    description="AI-Powered Semantic Knowledge Base for Bookmarks",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# A√±adir el limiter a la app
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

_cors_origins = ["*"] if settings.CORS_ORIGINS.strip() == "*" else [o.strip() for o in settings.CORS_ORIGINS.split(",") if o.strip()]
app.add_middleware(
    CORSMiddleware,
    allow_origins=_cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.on_event("startup")
async def startup_event():
    logger.info("üöÄ Iniciando Neural Bookmark Brain...")
    try:
        await init_db()
        logger.info("‚úÖ Base de datos inicializada")
        embedding_service = get_embedding_service()
        _ = embedding_service.model
        logger.info("‚úÖ Modelo de embeddings cargado")
        logger.info("üéâ Sistema listo!")
    except Exception as e:
        logger.error(f"‚ùå Error en startup: {e}")
        raise


@app.on_event("shutdown")
async def shutdown_event():
    logger.info("üëã Cerrando Neural Bookmark Brain...")
    await close_db()
    logger.info("‚úÖ Conexiones cerradas")


@app.get("/", tags=["Root"])
async def root():
    return {
        "service": "Neural Bookmark Brain",
        "version": "1.0.0",
        "status": "operational",
        "docs": "/docs"
    }


@app.get("/health", response_model=HealthResponse, tags=["Health"])
async def health_check(db: AsyncSession = Depends(get_db)):
    try:
        await db.execute(text("SELECT 1"))
        db_status = "healthy"
    except Exception as e:
        logger.error(f"Database health check failed: {e}")
        db_status = "unhealthy"
    
    return HealthResponse(
        status="healthy" if db_status == "healthy" else "degraded",
        database=db_status,
        version="1.0.0",
        timestamp=datetime.now()
    )


# --- Constantes de paginaci√≥n y exportaci√≥n ---
DEFAULT_BOOKMARK_LIMIT = 50
MAX_BOOKMARK_LIMIT = 100
MAX_EXPORT_LIMIT = 10_000


@app.post("/bookmarks", response_model=BookmarkResponse, status_code=status.HTTP_201_CREATED, tags=["Bookmarks"])
@limiter.limit(settings.RATE_LIMIT_CREATE)
async def create_bookmark(
    request: Request,
    bookmark_in: BookmarkCreate,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db)
):

    """
    Crea un nuevo bookmark y lo pone en cola para procesamiento
    """
    try:
        # 1. Validar URL
        is_valid, normalized_url, error_msg = URLValidator.validate_and_normalize(bookmark_in.url)
        if not is_valid:
            raise HTTPException(status_code=400, detail=f"URL inv√°lida: {error_msg}")

        # 2. Verificar duplicados
        existing = await db.execute(select(Bookmark).where(Bookmark.url == normalized_url))
        if existing.scalar_one_or_none():
            raise HTTPException(status_code=409, detail="El bookmark ya existe")

        # 3. Crear en DB
        new_bookmark = Bookmark(
            url=normalized_url,
            original_title=bookmark_in.original_title or "Pendiente de procesar",
            status="pending"
        )
        db.add(new_bookmark)
        await db.commit()
        await db.refresh(new_bookmark)

        # 4. Trigger procesamiento en background (simulado v√≠a reprocess endpoint logic)
        # En producci√≥n real, esto ir√≠a a una cola (Celery/Redis), aqu√≠ llamamos directo
        # o dejamos que el cron/job lo recoja. Para UX inmediata, lanzamos background task.
        background_tasks.add_task(process_bookmark_background, new_bookmark.id)

        return new_bookmark
    
    except HTTPException:
        raise
    except Exception as e:
        logger.exception("Error creando bookmark")
        raise HTTPException(status_code=500, detail="Error creando bookmark")

async def process_bookmark_background(bookmark_id: int) -> None:
    # Wrapper simple para procesar en background sin bloquear request
    # Requiere crear una nueva sesi√≥n ya que la anterior se cierra
    # NOTA: Para simplificar este fix, confiamos en el script reprocess_failed.py
    # o el endpoint /process/{id} que el usuario puede llamar.
    # Si se requiere autom√°tico, implementar aqu√≠ l√≥gica de orchestrator con nueva sesi√≥n.
    pass


@app.post("/search", response_model=SearchResponse, tags=["Search"])
@limiter.limit(settings.RATE_LIMIT_SEARCH)
async def semantic_search(
    request: Request,
    search_request: SearchRequest,
    db: AsyncSession = Depends(get_db)
):
    start_time = datetime.now()
    
    try:
        logger.info(f"üîç B√∫squeda: '{search_request.query}' (limit: {search_request.limit})")
        
        embedding_service = get_embedding_service()
        query_embedding = embedding_service.generate_query_embedding(search_request.query)
        
        query_stmt = select(Bookmark).where(Bookmark.status == "completed")
        
        if not search_request.include_nsfw:
            query_stmt = query_stmt.where(Bookmark.is_nsfw == False)
        
        if search_request.category:
            query_stmt = query_stmt.where(Bookmark.category == search_request.category)
        
        if search_request.tags:
            tag_conditions = [Bookmark.tags.contains([tag]) for tag in search_request.tags]
            query_stmt = query_stmt.where(or_(*tag_conditions))
        
        query_stmt = query_stmt.order_by(
            Bookmark.embedding.cosine_distance(query_embedding)
        ).limit(search_request.limit)
        
        result = await db.execute(query_stmt)
        bookmarks = result.scalars().all()
        
        search_results = []
        for bookmark in bookmarks:
            ### FIX: Comprobaci√≥n segura de arrays NumPy/Listas ###
            has_embedding = False
            if bookmark.embedding is not None:
                if isinstance(bookmark.embedding, (list, np.ndarray)):
                    has_embedding = len(bookmark.embedding) > 0
                else:
                    has_embedding = True # Fallback

            if has_embedding:
                similarity = embedding_service.calculate_similarity(
                    query_embedding,
                    bookmark.embedding
                )
            else:
                similarity = 0.0
            
            search_results.append(
                SearchResult(
                    bookmark=BookmarkResponse.from_orm(bookmark),
                    similarity_score=similarity
                )
            )
        
        search_history = SearchHistory(
            query=search_request.query,
            results_count=len(search_results)
        )
        db.add(search_history)
        await db.commit()
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        return SearchResponse(
            query=search_request.query,
            results=search_results,
            total=len(search_results),
            execution_time=execution_time
        )
    
    except HTTPException:
        raise
    except Exception:
        logger.exception("Error en b√∫squeda")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Error en b√∫squeda",
        )


@app.get("/bookmarks/{bookmark_id}", response_model=BookmarkResponse, tags=["Bookmarks"])
async def get_bookmark(bookmark_id: int, db: AsyncSession = Depends(get_db)):
    try:
        result = await db.execute(select(Bookmark).where(Bookmark.id == bookmark_id))
        bookmark = result.scalar_one_or_none()
        if not bookmark:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Bookmark no encontrado")
        return BookmarkResponse.from_orm(bookmark)
    except HTTPException:
        raise
    except Exception:
        logger.exception("Error obteniendo bookmark")
        raise HTTPException(status_code=500, detail="Error obteniendo bookmark")


@app.get("/bookmarks", response_model=List[BookmarkResponse], tags=["Bookmarks"])
async def list_bookmarks(
    skip: int = Query(0, ge=0),
    limit: int = Query(DEFAULT_BOOKMARK_LIMIT, ge=1, le=MAX_BOOKMARK_LIMIT),
    status_filter: Optional[str] = None,
    category: Optional[str] = None,
    include_nsfw: bool = False,
    db: AsyncSession = Depends(get_db)
):
    try:
        query = select(Bookmark)
        if status_filter:
            query = query.where(Bookmark.status == status_filter)
        if category:
            query = query.where(Bookmark.category == category)
        if not include_nsfw:
            query = query.where(Bookmark.is_nsfw == False)
        
        query = query.order_by(Bookmark.created_at.desc()).offset(skip).limit(limit)
        result = await db.execute(query)
        bookmarks = result.scalars().all()
        return [BookmarkResponse.from_orm(b) for b in bookmarks]
    except HTTPException:
        raise
    except Exception:
        logger.exception("Error listando bookmarks")
        raise HTTPException(status_code=500, detail="Error listando bookmarks")


@app.get("/stats/processing", response_model=ProcessingStats, tags=["Statistics"])
async def get_processing_stats(db: AsyncSession = Depends(get_db)):
    try:
        result = await db.execute(select(Bookmark.status, func.count(Bookmark.id).label('count')).group_by(Bookmark.status))
        stats_by_status = {row.status: row.count for row in result}
        total_result = await db.execute(select(func.count(Bookmark.id)))
        total = total_result.scalar()
        
        return ProcessingStats(
            total=total,
            pending=stats_by_status.get('pending', 0),
            processing=stats_by_status.get('processing', 0),
            completed=stats_by_status.get('completed', 0),
            failed=stats_by_status.get('failed', 0),
            manual_required=stats_by_status.get('manual_required', 0),
        )
    except HTTPException:
        raise
    except Exception:
        logger.exception("Error obteniendo estad√≠sticas de procesamiento")
        raise HTTPException(status_code=500, detail="Error obteniendo estad√≠sticas")


@app.get("/stats/categories", tags=["Statistics"])
async def get_category_stats(db: AsyncSession = Depends(get_db)):
    try:
        result = await db.execute(
            select(Bookmark.category, func.count(Bookmark.id).label('count'))
            .where(and_(Bookmark.category.isnot(None), Bookmark.status == "completed"))
            .group_by(Bookmark.category).order_by(func.count(Bookmark.id).desc())
        )
        categories = [{"category": row.category, "count": row.count} for row in result]
        return {"categories": categories}
    except HTTPException:
        raise
    except Exception:
        logger.exception("Error obteniendo estad√≠sticas de categor√≠as")
        raise HTTPException(status_code=500, detail="Error obteniendo estad√≠sticas de categor√≠as")


@app.get("/stats/tags", tags=["Statistics"])
async def get_tag_stats(limit: int = Query(20, ge=1, le=100), db: AsyncSession = Depends(get_db)):
    try:
        result = await db.execute(
            text("SELECT unnest(tags) as tag, COUNT(*) as count FROM bookmarks WHERE status = 'completed' AND tags IS NOT NULL GROUP BY tag ORDER BY count DESC LIMIT :limit"),
            {"limit": limit}
        )
        tags = [{"tag": row.tag, "count": row.count} for row in result]
        return {"tags": tags}
    except HTTPException:
        raise
    except Exception:
        logger.exception("Error obteniendo estad√≠sticas de tags")
        raise HTTPException(status_code=500, detail="Error obteniendo estad√≠sticas de tags")

@app.get("/export/json")
async def export_json(
    limit: int = Query(MAX_EXPORT_LIMIT, ge=1, le=MAX_EXPORT_LIMIT),
    db: AsyncSession = Depends(get_db),
):
    try:
        result = await db.execute(select(Bookmark).order_by(Bookmark.created_at.desc()).limit(limit))
        bookmarks = result.scalars().all()
        data = [b.to_dict() for b in bookmarks]
        return JSONResponse(content=data)
    except HTTPException:
        raise
    except Exception:
        logger.exception("Error exportando a JSON")
        raise HTTPException(status_code=500, detail="Error exportando a JSON")

@app.get("/export/markdown")
async def export_markdown(
    limit: int = Query(MAX_EXPORT_LIMIT, ge=1, le=MAX_EXPORT_LIMIT),
    db: AsyncSession = Depends(get_db),
):
    try:
        result = await db.execute(select(Bookmark).order_by(Bookmark.created_at.desc()).limit(limit))
        bookmarks = result.scalars().all()
        md = "# My Bookmarks\n\n"
        for b in bookmarks:
            title = b.clean_title or b.original_title or "Sin t√≠tulo"
            tags_str = ", ".join(b.tags) if b.tags else ""
            md += f"## {title}\n"
            md += f"- **URL**: {b.url}\n"
            md += f"- **Category**: {b.category}\n"
            md += f"- **Tags**: {tags_str}\n\n"
            md += f"{b.summary or ''}\n\n---\n\n"
        return Response(content=md, media_type="text/markdown")
    except HTTPException:
        raise
    except Exception:
        logger.exception("Error exportando a Markdown")
        raise HTTPException(status_code=500, detail="Error exportando a Markdown")


@app.post("/process/{bookmark_id}", tags=["Processing"])
@limiter.limit(settings.RATE_LIMIT_CREATE)
async def reprocess_bookmark(request: Request, bookmark_id: int, db: AsyncSession = Depends(get_db)):
    result = await db.execute(select(Bookmark).where(Bookmark.id == bookmark_id))
    bookmark = result.scalar_one_or_none()
    
    if not bookmark:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Bookmark no encontrado")
    
    try:
        bookmark.status = "processing"
        await db.commit()
        
        result = await orchestrator.process_bookmark(bookmark.url, bookmark.original_title)
        
        bookmark.clean_title = result.get("clean_title")
        bookmark.summary = result.get("summary")
        bookmark.full_text = result.get("full_text")
        bookmark.tags = result.get("tags", [])
        bookmark.category = result.get("category")
        bookmark.is_nsfw = result.get("is_nsfw", False)
        bookmark.nsfw_reason = result.get("nsfw_reason")
        bookmark.is_local = result.get("is_local", False)
        bookmark.domain = result.get("domain")
        bookmark.language = result.get("language")
        bookmark.word_count = result.get("word_count", 0)
        bookmark.embedding = result.get("embedding")
        bookmark.status = result.get("status", "failed")
        bookmark.error_message = result.get("error")
        
        await db.commit()
        
        log = ProcessingLog(
            bookmark_id=bookmark.id,
            url=bookmark.url,
            agent_name="orchestrator",
            success=result.get("success", False),
            error_message=result.get("error"),
            processing_time=result.get("processing_time", 0)
        )
        db.add(log)
        await db.commit()
        
        return {
            "success": True,
            "bookmark_id": bookmark.id,
            "status": bookmark.status,
            "processing_time": result.get("processing_time", 0)
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.exception("Error re-procesando bookmark %s", bookmark_id)
        bookmark.status = "failed"
        bookmark.error_message = str(e)
        await db.commit()
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Error procesando")

@app.post("/admin/reembed-all")
async def reembed_all_bookmarks(db: AsyncSession = Depends(get_db)):
    """Re-genera embeddings para todos los bookmarks"""
    try:
        bookmarks = await db.execute(
            select(Bookmark).where(Bookmark.status == "completed")
        )
        
        embedding_service = get_embedding_service()
        count = 0
        for bookmark in bookmarks.scalars():
            try:
                text = f"{bookmark.clean_title}. {bookmark.summary}"
                bookmark.embedding = embedding_service.generate_embedding(text)
                count += 1
            except Exception:
                logger.exception("Error generando embedding para bookmark %s", bookmark.id)
        await db.commit()
        return {"status": "success", "count": count}
    except HTTPException:
        raise
    except Exception:
        logger.exception("Error en reembed-all")
        raise HTTPException(status_code=500, detail="Error regenerando embeddings")


@app.post("/search/hybrid")
async def hybrid_search(query: str, db: AsyncSession = Depends(get_db)):
    try:
        # B√∫squeda sem√°ntica
        embedding_service = get_embedding_service()
        embedding = embedding_service.generate_query_embedding(query)
        semantic_results = await db.execute(
            select(Bookmark)
            .order_by(Bookmark.embedding.cosine_distance(embedding))
            .limit(20)
        )
        
        # B√∫squeda por keywords en t√≠tulo/tags
        keyword_results = await db.execute(
            select(Bookmark)
            .where(
                or_(
                    Bookmark.clean_title.ilike(f"%{query}%"),
                    Bookmark.tags.contains([query.lower()])
                )
            )
            .limit(20)
        )
        
        return {
            "semantic": [BookmarkResponse.from_orm(b) for b in semantic_results.scalars()],
            "keyword": [BookmarkResponse.from_orm(b) for b in keyword_results.scalars()]
        }
    except HTTPException:
        raise
    except Exception:
        logger.exception("Error en b√∫squeda h√≠brida")
        raise HTTPException(status_code=500, detail="Error en b√∫squeda h√≠brida")
    

@app.delete("/bookmarks/{bookmark_id}", tags=["Bookmarks"])
async def delete_bookmark(bookmark_id: int, db: AsyncSession = Depends(get_db)):
    try:
        result = await db.execute(select(Bookmark).where(Bookmark.id == bookmark_id))
        bookmark = result.scalar_one_or_none()
        
        if not bookmark:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Bookmark no encontrado")
        
        await db.delete(bookmark)
        await db.commit()
        return {"success": True, "message": "Bookmark eliminado"}
    except HTTPException:
        raise
    except Exception:
        logger.exception("Error eliminando bookmark")
        raise HTTPException(status_code=500, detail="Error eliminando bookmark")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)


================================================================================
üìÑ ARCHIVO: app/models.py
üìè Tama√±o: 6.4 KB
================================================================================

# app/models.py - VERSI√ìN ACTUALIZADA CON RESILIENCIA

from sqlalchemy import Column, Integer, String, Text, DateTime, Boolean, Float, Index
from sqlalchemy.dialects.postgresql import ARRAY
from sqlalchemy.sql import func
from pgvector.sqlalchemy import Vector
from datetime import datetime

from app.database import Base
from app.config import get_settings

settings = get_settings()


class Bookmark(Base):
    """Modelo principal de Bookmarks con b√∫squeda sem√°ntica y resiliencia"""
    
    __tablename__ = "bookmarks"
    
    # Identificaci√≥n
    id = Column(Integer, primary_key=True, index=True)
    url = Column(String(2048), unique=True, nullable=False, index=True)
    original_title = Column(String(512), nullable=False)
    
    # Contenido procesado
    clean_title = Column(String(512))
    summary = Column(Text)
    full_text = Column(Text)
    
    # Clasificaci√≥n
    tags = Column(ARRAY(String), default=list)
    category = Column(String(100))
    
    # Safety & Privacy
    is_nsfw = Column(Boolean, default=False, index=True)
    is_local = Column(Boolean, default=False, index=True)
    nsfw_reason = Column(String(256))
    
    # ========== NUEVO: Estados de Resiliencia ==========
    
    # Estado general (mantiene compatibilidad)
    status = Column(
        String(50),
        default="pending",
        index=True,
        # Valores: pending, processing, completed, completed_partial, 
        #          failed, manual_required
    )
    error_message = Column(Text)
    
    # Estado de Scraping
    scraping_status = Column(String(50))  
    # Valores: pending, success, partial, failed, skipped
    
    scraping_strategy = Column(String(50))
    # Valores: trafilatura, trafilatura_retry, beautifulsoup, 
    #          archive_org, none
    
    scraping_error_type = Column(String(50))
    # Valores: bot_detection, timeout, connection_refused, 
    #          rate_limited, dns_error, ssl_error, unknown
    
    scraping_attempts = Column(Integer, default=0)
    # N√∫mero de intentos de scraping realizados
    
    # Estado de Curaci√≥n IA
    curation_status = Column(String(50))
    # Valores: pending, success, fallback, failed
    
    curation_mode = Column(String(50))
    # Valores: full_text, url_only, enhanced_url
    
    # M√©tricas de Calidad
    confidence_score = Column(Float, default=0.0)
    # 0.0-1.0: Nivel de confianza en la metadata generada
    # 1.0 = scraping exitoso + curaci√≥n completa
    # 0.7 = scraping exitoso + curaci√≥n parcial
    # 0.5 = solo URL + t√≠tulo procesado con IA
    # 0.3 = fallback b√°sico
    # 0.0 = completamente fallido
    
    # ====================================================
    
    # Embeddings (Vector Sem√°ntico)
    embedding = Column(Vector(settings.EMBEDDING_DIMENSION))
    
    # Metadata
    domain = Column(String(256), index=True)
    favicon_url = Column(String(512))
    language = Column(String(10))
    word_count = Column(Integer)
    
    # M√©tricas (legacy)
    relevance_score = Column(Float, default=0.0)
    
    # Timestamps
    created_at = Column(DateTime(timezone=True), server_default=func.now(), index=True)
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    scraped_at = Column(DateTime(timezone=True))
    
    # √çndices para b√∫squeda
    __table_args__ = (
        Index('ix_bookmarks_embedding_cosine', 'embedding', postgresql_using='ivfflat'),
        Index('ix_bookmarks_tags_gin', 'tags', postgresql_using='gin'),
        Index('ix_bookmarks_category', 'category'),
        Index('ix_bookmarks_domain', 'domain'),
        Index('ix_bookmarks_created_at_desc', created_at.desc()),
        # Nuevos √≠ndices
        Index('ix_bookmarks_scraping_status', 'scraping_status'),
        Index('ix_bookmarks_confidence_score', confidence_score.desc()),
    )
    
    def __repr__(self):
        return f"<Bookmark(id={self.id}, url={self.url[:50]}, status={self.status}, confidence={self.confidence_score:.2f})>"
    
    def to_dict(self):
        """Convierte el modelo a diccionario para API"""
        return {
            "id": self.id,
            "url": self.url,
            "original_title": self.original_title,
            "clean_title": self.clean_title,
            "summary": self.summary,
            "tags": self.tags or [],
            "category": self.category,
            "is_nsfw": self.is_nsfw,
            "is_local": self.is_local,
            "status": self.status,
            "domain": self.domain,
            "language": self.language,
            "word_count": self.word_count,
            "confidence_score": self.confidence_score,
            # Nuevos campos
            "scraping_status": self.scraping_status,
            "scraping_strategy": self.scraping_strategy,
            "curation_mode": self.curation_mode,
            "created_at": self.created_at.isoformat() if self.created_at else None,
            "updated_at": self.updated_at.isoformat() if self.updated_at else None,
        }


class ProcessingLog(Base):
    """Log de procesamiento para debugging y monitoreo"""
    
    __tablename__ = "processing_logs"
    
    id = Column(Integer, primary_key=True, index=True)
    bookmark_id = Column(Integer, index=True)
    url = Column(String(2048))
    
    # Agente que proces√≥
    agent_name = Column(String(50), index=True)  # archivist, curator
    
    # Resultado
    success = Column(Boolean, default=False)
    error_message = Column(Text)
    
    # Metadata de procesamiento
    processing_time = Column(Float)  # segundos
    tokens_used = Column(Integer)
    
    # ========== NUEVO: Detalles de Resiliencia ==========
    scraping_attempts = Column(Integer, default=1)
    scraping_strategy_used = Column(String(50))
    fallback_triggered = Column(Boolean, default=False)
    # ====================================================
    
    # Timestamp
    created_at = Column(DateTime(timezone=True), server_default=func.now(), index=True)
    
    def __repr__(self):
        return f"<ProcessingLog(id={self.id}, agent={self.agent_name}, success={self.success})>"


class SearchHistory(Base):
    """Historial de b√∫squedas para analytics"""
    
    __tablename__ = "search_history"
    
    id = Column(Integer, primary_key=True, index=True)
    query = Column(String(512), index=True)
    results_count = Column(Integer)
    
    # Timestamp
    created_at = Column(DateTime(timezone=True), server_default=func.now(), index=True)
    
    def __repr__(self):
        return f"<SearchHistory(id={self.id}, query={self.query})>"


================================================================================
üìÑ ARCHIVO: app/schemas.py
üìè Tama√±o: 3.3 KB
================================================================================

from pydantic import BaseModel, field_validator, HttpUrl, Field, validator
from typing import List, Optional
from datetime import datetime
from enum import Enum


class BookmarkStatus(str, Enum):
    """Estados posibles de un bookmark"""
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"
    MANUAL_REQUIRED = "manual_required"


class BookmarkBase(BaseModel):
    """Schema base de bookmark"""
    url: str
    original_title: str


class BookmarkCreate(BaseModel):
    url: str
    original_title: Optional[str] = None
### ----------------- ###


class BookmarkUpdate(BaseModel):
    """Schema para actualizar bookmark"""
    clean_title: Optional[str] = None
    summary: Optional[str] = None
    full_text: Optional[str] = None
    tags: Optional[List[str]] = None
    category: Optional[str] = None
    is_nsfw: Optional[bool] = None
    is_local: Optional[bool] = None
    nsfw_reason: Optional[str] = None
    status: Optional[BookmarkStatus] = None
    error_message: Optional[str] = None
    embedding: Optional[List[float]] = None
    domain: Optional[str] = None
    language: Optional[str] = None
    word_count: Optional[int] = None
    relevance_score: Optional[float] = None


class BookmarkResponse(BookmarkBase):
    """Schema de respuesta de bookmark"""
    id: int
    clean_title: Optional[str] = None
    summary: Optional[str] = None
    tags: List[str] = []
    category: Optional[str] = None
    is_nsfw: bool = False
    is_local: bool = False
    status: str
    domain: Optional[str] = None
    language: Optional[str] = None
    word_count: Optional[int] = None
    relevance_score: float = 0.0
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None
    
    class Config:
        from_attributes = True


class SearchRequest(BaseModel):
    """Request de b√∫squeda sem√°ntica"""
    query: str = Field(..., min_length=1, max_length=512)
    limit: int = Field(default=10, ge=1, le=100)
    include_nsfw: bool = Field(default=False)
    category: Optional[str] = None
    tags: Optional[List[str]] = None
    
    @field_validator('query')
    def validate_query(cls, v):
        """Valida que la query no est√© vac√≠a"""
        if not v.strip():
            raise ValueError("La query no puede estar vac√≠a")
        return v.strip()


class SearchResult(BaseModel):
    """Resultado de b√∫squeda con score"""
    bookmark: BookmarkResponse
    similarity_score: float = Field(..., ge=0.0, le=1.0)
    
    class Config:
        from_attributes = True


class SearchResponse(BaseModel):
    """Respuesta de b√∫squeda"""
    query: str
    results: List[SearchResult]
    total: int
    execution_time: float


class ImportStats(BaseModel):
    """Estad√≠sticas de importaci√≥n"""
    total_bookmarks: int
    imported: int
    duplicates: int
    failed: int
    nsfw_detected: int
    local_detected: int
    errors: List[str] = []


class ProcessingStats(BaseModel):
    """Estad√≠sticas de procesamiento"""
    total: int
    pending: int
    processing: int
    completed: int
    failed: int
    manual_required: int
    
    class Config:
        from_attributes = True


class HealthResponse(BaseModel):
    """Health check response"""
    status: str
    database: str
    version: str
    timestamp: datetime



================================================================================
üìÑ ARCHIVO: app/services/__init__.py
üìè Tama√±o: 0.0 KB
================================================================================

"""
Servicios de la aplicaci√≥n
"""



================================================================================
üìÑ ARCHIVO: app/services/classifier.py
üìè Tama√±o: 4.2 KB
================================================================================

from typing import Tuple, Optional
from loguru import logger
from urllib.parse import urlparse
import re

from app.config import get_settings

settings = get_settings()


class SafetyClassifier:
    """Clasificador de contenido NSFW/Adult basado en keywords y dominios"""
    
    def __init__(self):
        self.nsfw_keywords = settings.nsfw_keywords_list
        self.nsfw_domains = settings.nsfw_domains_list
    
    def classify(
        self,
        url: str,
        title: str = "",
        text: str = "",
    ) -> Tuple[bool, Optional[str]]:
        """
        Clasifica si el contenido es NSFW
        
        Args:
            url: URL del bookmark
            title: T√≠tulo del contenido
            text: Texto extra√≠do del contenido
        
        Returns:
            Tuple: (is_nsfw: bool, reason: str)
        """
        # 1. Verificar dominio
        is_nsfw_domain, domain_reason = self._check_domain(url)
        if is_nsfw_domain:
            return True, domain_reason
        
        # 2. Verificar URL
        is_nsfw_url, url_reason = self._check_url(url)
        if is_nsfw_url:
            return True, url_reason
        
        # 3. Verificar t√≠tulo
        if title:
            is_nsfw_title, title_reason = self._check_text(title, "t√≠tulo")
            if is_nsfw_title:
                return True, title_reason
        
        # 4. Verificar texto (sample)
        if text:
            # Solo analizar primeros 1000 caracteres para eficiencia
            text_sample = text[:1000]
            is_nsfw_text, text_reason = self._check_text(text_sample, "contenido")
            if is_nsfw_text:
                return True, text_reason
        
        return False, None
    
    def _check_domain(self, url: str) -> Tuple[bool, Optional[str]]:
        """Verifica si el dominio est√° en la lista NSFW"""
        try:
            parsed = urlparse(url.lower())
            hostname = parsed.hostname or parsed.netloc
            
            for nsfw_domain in self.nsfw_domains:
                if nsfw_domain in hostname:
                    logger.warning(f"Dominio NSFW detectado: {hostname}")
                    return True, f"Dominio NSFW: {nsfw_domain}"
            
            return False, None
        
        except Exception as e:
            logger.error(f"Error verificando dominio NSFW: {e}")
            return False, None
    
    def _check_url(self, url: str) -> Tuple[bool, Optional[str]]:
        """Verifica si la URL contiene keywords NSFW"""
        url_lower = url.lower()
        
        for keyword in self.nsfw_keywords:
            # Buscar keyword como palabra completa (no substring)
            pattern = r'\b' + re.escape(keyword) + r'\b'
            if re.search(pattern, url_lower):
                logger.warning(f"Keyword NSFW en URL: {keyword}")
                return True, f"Keyword NSFW en URL: {keyword}"
        
        return False, None
    
    def _check_text(self, text: str, source: str) -> Tuple[bool, Optional[str]]:
        """Verifica si el texto contiene keywords NSFW"""
        text_lower = text.lower()
        
        # Contador de coincidencias
        matches = 0
        found_keywords = []
        
        for keyword in self.nsfw_keywords:
            # Buscar keyword como palabra completa
            pattern = r'\b' + re.escape(keyword) + r'\b'
            if re.search(pattern, text_lower):
                matches += 1
                found_keywords.append(keyword)
        
        # Umbral: si hay 2+ keywords, marcar como NSFW
        if matches >= 2:
            logger.warning(f"Keywords NSFW en {source}: {found_keywords}")
            return True, f"Keywords NSFW en {source}: {', '.join(found_keywords[:3])}"
        
        return False, None
    
    def add_keyword(self, keyword: str):
        """A√±ade keyword NSFW en runtime"""
        if keyword.lower() not in self.nsfw_keywords:
            self.nsfw_keywords.append(keyword.lower())
            logger.info(f"Keyword NSFW a√±adida: {keyword}")
    
    def add_domain(self, domain: str):
        """A√±ade dominio NSFW en runtime"""
        if domain.lower() not in self.nsfw_domains:
            self.nsfw_domains.append(domain.lower())
            logger.info(f"Dominio NSFW a√±adido: {domain}")


# Singleton
classifier = SafetyClassifier()



================================================================================
üìÑ ARCHIVO: app/services/embeddings.py
üìè Tama√±o: 5.7 KB
================================================================================

from sentence_transformers import SentenceTransformer
from typing import List
import numpy as np
from loguru import logger
from functools import lru_cache

from app.config import get_settings

settings = get_settings()


class EmbeddingService:
    """Servicio de generaci√≥n de embeddings sem√°nticos"""
    
    def __init__(self):
        self.model_name = settings.EMBEDDING_MODEL
        self.dimension = settings.EMBEDDING_DIMENSION
        self._model = None
    
    @property
    def model(self) -> SentenceTransformer:
        """Lazy loading del modelo"""
        if self._model is None:
            try:
                logger.info(f"Cargando modelo de embeddings: {self.model_name}")
                self._model = SentenceTransformer(self.model_name)
                logger.info(f"Modelo cargado exitosamente")
            except Exception as e:
                print(f"Error cargando modelo de embeddings: {e}")
                logger.error(f"Error cargando modelo de embeddings: {e}")
                raise
        return self._model
    
    def generate_embedding(self, text: str) -> List[float]:
        """
        Genera embedding para un texto
        
        Args:
            text: Texto a vectorizar
        
        Returns:
            Lista de floats (embedding vector)
        """
        if not text or not text.strip():
            logger.warning("Texto vac√≠o para embedding, retornando vector cero")
            return [0.0] * self.dimension
        
        try:
            # Truncar texto si es muy largo (max 512 tokens)
            text_truncated = text[:2000]
            
            # Generar embedding
            embedding = self.model.encode(
                text_truncated,
                convert_to_numpy=True,
                show_progress_bar=False
            )
            
            # Convertir a lista
            embedding_list = embedding.tolist()
            
            # Normalizar (opcional pero recomendado para cosine similarity)
            embedding_normalized = self._normalize(embedding_list)
            
            logger.debug(f"Embedding generado para texto de {len(text)} chars")
            
            return embedding_normalized
        
        except Exception as e:
            print(f"Error generando embedding: {e}")
            logger.error(f"Error generando embedding: {e}")
            return [0.0] * self.dimension
    
    def generate_query_embedding(self, query: str) -> List[float]:
        """
        Genera embedding optimizado para queries de b√∫squeda
        
        Args:
            query: Query de b√∫squeda
        
        Returns:
            Embedding vector
        """
        # Para queries, podemos preprocesar el texto
        query_clean = query.strip().lower()
        
        return self.generate_embedding(query_clean)
    
    def generate_batch_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        Genera embeddings para m√∫ltiples textos (m√°s eficiente)
        
        Args:
            texts: Lista de textos
        
        Returns:
            Lista de embeddings
        """
        if not texts:
            return []
        
        try:
            # Truncar textos
            texts_truncated = [text[:2000] if text else "" for text in texts]
            
            # Generar embeddings en batch
            embeddings = self.model.encode(
                texts_truncated,
                convert_to_numpy=True,
                show_progress_bar=True,
                batch_size=32
            )
            
            # Normalizar
            embeddings_normalized = [
                self._normalize(emb.tolist()) for emb in embeddings
            ]
            
            logger.info(f"Generados {len(embeddings_normalized)} embeddings en batch")
            
            return embeddings_normalized
        
        except Exception as e:
            print(f"Error generando batch embeddings: {e}")
            logger.error(f"Error generando batch embeddings: {e}")
            return [[0.0] * self.dimension] * len(texts)
    
    def _normalize(self, vector: List[float]) -> List[float]:
        """Normaliza un vector (L2 normalization)"""
        try:
            np_vector = np.array(vector)
            norm = np.linalg.norm(np_vector)
            
            if norm == 0:
                return vector
            
            normalized = (np_vector / norm).tolist()
            return normalized
        
        except Exception as e:
            print(f"Error normalizando vector: {e}")
            logger.error(f"Error normalizando vector: {e}")
            return vector
    
    def calculate_similarity(
        self,
        embedding1: List[float],
        embedding2: List[float]
    ) -> float:
        """
        Calcula similitud coseno entre dos embeddings
        
        Args:
            embedding1: Primer embedding
            embedding2: Segundo embedding
        
        Returns:
            Score de similitud [0, 1]
        """
        try:
            vec1 = np.array(embedding1)
            vec2 = np.array(embedding2)
            
            # Cosine similarity
            similarity = np.dot(vec1, vec2) / (
                np.linalg.norm(vec1) * np.linalg.norm(vec2)
            )
            
            # Convertir de [-1, 1] a [0, 1]
            similarity_normalized = (similarity + 1) / 2
            
            return float(similarity_normalized)
        
        except Exception as e:
            print(f"Error calculando similitud: {e}")
            logger.error(f"Error calculando similitud: {e}")
            return 0.0


# Singleton
@lru_cache()
def get_embedding_service() -> EmbeddingService:
    """Obtiene instancia singleton del servicio de embeddings"""
    return EmbeddingService()



================================================================================
üìÑ ARCHIVO: app/services/scraper.py
üìè Tama√±o: 16.6 KB
================================================================================

# app/services/scraper.py - VERSI√ìN RESILIENTE ACTUALIZADA

import trafilatura
import httpx
from typing import Optional, Dict, Tuple
from loguru import logger
from datetime import datetime
import tldextract
from urllib.parse import urlparse
import random
import asyncio
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    RetryError
)

from app.config import get_settings

settings = get_settings()


class ScrapingError(Exception):
    """Error base de scraping"""
    pass


class BotDetectionError(ScrapingError):
    """Error 403 - Detectado como bot"""
    pass


class RateLimitError(ScrapingError):
    """Error 429 - Rate limited"""
    pass


class TimeoutError(ScrapingError):
    """Timeout de conexi√≥n"""
    pass


class UserAgentRotator:
    """Rotaci√≥n de User-Agents realistas"""
    
    AGENTS = [
        # Chrome Windows (m√°s com√∫n)
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        # Firefox Windows
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
        # Edge Windows
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.2210.133",
        # Safari macOS (menos com√∫n pero realista)
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15",
    ]
    
    @classmethod
    def get_random_agent(cls) -> str:
        """Obtiene un User-Agent aleatorio"""
        return random.choice(cls.AGENTS)
    
    @classmethod
    def get_realistic_headers(cls) -> Dict[str, str]:
        """Headers completos que parecen navegador real"""
        return {
            "User-Agent": cls.get_random_agent(),
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "Accept-Language": "es-ES,es;q=0.9,en;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "DNT": "1",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1",
            "Cache-Control": "max-age=0",
        }


class ResilientScraper:
    """Scraper con m√∫ltiples estrategias y reintentos"""
    
    def __init__(self):
        self.timeout = settings.SCRAPER_TIMEOUT
        self.max_retries = settings.SCRAPER_MAX_RETRIES
        self.max_redirects = settings.SCRAPER_MAX_REDIRECTS
        self.delay_between_requests = settings.SCRAPER_DELAY_BETWEEN_REQUESTS
        self.user_agent_rotator = UserAgentRotator()
        self.last_request_time = None
    
    async def _rate_limit(self):
        """Aplica rate limiting entre peticiones"""
        if self.last_request_time is not None:
            elapsed = datetime.now().timestamp() - self.last_request_time
            if elapsed < self.delay_between_requests:
                wait_time = self.delay_between_requests - elapsed
                logger.debug(f"Rate limiting: esperando {wait_time:.2f}s")
                await asyncio.sleep(wait_time)
        
        self.last_request_time = datetime.now().timestamp()
    
    async def scrape_url(self, url: str) -> Dict:
        """
        Scraping resiliente con m√∫ltiples estrategias
        
        Returns:
            Dict con: success, text, title, strategy, error_type, attempts, etc.
        """
        result = {
            "success": False,
            "title": None,
            "text": None,
            "html": None,
            "language": None,
            "word_count": 0,
            "domain": None,
            "strategy": None,
            "error_type": None,
            "error_message": None,
            "attempts": 0,
        }
        
        try:
            # Extraer dominio
            extracted = tldextract.extract(url)
            result["domain"] = f"{extracted.domain}.{extracted.suffix}"
            
            # Verificar si es URL local
            if self._is_local_url(url):
                result["error_type"] = "local_url"
                result["error_message"] = "URL local detectada - requiere captura manual"
                return result
            
            # Estrategia 1: Trafilatura con reintentos
            logger.info(f"[Scraper] Estrategia 1: Trafilatura con reintentos")
            strategy_result = await self._trafilatura_with_retry(url)
            result["attempts"] += strategy_result["attempts"]
            
            if strategy_result["success"]:
                result.update(strategy_result)
                result["strategy"] = "trafilatura_retry"
                logger.info(f"‚úÖ Scraping exitoso con trafilatura: {url}")
                return result
            
            # ========== CAMBIO CR√çTICO AQU√ç ==========
            # Si falla con bot detection O contenido insuficiente, intentar BeautifulSoup
            if strategy_result.get("error_type") in ["bot_detection", "insufficient_content"]:
                logger.warning(
                    f"[Scraper] {strategy_result.get('error_type')} - "
                    f"Intentando estrategia 2: BeautifulSoup"
                )
                bs_result = await self._beautifulsoup_fallback(url)
                result["attempts"] += 1
                
                if bs_result["success"]:
                    result.update(bs_result)
                    result["strategy"] = "beautifulsoup"
                    logger.info(f"‚úÖ Scraping exitoso con BeautifulSoup: {url}")
                    return result
            # ==========================================
            
            # Si todas las estrategias fallan
            result["error_type"] = strategy_result.get("error_type", "unknown")
            result["error_message"] = strategy_result.get("error_message", "Todas las estrategias fallaron")
            logger.error(f"‚ùå Scraping fallido: {url} - {result['error_type']}")
        
        except Exception as e:
            result["error_type"] = "unexpected_error"
            result["error_message"] = str(e)
            logger.error(f"‚ùå Error inesperado en scraping {url}: {e}")
        
        return result
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((httpx.TimeoutException, httpx.ConnectError)),
        reraise=True
    )
    async def _fetch_with_retry(self, url: str, headers: Dict) -> httpx.Response:
        """Descarga HTML con reintentos autom√°ticos para errores temporales"""
        # Aplicar rate limiting antes de la petici√≥n
        await self._rate_limit()
        
        try:
            async with httpx.AsyncClient(
                timeout=self.timeout,
                follow_redirects=True,
                max_redirects=self.max_redirects,
            ) as client:
                response = await client.get(url, headers=headers)
                
                # Clasificar errores HTTP
                if response.status_code == 403:
                    raise BotDetectionError(f"403 Forbidden - Bot detection: {url}")
                elif response.status_code == 429:
                    raise RateLimitError(f"429 Too Many Requests: {url}")
                elif response.status_code >= 500:
                    raise httpx.HTTPStatusError(f"Server error {response.status_code}", request=response.request, response=response)
                
                response.raise_for_status()
                return response
        
        except httpx.TooManyRedirects as e:
            print(f"Error: demasiadas redirecciones ({self.max_redirects}): {url}")
            logger.error(f"Demasiadas redirecciones para {url}: {e}")
            raise
        
        except httpx.TimeoutException as e:
            print(f"Error: timeout ({self.timeout}s): {url}")
            logger.error(f"Timeout en petici√≥n a {url}: {e}")
            raise
    
    async def _trafilatura_with_retry(self, url: str) -> Dict:
        """Estrategia 1: Trafilatura con reintentos inteligentes"""
        result = {
            "success": False,
            "attempts": 0,
            "error_type": None,
            "error_message": None,
        }
        
        for attempt in range(1, self.max_retries + 1):
            result["attempts"] = attempt
            
            try:
                logger.info(f"  Intento {attempt}/{self.max_retries}: Descargando {url}")
                
                # Rotar headers en cada intento
                headers = self.user_agent_rotator.get_realistic_headers()
                
                # Descargar con reintentos
                response = await self._fetch_with_retry(url, headers)
                html = response.text
                
                # Extraer contenido con Trafilatura
                text = trafilatura.extract(
                    html,
                    include_comments=False,
                    include_tables=True,
                    no_fallback=False,
                )
                
                # Extraer metadata
                metadata = trafilatura.extract_metadata(html)
                
                if text and len(text.strip()) > 50:
                    result["success"] = True
                    result["text"] = text
                    result["html"] = html[:10000]  # Limitar tama√±o
                    result["word_count"] = len(text.split())
                    
                    if metadata:
                        result["title"] = metadata.title
                        result["language"] = metadata.language
                    
                    return result
                else:
                    logger.warning(f"  Texto extra√≠do muy corto ({len(text) if text else 0} chars)")
                    result["error_type"] = "insufficient_content"
                    result["error_message"] = "Contenido extra√≠do insuficiente"
            
            except BotDetectionError as e:
                result["error_type"] = "bot_detection"
                result["error_message"] = str(e)
                logger.warning(f"  Bot detection detectado en intento {attempt}")
                # No reintentar si es bot detection - pasar a siguiente estrategia
                break
            
            except RateLimitError as e:
                result["error_type"] = "rate_limited"
                result["error_message"] = str(e)
                logger.warning(f"  Rate limited en intento {attempt}")
                # Esperar m√°s tiempo antes de siguiente intento
                if attempt < self.max_retries:
                    import asyncio
                    await asyncio.sleep(10 * attempt)
            
            except httpx.TimeoutException as e:
                result["error_type"] = "timeout"
                result["error_message"] = f"Timeout despu√©s de {self.timeout}s"
                logger.warning(f"  Timeout en intento {attempt}")
            
            except httpx.ConnectError as e:
                result["error_type"] = "connection_refused"
                result["error_message"] = "No se pudo conectar al servidor"
                logger.warning(f"  Connection refused en intento {attempt}")
            
            except httpx.HTTPStatusError as e:
                result["error_type"] = "http_error"
                result["error_message"] = f"HTTP {e.response.status_code}"
                logger.warning(f"  HTTP error {e.response.status_code} en intento {attempt}")
            
            except Exception as e:
                result["error_type"] = "unknown"
                result["error_message"] = str(e)
                logger.error(f"  Error inesperado en intento {attempt}: {e}")
        
        return result
    
    async def _beautifulsoup_fallback(self, url: str) -> Dict:
        """Estrategia 2: BeautifulSoup b√°sico (menos detectable)"""
        try:
            from bs4 import BeautifulSoup
            
            # Aplicar rate limiting
            await self._rate_limit()
            
            headers = self.user_agent_rotator.get_realistic_headers()
            
            async with httpx.AsyncClient(
                timeout=self.timeout,
                follow_redirects=True,
                max_redirects=self.max_redirects
            ) as client:
                response = await client.get(url, headers=headers)
                response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'lxml')
            
            # Eliminar scripts y styles
            for script in soup(["script", "style"]):
                script.decompose()
            
            # Extraer texto
            text = soup.get_text(separator=' ', strip=True)
            title = soup.find('title').text if soup.find('title') else ""
            
            # Limpiar texto
            lines = (line.strip() for line in text.splitlines())
            text = '\n'.join(line for line in lines if line)
            
            return {
                "success": True,
                "text": text[:10000],  # Limitar
                "title": title,
                "html": response.text[:10000],
                "word_count": len(text.split()),
            }
        
        except httpx.TooManyRedirects as e:
            print(f"Error: demasiadas redirecciones en BeautifulSoup fallback: {url}")
            logger.error(f"Demasiadas redirecciones en BeautifulSoup fallback: {e}")
            return {
                "success": False,
                "error_type": "too_many_redirects",
                "error_message": str(e),
            }
        
        except httpx.TimeoutException as e:
            print(f"Error: timeout en BeautifulSoup fallback: {url}")
            logger.error(f"Timeout en BeautifulSoup fallback: {e}")
            return {
                "success": False,
                "error_type": "timeout",
                "error_message": str(e),
            }
        
        except Exception as e:
            print(f"Error en BeautifulSoup fallback: {e}")
            logger.error(f"Error en BeautifulSoup fallback: {e}")
            return {
                "success": False,
                "error_type": "beautifulsoup_failed",
                "error_message": str(e),
            }
    
    def _is_local_url(self, url: str) -> bool:
        """Verifica si la URL es local (.test, .local, localhost, etc.)"""
        try:
            parsed = urlparse(url.lower())
            hostname = parsed.hostname or parsed.netloc
            
            # Verificar contra dominios locales configurados
            for local_domain in settings.local_domains_list:
                if local_domain in hostname:
                    return True
            
            return False
        
        except Exception as e:
            logger.warning(f"Error verificando URL local {url}: {e}")
            return False
    
    def extract_clean_title(self, original_title: str, domain: str = None) -> str:
        """
        Limpia t√≠tulos gen√©ricos como 'Home', 'Index', etc.
        
        Args:
            original_title: T√≠tulo original del bookmark
            domain: Dominio para mejorar el t√≠tulo
        
        Returns:
            T√≠tulo limpio y descriptivo
        """
        try:
            generic_titles = {
                "home", "index", "welcome", "inicio", "p√°gina principal",
                "main page", "default", "untitled", "new tab", "homepage"
            }
            
            title_lower = original_title.lower().strip()
            
            # Si el t√≠tulo es gen√©rico y tenemos dominio
            if title_lower in generic_titles and domain:
                # Capitalizar dominio como t√≠tulo
                clean_domain = domain.replace("-", " ").replace("_", " ").title()
                return f"{clean_domain} - P√°gina Principal"
            
            # Si el t√≠tulo est√° vac√≠o
            if not original_title.strip():
                return domain.title() if domain else "T√≠tulo Desconocido"
            
            # Limpiar separadores comunes
            title_clean = original_title.strip()
            
            # Remover pipes y guiones al final
            for separator in ["|", "-", "‚Äî", "‚Äì"]:
                if separator in title_clean:
                    parts = title_clean.split(separator)
                    # Tomar la parte m√°s larga
                    title_clean = max(parts, key=len).strip()
            
            return title_clean
        
        except Exception as e:
            logger.error(f"Error extrayendo t√≠tulo limpio: {e}")
            return original_title if original_title else "T√≠tulo Desconocido"


# Singleton
scraper = ResilientScraper()


================================================================================
üìÑ ARCHIVO: app/services/url_cleaner.py
üìè Tama√±o: 4.5 KB
================================================================================

import re
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
from typing import Dict, Tuple, Optional
from loguru import logger

class URLCleaner:
    """Limpia URLs de par√°metros de tracking para deduplicaci√≥n"""
    
    # Patrones de par√°metros de tracking comunes
    TRACKING_PARAMS = {
        # Google Analytics
        '_gl', '_ga', '_gid', '_gat', 'ga', 'utm_source', 'utm_medium', 
        'utm_campaign', 'utm_term', 'utm_content', 'utm_id', 'utm_source_platform',
        'utm_medium', 'utm_campaign', 'utm_term', 'utm_content',
        # Facebook
        'fbclid', 'ref', 'fb_source', 'fb_action_ids', 'fb_action_types',
        # Google Ads
        'gclid', 'gclsrc',
        # Microsoft
        'msclkid',
        # Twitter
        'twclid',
        # LinkedIn
        'li_fat_id', 'trk',
        # Outbrain
        'ob_click_id',
        # Taboola
        'taboola',
        # Reddit
        'rdt_cid',
        # Otros comunes
        'ref_src', 'ref_url', 'cmpid', 'ncid', '_bta_tid', '_bta_c', 'mc_cid',
        'mc_eid', 'pk_campaign', 'pk_kwd', 'piwik_campaign', 'piwik_kwd',
        'mtm_campaign', 'mtm_keyword', 'mtm_source', 'mtm_medium',
    }
    
    @staticmethod
    def clean_url(url: str) -> Tuple[str, Dict[str, any]]:
        """
        Limpia una URL de par√°metros de tracking
        
        Args:
            url: URL original con posibles par√°metros de tracking
            
        Returns:
            Tuple: (url_limpia, dict_con_parametros_tracking)
        """
        try:
            # Manejar URLs vac√≠as o None
            if not url or not isinstance(url, str):
                return url, {}
            
            parsed = urlparse(url)
            
            # Si no hay query string, retornar URL original (sin trailing slash)
            if not parsed.query:
                cleaned_url = url.rstrip('/') if url.endswith('/') and not url.endswith('://') else url
                return cleaned_url, {}
            
            # Parsear todos los par√°metros
            all_params = parse_qs(parsed.query, keep_blank_values=True)
            
            # Separar par√°metros de tracking de par√°metros funcionales
            tracking_params = {}
            functional_params = {}
            
            for key, values in all_params.items():
                if key in URLCleaner.TRACKING_PARAMS:
                    tracking_params[key] = values[0] if len(values) == 1 else values
                else:
                    functional_params[key] = values
            
            # Reconstruir URL con solo par√°metros funcionales
            cleaned_query = urlencode(functional_params, doseq=True)
            
            # Reconstruir URL completa
            cleaned_url = urlunparse((
                parsed.scheme,
                parsed.netloc,
                parsed.path.rstrip('/'),  # Eliminar trailing slash en el path
                parsed.params,
                cleaned_query,
                parsed.fragment
            ))
            
            # Si la URL limpia es igual a la original (ignorando trailing slash), retornar original
            original_normalized = url.rstrip('/')
            cleaned_normalized = cleaned_url.rstrip('/')
            
            if cleaned_normalized == original_normalized:
                return url, {}
            
            logger.debug(
                f"URL limpiada: {url[:60]}... ‚Üí {cleaned_url[:60]}... "
                f"(tracking params: {len(tracking_params)})"
            )
            
            return cleaned_url, tracking_params
            
        except Exception as e:
            logger.warning(f"Error limpiando URL {url[:80]}: {e}")
            return url, {}
    
    @staticmethod
    def has_tracking_params(url: str) -> bool:
        """Verifica si una URL contiene par√°metros de tracking"""
        try:
            if not url or not isinstance(url, str):
                return False
            
            parsed = urlparse(url)
            if not parsed.query:
                return False
            
            params = parse_qs(parsed.query)
            return any(key in URLCleaner.TRACKING_PARAMS for key in params.keys())
        except:
            return False
    
    @staticmethod
    def extract_domain(url: str) -> str:
        """Extrae el dominio de una URL"""
        try:
            if not url or not isinstance(url, str):
                return ""
            
            parsed = urlparse(url)
            return parsed.netloc
        except:
            return ""


# Singleton
url_cleaner = URLCleaner()


================================================================================
üìÑ ARCHIVO: app/utils/__init__.py
üìè Tama√±o: 0.0 KB
================================================================================

"""
Utilidades de la aplicaci√≥n
"""



================================================================================
üìÑ ARCHIVO: app/utils/validators.py
üìè Tama√±o: 5.4 KB
‚ö†Ô∏è  DATOS SENSIBLES ENMASCARADOS:
  ‚ö†Ô∏è  Encontrado 1 coincidencia(s) de tipo: https?://
================================================================================

# app/utils/validators.py - VERSI√ìN CORREGIDA (parcial - solo TextValidator)

import validators
from typing import Optional, Tuple
from urllib.parse import urlparse
import re
from loguru import logger


class URLValidator:
    """Validador de URLs"""
    
    @staticmethod
    def is_valid_url(url: str) -> bool:
        """Valida si una URL es v√°lida"""
        if not url or not url.strip():
            return False
        
        # Validaci√≥n b√°sica con validators
        return validators.url(url.strip()) is True
    
    @staticmethod
    def normalize_url(url: str) -> str:
        """Normaliza una URL (a√±ade https://user:xxxxxxxxxx@staticmethod
    def extract_domain(url: str) -> Optional[str]:
        """Extrae el dominio de una URL"""
        try:
            parsed = urlparse(url)
            return parsed.netloc or parsed.hostname
        except Exception as e:
            logger.error(f"Error extrayendo dominio de {url}: {e}")
            return None
    
    @staticmethod
    def validate_and_normalize(url: str) -> Tuple[bool, str, Optional[str]]:
        """
        Valida y normaliza una URL
        
        Returns:
            Tuple: (is_valid, normalized_url, error_message)
        """
        if not url or not url.strip():
            return False, url, "URL vac√≠a"
        
        # Normalizar
        normalized = URLValidator.normalize_url(url)
        
        # Validar
        if not URLValidator.is_valid_url(normalized):
            return False, url, "URL inv√°lida"
        
        return True, normalized, None


class TextValidator:
    """Validador de texto y contenido"""
    
    @staticmethod
    def clean_text(text: str) -> str:
        """
        Limpia texto de caracteres especiales y espacios extra
        CORREGIDO: Mantiene espacios simples entre palabras
        """
        if not text:
            return ""
        
        # 1. Remover caracteres de control (excepto espacios normales)
        text = re.sub(r'[\x00-\x08\x0b-\x0c\x0e-\x1f\x7f-\x9f]', '', text)
        
        # 2. Convertir tabs y newlines a espacios
        text = text.replace('\t', ' ').replace('\n', ' ').replace('\r', ' ')
        
        # 3. Normalizar m√∫ltiples espacios a uno solo
        text = re.sub(r' +', ' ', text)
        
        # 4. Strip espacios al inicio/final
        return text.strip()
    
    @staticmethod
    def truncate(text: str, max_length: int, suffix: str = "...") -> str:
        """Trunca texto a longitud m√°xima"""
        if not text or len(text) <= max_length:
            return text
        
        return text[:max_length - len(suffix)] + suffix
    
    @staticmethod
    def extract_first_sentence(text: str) -> str:
        """Extrae la primera oraci√≥n de un texto"""
        if not text:
            return ""
        
        # Buscar primer punto, signo de exclamaci√≥n o interrogaci√≥n
        match = re.search(r'[.!?]', text)
        
        if match:
            return text[:match.end()].strip()
        
        # Si no hay puntuaci√≥n, retornar primeras 100 palabras
        words = text.split()
        if len(words) > 100:
            return ' '.join(words[:100]) + '...'
        
        return text
    
    @staticmethod
    def is_meaningful_text(text: str, min_words: int = 10) -> bool:
        """Verifica si el texto es significativo"""
        if not text:
            return False
        
        words = text.split()
        return len(words) >= min_words


class DataValidator:
    """Validador de datos generales"""
    
    @staticmethod
    def validate_tags(tags: list) -> list:
        """Valida y limpia lista de tags"""
        if not tags:
            return []
        
        cleaned_tags = []
        for tag in tags:
            if isinstance(tag, str):
                tag_clean = tag.strip().lower()
                if tag_clean and len(tag_clean) > 1:
                    cleaned_tags.append(tag_clean)
        
        # Remover duplicados manteniendo orden
        seen = set()
        unique_tags = []
        for tag in cleaned_tags:
            if tag not in seen:
                seen.add(tag)
                unique_tags.append(tag)
        
        return unique_tags
    
    @staticmethod
    def validate_category(category: str, valid_categories: list) -> Optional[str]:
        """Valida que una categor√≠a est√© en la lista v√°lida"""
        if not category:
            return None
        
        category_clean = category.strip().title()
        
        if category_clean in valid_categories:
            return category_clean
        
        # Buscar coincidencia parcial
        for valid_cat in valid_categories:
            if category_clean.lower() in valid_cat.lower():
                return valid_cat
        
        return "Otros"  # Categor√≠a por defecto
    
    @staticmethod
    def validate_embedding(embedding: list, expected_dim: int) -> bool:
        """Valida que un embedding tenga la dimensi√≥n correcta"""
        if not embedding:
            return False
        
        if not isinstance(embedding, list):
            return False
        
        if len(embedding) != expected_dim:
            return False
        return all(isinstance(x, (int, float)) for x in embedding)


# Categor√≠as v√°lidas del sistema
VALID_CATEGORIES = [
    "Tecnolog√≠a",
    "Negocios",
    "Educaci√≥n",
    "Entretenimiento",
    "Salud",
    "Ciencia",
    "Arte",
    "Deportes",
    "Noticias",
    "Programaci√≥n",
    "Dise√±o",
    "Marketing",
    "Finanzas",
    "Productividad",
    "Otros"
]


================================================================================
üìÑ ARCHIVO: docker-compose.yml
üìè Tama√±o: 1.2 KB
‚ö†Ô∏è  DATOS SENSIBLES ENMASCARADOS:
  ‚ö†Ô∏è  Encontrado 2 coincidencia(s) de tipo: (?i)(password|passwd|pwd)
================================================================================

services:
  db:
    image: pgvector/pgvector:pg16
    container_name: neural_bookmark_db
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-bookmark_user}
      # Definir POSTGRES_PASSWORD en .env en producci√≥n
      POSTGRES_PASSWORD: "xxxxxxxxxx"
      POSTGRES_DB: ${POSTGRES_DB:-neural_bookmarks}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U bookmark_user -d neural_bookmarks"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bookmark_network

  api:
    build: .
    container_name: neural_bookmark_api
    depends_on:
      db:
        condition: service_healthy
    env_file:  # ‚Üê CARGAR VARIABLES DESDE .env DEL HOST
      - .env
    environment:
      DATABASE_URL: postgresql+asyncpg://${POSTGRES_USER:-bookmark_user}:${POSTGRES_PASSWORD: "xxxxxxxxxx"
      ENVIRONMENT: production
    ports:
      - "8090:8000"  # HOST:8090 ‚Üí CONTAINER:8000
    volumes:
      - ./app:/app/app
      - ./scripts:/app/scripts
      - ./data:/app/data
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    networks:
      - bookmark_network

volumes:
  postgres_data:

networks:
  bookmark_network:
    driver: bridge


================================================================================
üìÑ ARCHIVO: filtrar_csv.py
üìè Tama√±o: 1.0 KB
================================================================================

# guarda como filtrar_csv.py
import csv

# 1. Cargar URLs a borrar
with open('urls_para_borrar.txt', 'r') as f:
    urls_muertas = {line.strip() for line in f if line.strip()}

print(f"URLs detectadas para eliminar: {len(urls_muertas)}")

# 2. Filtrar el CSV
try:
    with open('bookmarks.csv', 'r', encoding='utf-8') as f_in, \
         open('bookmarks_limpio.csv', 'w', encoding='utf-8', newline='') as f_out:
        
        reader = csv.reader(f_in)
        writer = csv.writer(f_out)
        
        eliminados = 0
        for row in reader:
            # Si alguna de las URLs muertas est√° en esta fila, la saltamos
            if any(url in "".join(row) for url in urls_muertas):
                eliminados += 1
                continue
            writer.writerow(row)
            
    print(f"‚úÖ Proceso terminado.")
    print(f"Filas eliminadas del CSV: {eliminados}")
    print(f"Nuevo archivo creado: bookmarks_limpio.csv")

except FileNotFoundError:
    print("‚ùå Error: No se encontr√≥ 'bookmarks.csv'")


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/.env.example
üìè Tama√±o: 0.2 KB
================================================================================

# Archivo de ejemplo para variables de entorno
# Copia este archivo a .env y configura tus valores

# URL base de la API
REACT_APP_API_URL=http://192.168.1.40:8090

# Puerto del servidor de desarrollo
VITE_PORT=5173


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/eslint.config.js
üìè Tama√±o: 0.6 KB
================================================================================

import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'
import tseslint from 'typescript-eslint'
import { defineConfig, globalIgnores } from 'eslint/config'

export default defineConfig([
  globalIgnores(['dist']),
  {
    files: ['**/*.{ts,tsx}'],
    extends: [
      js.configs.recommended,
      tseslint.configs.recommended,
      reactHooks.configs.flat.recommended,
      reactRefresh.configs.vite,
    ],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
    },
  },
])



================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/index.html
üìè Tama√±o: 0.5 KB
================================================================================

<!doctype html>
<html lang="es">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/brain-icon.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="Neural Bookmark Brain - Tu biblioteca inteligente de bookmarks" />
    <meta name="google" content="notranslate">
    <title>Neural Bookmark Brain</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/package.json
üìè Tama√±o: 1.4 KB
================================================================================

{
  "name": "neural-bookmark-brain-ui",
  "version": "1.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "tsc && vite build",
    "preview": "vite preview",
    "lint": "eslint . --ext ts,tsx --report-unused-disable-directives --max-warnings 0",
    "test": "playwright test",
    "test:ui": "playwright test tests/ui/",
    "test:api": "playwright test tests/api/",
    "test:e2e": "playwright test tests/e2e/",
    "test:debug": "playwright test --debug",
    "test:headed": "playwright test --headed",
    "test:chromium": "playwright test --project=chromium",
    "test:firefox": "playwright test --project=firefox",
    "test:webkit": "playwright test --project=webkit",
    "test:report": "playwright show-report"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.20.0",
    "uuid": "^9.0.1"
  },
  "devDependencies": {
    "@playwright/test": "^1.58.2",
    "@types/react": "^18.2.43",
    "@types/react-dom": "^18.2.17",
    "@types/uuid": "^9.0.7",
    "@typescript-eslint/eslint-plugin": "^7.0.0",
    "@typescript-eslint/parser": "^7.0.0",
    "@vitejs/plugin-react": "^4.2.1",
    "autoprefixer": "^10.4.16",
    "eslint": "^8.56.0",
    "eslint-plugin-react-hooks": "^4.6.0",
    "eslint-plugin-react-refresh": "^0.4.5",
    "postcss": "^8.4.32",
    "tailwindcss": "^3.4.0",
    "typescript": "^5.2.2",
    "vite": "^5.0.8"
  }
}



================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/playwright.config.ts
üìè Tama√±o: 1.0 KB
================================================================================

// neural-bookmark-ui/playwright.config.ts

import { defineConfig, devices } from '@playwright/test';

export default defineConfig({
    testDir: './tests',
    timeout: 30 * 1000,
    expect: { timeout: 5000 },
    fullyParallel: true,
    forbidOnly: !!process.env.CI,
    retries: 1, // A√±adimos un reintento por inestabilidad de red WSL2
    workers: 1, 
    reporter: 'html',
    use: {
        // URL del Frontend (Vite)
        baseURL: 'http://192.168.1.40:5173', 
        trace: 'on-first-retry',
        screenshot: 'only-on-failure',
        video: 'retain-on-failure',
      },
    
      projects: [
        {
          name: 'chromium',
          use: { ...devices['Desktop Chrome'] }, 
        }
      ],
    
      // IMPORTANTE: Levantar el frontend autom√°ticamente si no est√° corriendo
      webServer: {
        command: 'npm run dev -- --host',
        url: 'http://192.168.1.40:5173',
        reuseExistingServer: !process.env.CI,
        timeout: 120 * 1000,
      },
    });


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/postcss.config.js
üìè Tama√±o: 0.1 KB
================================================================================

// postcss.config.js
export default {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/App.css
üìè Tama√±o: 1.2 KB
================================================================================

:root {
  --bg-primary: #111827;
  --bg-secondary: #1f2937;
  --text-primary: #f9fafb;
  --accent-primary: #3b82f6;
}

body {
  margin: 0;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
  background-color: var(--bg-primary);
  color: var(--text-primary);
  line-height: 1.6;
}

.container {
  max-width: 1200px;
  margin: 0 auto;
  padding: 2rem;
}

.bookmarks-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(350px, 1fr));
  gap: 1.5rem;
  margin-top: 2rem;
}

.bookmark-card {
  background: var(--bg-secondary);
  border-radius: 10px;
  padding: 1.5rem;
  transition: transform 0.2s;
}

.bookmark-card:hover {
  transform: translateY(-5px);
}

h2 {
  margin: 0 0 1rem 0;
  font-size: 1.25rem;
}

.summary {
  color: #9ca3af;
  margin: 1rem 0;
  font-size: 0.95rem;
}

.meta {
  display: flex;
  gap: 1rem;
  margin: 1rem 0;
  color: #6b7280;
  font-size: 0.875rem;
}

.tags {
  display: flex;
  gap: 0.5rem;
  flex-wrap: wrap;
}

.tag {
  background: #374151;
  color: #9ca3af;
  padding: 0.25rem 0.75rem;
  border-radius: 15px;
  font-size: 0.8rem;
}

.loading {
  text-align: center;
  padding: 2rem;
  font-size: 1.2rem;
}


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/App.tsx
üìè Tama√±o: 4.3 KB
================================================================================

// App.tsx - Componente principal de la aplicaci√≥n
import React, { useState, useEffect } from 'react';
import { BrowserRouter as Router, Routes, Route, Navigate } from 'react-router-dom';
import Layout from './components/layout/Layout';
import Dashboard from './pages/Dashboard';
import Bookmarks from './pages/Bookmarks';
import SearchPage from './pages/Search';
import Statistics from './pages/Statistics';
import { api } from './services/api';
import useToast from './hooks/useToast';
import Toast from './components/ui/Toast';
import type { ProcessingStats } from './types';

const App: React.FC = () => {
  const [stats, setStats] = useState<ProcessingStats | null>(null);
  const [loading, setLoading] = useState(true);
  const { toasts, showToast, hideToast } = useToast();

  useEffect(() => {
    loadStats();
  }, []);

  const loadStats = async () => {
    try {
      const statsData = await api.getStats();
      setStats(statsData);
    } catch (error: any) {
      console.error('Error loading stats:', error);
      showToast({
        type: 'error',
        message: 'Error al cargar las estad√≠sticas: ' + error.message
      });
    } finally {
      setLoading(false);
    }
  };

  if (loading) {
    return (
      <div className="min-h-screen bg-gradient-to-br from-indigo-900 to-purple-900 flex items-center justify-center">
        <div className="text-center">
          <div className="text-6xl mb-4 animate-pulse">üß†</div>
          <div className="text-white text-2xl font-bold mb-2">Neural Bookmark Brain</div>
          <div className="text-indigo-200">Cargando...</div>
          <div className="mt-4">
            <div className="animate-spin rounded-full h-8 w-8 border-b-4 border-white mx-auto"></div>
          </div>
        </div>
      </div>
    );
  }

  return (
    <Router>
      <div className="min-h-screen">
        <Routes>
          {/* Rutas con Layout */}
          <Route
            path="/"
            element={
              <Layout stats={stats}>
                <Dashboard stats={stats} />
              </Layout>
            }
          />
          
          <Route
            path="/bookmarks"
            element={
              <Layout stats={stats}>
                <Bookmarks />
              </Layout>
            }
          />
          
          <Route
            path="/search"
            element={
              <Layout stats={stats}>
                <SearchPage />
              </Layout>
            }
          />
          
          <Route
            path="/stats"
            element={
              <Layout stats={stats}>
                <Statistics />
              </Layout>
            }
          />
          
          {/* Rutas adicionales */}
          <Route
            path="/categories"
            element={
              <Layout stats={stats}>
                <div className="text-center py-12">
                  <h2 className="text-2xl font-bold text-gray-900 mb-4">üìÇ Categor√≠as</h2>
                  <p className="text-gray-500">Pr√≥ximamente...</p>
                </div>
              </Layout>
            }
          />
          
          <Route
            path="/tags"
            element={
              <Layout stats={stats}>
                <div className="text-center py-12">
                  <h2 className="text-2xl font-bold text-gray-900 mb-4">üè∑Ô∏è Tags</h2>
                  <p className="text-gray-500">Pr√≥ximamente...</p>
                </div>
              </Layout>
            }
          />
          
          <Route
            path="/settings"
            element={
              <Layout stats={stats}>
                <div className="text-center py-12">
                  <h2 className="text-2xl font-bold text-gray-900 mb-4">‚öôÔ∏è Configuraci√≥n</h2>
                  <p className="text-gray-500">Pr√≥ximamente...</p>
                </div>
              </Layout>
            }
          />

          {/* Redirecci√≥n para rutas no encontradas */}
          <Route path="*" element={<Navigate to="/" replace />} />
        </Routes>

        {/* Toast Notifications */}
        <div className="fixed bottom-4 right-4 z-50 space-y-2">
          {toasts.map((toast) => (
            <Toast key={toast.id} message={toast} onClose={hideToast} />
          ))}
        </div>
      </div>
    </Router>
  );
};

export default App;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/components/bookmarks/BookmarkActions.tsx
üìè Tama√±o: 2.2 KB
================================================================================

// BookmarkActions.tsx - Componente de acciones para bookmarks
import React from 'react';
import Button from '../ui/Button';
import type { Bookmark } from '../../types';

interface BookmarkActionsProps {
  bookmark: Bookmark;
  onRefresh?: () => void;
  onEdit?: (bookmark: Bookmark) => void;
  onDelete?: (id: number) => void;
}

const BookmarkActions: React.FC<BookmarkActionsProps> = ({ 
  bookmark, 
  onRefresh,
  onEdit, 
  onDelete 
}) => {
  const getStatusColor = () => {
    switch (bookmark.status) {
      case 'completed':
        return 'text-green-600 bg-green-50';
      case 'processing':
        return 'text-yellow-600 bg-yellow-50';
      case 'pending':
        return 'text-blue-600 bg-blue-50';
      case 'failed':
        return 'text-red-600 bg-red-50';
      default:
        return 'text-gray-600 bg-gray-50';
    }
  };

  return (
    <div className="flex flex-wrap gap-2">
      {/* Status Badge */}
      <div 
        className={`px-3 py-1.5 rounded-lg font-medium text-sm flex items-center gap-1.5 ${getStatusColor()}`}
      >
        {bookmark.status === 'completed' && '‚úÖ'}
        {bookmark.status === 'processing' && '‚öôÔ∏è'}
        {bookmark.status === 'pending' && '‚è≥'}
        {bookmark.status === 'failed' && '‚ùå'}
        {bookmark.status.charAt(0).toUpperCase() + bookmark.status.slice(1)}
      </div>

      {/* Actions */}
      {onEdit && (
        <Button
          variant="outline"
          size="sm"
          onClick={() => onEdit(bookmark)}
        >
          ‚úèÔ∏è Editar
        </Button>
      )}

      {onDelete && (
        <Button
          variant="danger"
          size="sm"
          onClick={() => onDelete(bookmark.id)}
        >
          üóëÔ∏è Eliminar
        </Button>
      )}

      {onRefresh && bookmark.status === 'failed' && (
        <Button
          variant="success"
          size="sm"
          onClick={onRefresh}
        >
          üîÑ Reintentar
        </Button>
      )}

      {/* Open Link */}
      <Button
        variant="ghost"
        size="sm"
        onClick={() => window.open(bookmark.url, '_blank')}
      >
        üîó Abrir
      </Button>
    </div>
  );
};

export default BookmarkActions;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/components/bookmarks/BookmarkCard.tsx
üìè Tama√±o: 5.3 KB
================================================================================

// BookmarkCard.tsx - Tarjeta individual de bookmark
import React, { useState } from 'react';
import Badge from '../ui/Badge';
import Button from '../ui/Button';
import type { Bookmark } from '../../types';

interface BookmarkCardProps {
  bookmark: Bookmark;
  onEdit?: (bookmark: Bookmark) => void;
  onDelete?: (id: number) => void;
  showActions?: boolean;
}

const BookmarkCard: React.FC<BookmarkCardProps> = ({ 
  bookmark, 
  onEdit, 
  onDelete, 
  showActions = true 
}) => {
  const [expanded, setExpanded] = useState(false);
  const [showFullSummary, setShowFullSummary] = useState(false);

  const getCategoryVariant = (category: string | undefined): 'primary' | 'secondary' | 'success' | 'warning' | 'danger' | 'info' => {
    switch (category?.toLowerCase()) {
      case 'tecnolog√≠a':
      case 'technology':
        return 'primary';
      case 'educaci√≥n':
      case 'education':
        return 'success';
      case 'noticias':
      case 'news':
        return 'info';
      case 'entretenimiento':
      case 'entertainment':
        return 'warning';
      case 'negocios':
      case 'business':
        return 'secondary';
      default:
        return 'secondary';
    }
  };

  return (
    <div className="bg-white rounded-xl shadow-sm border border-gray-100 hover:shadow-md transition-all duration-300 overflow-hidden">
      {/* Header */}
      <div className="p-5 border-b border-gray-100">
        <div className="flex justify-between items-start">
          <div className="flex-1">
            <h3 className="text-lg font-bold text-gray-900 mb-1 line-clamp-2 hover:text-indigo-600 transition-colors">
              <a 
                href={bookmark.url} 
                target="_blank" 
                rel="noopener noreferrer"
                className="hover:underline"
              >
                {bookmark.clean_title || bookmark.original_title || 'Sin t√≠tulo'}
              </a>
            </h3>
            <a 
              href={bookmark.url} 
              target="_blank" 
              rel="noopener noreferrer"
              className="text-indigo-600 hover:text-indigo-800 text-sm break-all line-clamp-1 block"
            >
              {bookmark.url}
            </a>
          </div>
          
          {bookmark.category && (
            <Badge 
              variant={getCategoryVariant(bookmark.category)} 
              size="md"
              className="ml-3 flex-shrink-0"
            >
              {bookmark.category}
            </Badge>
          )}
        </div>
      </div>

      {/* Content */}
      {(bookmark.summary || bookmark.tags) && (
        <div className="p-5">
          {/* Summary */}
          {bookmark.summary && (
            <div className="mb-4">
              <p 
                className={`text-gray-700 text-sm leading-relaxed transition-all duration-300 ${
                  showFullSummary || bookmark.summary.length < 250 
                    ? '' 
                    : 'line-clamp-3'
                }`}
              >
                {bookmark.summary}
              </p>
              {bookmark.summary.length >= 250 && (
                <button
                  onClick={() => setShowFullSummary(!showFullSummary)}
                  className="mt-2 text-indigo-600 hover:text-indigo-800 text-sm font-medium transition-colors"
                >
                  {showFullSummary ? 'Ver menos' : 'Ver m√°s...'}
                </button>
              )}
            </div>
          )}

          {/* Tags */}
          {bookmark.tags && bookmark.tags.length > 0 && (
            <div className="flex flex-wrap gap-2">
              {bookmark.tags.slice(0, 10).map((tag, index) => (
                <Badge key={index} variant="info" size="sm">
                  #{tag}
                </Badge>
              ))}
              {bookmark.tags.length > 10 && (
                <Badge variant="secondary" size="sm">
                  +{bookmark.tags.length - 10} m√°s
                </Badge>
              )}
            </div>
          )}
        </div>
      )}

      {/* Footer */}
      <div className="px-5 py-3 bg-gray-50 border-t border-gray-100">
        <div className="flex justify-between items-center text-xs text-gray-500">
          <span className="flex items-center gap-1">
            <span>üîó {bookmark.domain}</span>
          </span>
          <span className="flex items-center gap-1">
            <span>üìù {bookmark.word_count || 0} palabras</span>
          </span>
          {bookmark.updated_at && (
            <span className="flex items-center gap-1">
              <span>üìÖ {new Date(bookmark.updated_at).toLocaleDateString('es-ES')}</span>
            </span>
          )}
        </div>

        {/* Actions */}
        {showActions && (onEdit || onDelete) && (
          <div className="mt-3 flex gap-2">
            {onEdit && (
              <Button
                variant="outline"
                size="sm"
                onClick={() => onEdit(bookmark)}
              >
                ‚úèÔ∏è Editar
              </Button>
            )}
            {onDelete && (
              <Button
                variant="danger"
                size="sm"
                onClick={() => onDelete(bookmark.id)}
              >
                üóëÔ∏è Eliminar
              </Button>
            )}
          </div>
        )}
      </div>
    </div>
  );
};

export default BookmarkCard;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/components/bookmarks/BookmarkGrid.tsx
üìè Tama√±o: 2.0 KB
================================================================================

// BookmarkGrid.tsx - Grid/List de bookmarks
import React from 'react';
import BookmarkCard from './BookmarkCard';
import type { Bookmark } from '../../types';

interface BookmarkGridProps {
  bookmarks: Bookmark[];
  onEdit?: (bookmark: Bookmark) => void;
  onDelete?: (id: number) => void;
  showActions?: boolean;
  isLoading?: boolean;
  emptyMessage?: string;
}

const BookmarkGrid: React.FC<BookmarkGridProps> = ({ 
  bookmarks, 
  onEdit, 
  onDelete, 
  showActions = true,
  isLoading = false,
  emptyMessage = 'No hay bookmarks para mostrar'
}) => {
  if (isLoading) {
    return (
      <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
        {[...Array(6)].map((_, i) => (
          <div 
            key={i} 
            className="bg-white rounded-xl shadow-sm border border-gray-100 animate-pulse"
          >
            <div className="p-5">
              <div className="h-6 bg-gray-200 rounded w-3/4 mb-3"></div>
              <div className="h-4 bg-gray-200 rounded w-full mb-2"></div>
              <div className="h-4 bg-gray-200 rounded w-5/6 mb-4"></div>
              <div className="flex gap-2">
                <div className="h-6 bg-gray-200 rounded px-3 py-1 w-20"></div>
                <div className="h-6 bg-gray-200 rounded px-3 py-1 w-16"></div>
              </div>
            </div>
          </div>
        ))}
      </div>
    );
  }

  if (bookmarks.length === 0) {
    return (
      <div className="text-center py-16 bg-white rounded-xl shadow-sm border-2 border-dashed border-gray-200">
        <div className="text-6xl mb-4">üß†</div>
        <p className="text-gray-500 text-lg font-medium">{emptyMessage}</p>
      </div>
    );
  }

  return (
    <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
      {bookmarks.map((bookmark) => (
        <BookmarkCard
          key={bookmark.id || bookmark.url}
          bookmark={bookmark}
          onEdit={onEdit}
          onDelete={onDelete}
          showActions={showActions}
        />
      ))}
    </div>
  );
};

export default BookmarkGrid;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/components/layout/Header.tsx
üìè Tama√±o: 3.5 KB
================================================================================

// Header.tsx - Componente Header
import React from 'react';
import { useNavigate } from 'react-router-dom';
import Button from '../ui/Button';
import Input from '../ui/Input';
import type { ProcessingStats } from '../../types';

interface HeaderProps {
  stats?: ProcessingStats | null;
  onSearch?: (query: string) => void;
  onAddBookmark?: () => void;
}

const Header: React.FC<HeaderProps> = ({ stats, onSearch, onAddBookmark }) => {
  const navigate = useNavigate();
  const [searchQuery, setSearchQuery] = React.useState('');

  const handleSearch = (e: React.FormEvent) => {
    e.preventDefault();
    if (onSearch) {
      onSearch(searchQuery);
    }
  };

  return (
    <header className="bg-white shadow-sm">
      <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div className="flex justify-between items-center h-16">
          {/* Logo & Title */}
          <div className="flex items-center gap-3">
            <div 
              className="w-10 h-10 bg-gradient-to-br from-indigo-600 to-purple-600 rounded-xl flex items-center justify-center cursor-pointer"
              onClick={() => navigate('/')}
            >
              <span className="text-white font-bold text-xl">üß†</span>
            </div>
            <div>
              <h1 
                className="text-xl font-bold text-gray-900 cursor-pointer"
                onClick={() => navigate('/')}
              >
                Neural Bookmark Brain
              </h1>
              <p className="text-xs text-gray-500">Tu biblioteca inteligente</p>
            </div>
          </div>

          {/* Search Bar */}
          <div className="flex-1 max-w-2xl mx-8">
            <form onSubmit={handleSearch}>
              <div className="relative">
                <Input
                  type="text"
                  placeholder="üîç Buscar en tus bookmarks..."
                  value={searchQuery}
                  onChange={(e) => setSearchQuery(e.target.value)}
                  size="md"
                  className="pr-24"
                />
                <button
                  type="submit"
                  className="absolute right-1 top-1 bottom-1 px-4 bg-indigo-600 text-white rounded-lg hover:bg-indigo-700 transition-colors"
                >
                  Buscar
                </button>
              </div>
            </form>
          </div>

          {/* Actions & Stats */}
          <div className="flex items-center gap-4">
            {stats && (
              <div className="hidden md:flex items-center gap-4 text-sm">
                <div className="text-center">
                  <p className="text-xs text-gray-500">Total</p>
                  <p className="font-bold text-gray-900">{stats.total_bookmarks}</p>
                </div>
                <div className="text-center">
                  <p className="text-xs text-gray-500">‚úÖ Procesados</p>
                  <p className="font-bold text-green-600">{stats.completed}</p>
                </div>
                <div className="text-center">
                  <p className="text-xs text-gray-500">‚è≥ Pendientes</p>
                  <p className="font-bold text-yellow-600">{stats.pending}</p>
                </div>
              </div>
            )}

            <Button
              onClick={onAddBookmark || (() => navigate('/add'))}
              variant="primary"
              size="md"
              className="whitespace-nowrap"
            >
              ‚ûï Nuevo Bookmark
            </Button>
          </div>
        </div>
      </div>
    </header>
  );
};

export default Header;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/components/layout/Layout.tsx
üìè Tama√±o: 2.1 KB
================================================================================

// Layout.tsx - Componente Layout principal
import React, { useState } from 'react';
import { Outlet } from 'react-router-dom';
import Header from './Header';
import Sidebar from './Sidebar';
import type { ProcessingStats } from '../../types';

interface LayoutProps {
  stats?: ProcessingStats | null;
}

const Layout: React.FC<LayoutProps> = ({ stats }) => {
  const [sidebarOpen, setSidebarOpen] = useState(true);
  const [searchQuery, setSearchQuery] = useState('');

  const toggleSidebar = () => {
    setSidebarOpen(!sidebarOpen);
  };

  const handleSearch = (query: string) => {
    setSearchQuery(query);
    // Aqu√≠ podr√≠as disparar la b√∫squeda real
    console.log('Buscar:', query);
  };

  return (
    <div className="flex h-screen bg-gray-50">
      {/* Sidebar */}
      <Sidebar 
        stats={stats} 
        isOpen={sidebarOpen} 
        onClose={() => setSidebarOpen(false)} 
      />

      {/* Main Content */}
      <div className="flex flex-col flex-1 overflow-hidden">
        {/* Header */}
        <Header 
          stats={stats} 
          onSearch={handleSearch}
          onAddBookmark={() => console.log('Agregar bookmark')}
        />

        {/* Mobile Sidebar Toggle */}
        <button
          onClick={toggleSidebar}
          className="md:hidden fixed bottom-4 left-4 z-50 bg-indigo-600 text-white p-3 rounded-full shadow-lg hover:bg-indigo-700 transition-colors"
          aria-label={sidebarOpen ? 'Cerrar men√∫' : 'Abrir men√∫'}
        >
          {sidebarOpen ? (
            <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
            </svg>
          ) : (
            <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M4 6h16M4 12h16M4 18h16" />
            </svg>
          )}
        </button>

        {/* Page Content */}
        <main className="flex-1 overflow-y-auto p-4 md:p-6">
          <Outlet />
        </main>
      </div>
    </div>
  );
};

export default Layout;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/components/layout/Sidebar.tsx
üìè Tama√±o: 4.3 KB
================================================================================

// Sidebar.tsx - Componente Sidebar
import React from 'react';
import { NavLink } from 'react-router-dom';
import { useNavigate } from 'react-router-dom';
import Badge from '../ui/Badge';
import type { ProcessingStats } from '../../types';

interface SidebarProps {
  stats?: ProcessingStats | null;
  isOpen?: boolean;
  onClose?: () => void;
}

const menuItems = [
  { path: '/', icon: 'üè†', label: 'Dashboard' },
  { path: '/bookmarks', icon: 'üìö', label: 'Todos los Bookmarks' },
  { path: '/categories', icon: 'üìÇ', label: 'Categor√≠as' },
  { path: '/tags', icon: 'üè∑Ô∏è', label: 'Tags' },
  { path: '/stats', icon: 'üìä', label: 'Estad√≠sticas' },
  { path: '/settings', icon: '‚öôÔ∏è', label: 'Configuraci√≥n' }
];

const Sidebar: React.FC<SidebarProps> = ({ stats, isOpen = true, onClose }) => {
  const navigate = useNavigate();

  return (
    <aside 
      className={`bg-gradient-to-b from-indigo-900 to-purple-900 text-white h-full ${
        isOpen ? 'block' : 'hidden'
      } md:block md:w-64 flex flex-col`}
    >
      {/* Logo */}
      <div className="p-6 border-b border-indigo-800">
        <div 
          className="w-12 h-12 bg-white/20 rounded-xl flex items-center justify-center mb-3 cursor-pointer"
          onClick={() => navigate('/')}
        >
          <span className="text-white text-2xl font-bold">üß†</span>
        </div>
        <h2 className="text-xl font-bold cursor-pointer" onClick={() => navigate('/')}>
          Neural Brain
        </h2>
        <p className="text-indigo-200 text-sm mt-1">Bookmarks Inteligentes</p>
      </div>

      {/* Stats Overview */}
      {stats && (
        <div className="p-4 bg-indigo-800/30 border-b border-indigo-700">
          <p className="text-xs text-indigo-200 mb-2">ESTAD√çSTICAS</p>
          <div className="space-y-2">
            <div>
              <div className="flex justify-between text-sm mb-1">
                <span>Total:</span>
                <span className="font-bold">{stats.total_bookmarks}</span>
              </div>
              <div className="w-full bg-indigo-700 rounded-full h-1.5">
                <div 
                  className="bg-white h-1.5 rounded-full" 
                  style={{ width: `${(stats.completed / stats.total_bookmarks) * 100 || 0}%` }}
                ></div>
              </div>
            </div>
            <div className="grid grid-cols-2 gap-2 text-xs">
              <div>
                <Badge variant="success" size="sm">‚úÖ {stats.completed}</Badge>
                <p className="text-indigo-200 mt-1">Procesados</p>
              </div>
              <div>
                <Badge variant="warning" size="sm">‚è≥ {stats.pending}</Badge>
                <p className="text-indigo-200 mt-1">Pendientes</p>
              </div>
              <div>
                <Badge variant="danger" size="sm">‚ùå {stats.failed}</Badge>
                <p className="text-indigo-200 mt-1">Fallidos</p>
              </div>
              <div>
                <Badge variant="info" size="sm">‚öôÔ∏è {stats.processing}</Badge>
                <p className="text-indigo-200 mt-1">Procesando</p>
              </div>
            </div>
          </div>
        </div>
      )}

      {/* Navigation */}
      <nav className="flex-1 overflow-y-auto py-4">
        <ul className="space-y-1 px-4">
          {menuItems.map((item) => (
            <li key={item.path}>
              <NavLink
                to={item.path}
                className={({ isActive }) =>
                  `flex items-center gap-3 px-4 py-3 rounded-lg transition-all ${
                    isActive
                      ? 'bg-white text-indigo-900 shadow-lg'
                      : 'text-indigo-100 hover:bg-indigo-800/50'
                  }`
                }
                onClick={onClose}
              >
                <span className="text-xl">{item.icon}</span>
                <span className="font-medium">{item.label}</span>
              </NavLink>
            </li>
          ))}
        </ul>
      </nav>

      {/* Footer */}
      <div className="p-4 border-t border-indigo-800">
        <div className="text-center">
          <p className="text-xs text-indigo-300">Neural Bookmark Brain</p>
          <p className="text-xs text-indigo-200 mt-1">v1.0.0</p>
        </div>
      </div>
    </aside>
  );
};

export default Sidebar;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/components/modals/AddBookmarkModal.tsx
üìè Tama√±o: 4.5 KB
================================================================================

// AddBookmarkModal.tsx - Modal para agregar nuevo bookmark
import React, { useState } from 'react';
import Button from '../ui/Button';
import Input from '../ui/Input';

interface AddBookmarkModalProps {
  isOpen: boolean;
  onClose: () => void;
  onAdd: (url: string) => Promise<void>;
}

const AddBookmarkModal: React.FC<AddBookmarkModalProps> = ({ 
  isOpen, 
  onClose, 
  onAdd 
}) => {
  const [url, setUrl] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState('');

  if (!isOpen) return null;

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!url.trim()) {
      setError('Por favor ingresa una URL v√°lida');
      return;
    }

    setError('');
    setIsLoading(true);

    try {
      await onAdd(url.trim());
      setUrl('');
      onClose();
    } catch (err: any) {
      setError(err.message || 'Error al agregar el bookmark');
    } finally {
      setIsLoading(false);
    }
  };

  const isValidUrl = (urlString: string) => {
    try {
      new URL(urlString);
      return true;
    } catch {
      return false;
    }
  };

  return (
    <div className="fixed inset-0 z-50 flex items-center justify-center p-4 bg-black bg-opacity-50">
      <div className="bg-white rounded-xl shadow-2xl w-full max-w-md max-h-[90vh] overflow-y-auto">
        {/* Header */}
        <div className="p-6 border-b border-gray-100">
          <div className="flex justify-between items-center">
            <h2 className="text-2xl font-bold text-gray-900">‚ûï Agregar Bookmark</h2>
            <button
              onClick={onClose}
              className="text-gray-400 hover:text-gray-600 transition-colors"
              aria-label="Cerrar"
            >
              <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
              </svg>
            </button>
          </div>
          <p className="text-gray-500 text-sm mt-1">
            Ingresa la URL que quieres guardar y procesar
          </p>
        </div>

        {/* Form */}
        <form onSubmit={handleSubmit} className="p-6">
          <div className="space-y-4">
            <Input
              type="url"
              label="URL del sitio web"
              placeholder="https://ejemplo.com/articulo"
              value={url}
              onChange={(e) => {
                setUrl(e.target.value);
                setError('');
              }}
              error={error}
              size="lg"
              iconLeft={
                <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M13.828 10.172a4 4 0 00-5.656 0l-4 4a4 4 0 105.656 5.656l1.102-1.101m-.758-4.899a4 4 0 005.656 0l4-4a4 4 0 00-5.656-5.656l-1.1 1.1" />
                </svg>
              }
            />

            {/* URL Preview */}
            {url && isValidUrl(url) && (
              <div className="p-3 bg-blue-50 rounded-lg">
                <p className="text-xs text-blue-700 font-medium mb-1">URL detectada:</p>
                <p className="text-sm text-blue-900 break-all">{url}</p>
              </div>
            )}

            {/* Help Text */}
            <div className="text-sm text-gray-500 space-y-2">
              <p>üí° <span className="font-medium">Tips:</span></p>
              <ul className="list-disc list-inside space-y-1">
                <li>Aseg√∫rate de que la URL sea accesible p√∫blicamente</li>
                <li>El procesamiento puede tardar unos segundos</li>
                <li>Se extraer√° el contenido, t√≠tulo y se generar√° un resumen</li>
              </ul>
            </div>

            {/* Actions */}
            <div className="flex gap-3 pt-2">
              <Button
                type="button"
                variant="secondary"
                size="lg"
                className="flex-1"
                onClick={onClose}
              >
                Cancelar
              </Button>
              <Button
                type="submit"
                variant="primary"
                size="lg"
                className="flex-1"
                isLoading={isLoading}
                disabled={!url.trim() || (url.trim() && !isValidUrl(url.trim()))}
              >
                üß† Procesar Bookmark
              </Button>
            </div>
          </div>
        </form>
      </div>
    </div>
  );
};

export default AddBookmarkModal;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/components/search/SearchBar.tsx
üìè Tama√±o: 2.3 KB
================================================================================

// SearchBar.tsx - Barra de b√∫squeda avanzada
import React, { useState } from 'react';
import Input from '../ui/Input';
import Button from '../ui/Button';

interface SearchBarProps {
  onSearch: (query: string) => void;
  onClear?: () => void;
  placeholder?: string;
  initialValue?: string;
}

const SearchBar: React.FC<SearchBarProps> = ({ 
  onSearch, 
  onClear, 
  placeholder = 'üîç Buscar en tus bookmarks...', 
  initialValue = '' 
}) => {
  const [query, setQuery] = useState(initialValue);
  const [isSearching, setIsSearching] = useState(false);

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!query.trim()) return;
    
    setIsSearching(true);
    try {
      await onSearch(query.trim());
    } finally {
      setIsSearching(false);
    }
  };

  const handleClear = () => {
    setQuery('');
    if (onClear) {
      onClear();
    }
  };

  return (
    <form onSubmit={handleSubmit} className="w-full max-w-4xl mx-auto">
      <div className="relative">
        <Input
          type="text"
          placeholder={placeholder}
          value={query}
          onChange={(e) => setQuery(e.target.value)}
          size="lg"
          iconLeft={
            <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z" />
            </svg>
          }
          className={query ? 'pr-24' : 'pr-12'}
        />
        
        {query && (
          <button
            type="button"
            onClick={handleClear}
            className="absolute right-14 top-1/2 -translate-y-1/2 text-gray-400 hover:text-gray-600 transition-colors"
            aria-label="Limpiar b√∫squeda"
          >
            <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
            </svg>
          </button>
        )}
        
        <Button
          type="submit"
          variant="primary"
          size="lg"
          isLoading={isSearching}
          className="absolute right-1 top-1 bottom-1"
        >
          Buscar
        </Button>
      </div>
    </form>
  );
};

export default SearchBar;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/components/stats/ProcessingProgress.tsx
üìè Tama√±o: 4.4 KB
================================================================================

// ProcessingProgress.tsx - Barra de progreso de procesamiento
import React from 'react';
import type { ProcessingStats } from '../../types';

interface ProcessingProgressProps {
  stats: ProcessingStats;
  showDetails?: boolean;
}

const ProcessingProgress: React.FC<ProcessingProgressProps> = ({ 
  stats, 
  showDetails = true 
}) => {
  const total = stats.total_bookmarks;
  const completedPercent = total > 0 ? (stats.completed / total) * 100 : 0;
  const pendingPercent = total > 0 ? (stats.pending / total) * 100 : 0;
  const processingPercent = total > 0 ? (stats.processing / total) * 100 : 0;
  const failedPercent = total > 0 ? (stats.failed / total) * 100 : 0;

  return (
    <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-6">
      <div className="mb-4">
        <div className="flex justify-between items-center mb-2">
          <h3 className="text-lg font-bold text-gray-900">Progreso de Procesamiento</h3>
          <span className="text-sm font-medium text-gray-600">
            {stats.completed}/{total} completados
          </span>
        </div>
        
        {/* Progress Bar */}
        <div className="w-full bg-gray-200 rounded-full h-4 overflow-hidden">
          <div 
            className="h-full bg-gradient-to-r from-green-500 to-emerald-600 transition-all duration-500"
            style={{ width: `${completedPercent}%` }}
            title={`${stats.completed} completados`}
          ></div>
          <div 
            className="h-full bg-gradient-to-r from-blue-500 to-indigo-600 transition-all duration-500"
            style={{ 
              width: `${processingPercent}%`, 
              marginLeft: `${completedPercent}%` 
            }}
            title={`${stats.processing} procesando`}
          ></div>
          <div 
            className="h-full bg-gradient-to-r from-yellow-500 to-orange-500 transition-all duration-500"
            style={{ 
              width: `${pendingPercent}%`, 
              marginLeft: `${completedPercent + processingPercent}%` 
            }}
            title={`${stats.pending} pendientes`}
          ></div>
          <div 
            className="h-full bg-gradient-to-r from-red-500 to-pink-600 transition-all duration-500"
            style={{ 
              width: `${failedPercent}%`, 
              marginLeft: `${completedPercent + processingPercent + pendingPercent}%` 
            }}
            title={`${stats.failed} fallidos`}
          ></div>
        </div>
      </div>

      {/* Details */}
      {showDetails && (
        <div className="grid grid-cols-2 md:grid-cols-4 gap-4">
          <div className="text-center p-3 bg-green-50 rounded-lg">
            <div className="text-2xl font-bold text-green-700">{stats.completed}</div>
            <div className="text-xs text-green-600 mt-1 flex items-center justify-center gap-1">
              <span>‚úÖ</span>
              <span>Completados</span>
            </div>
          </div>
          
          <div className="text-center p-3 bg-blue-50 rounded-lg">
            <div className="text-2xl font-bold text-blue-700">{stats.processing}</div>
            <div className="text-xs text-blue-600 mt-1 flex items-center justify-center gap-1">
              <span>‚öôÔ∏è</span>
              <span>Procesando</span>
            </div>
          </div>
          
          <div className="text-center p-3 bg-yellow-50 rounded-lg">
            <div className="text-2xl font-bold text-yellow-700">{stats.pending}</div>
            <div className="text-xs text-yellow-600 mt-1 flex items-center justify-center gap-1">
              <span>‚è≥</span>
              <span>Pendientes</span>
            </div>
          </div>
          
          <div className="text-center p-3 bg-red-50 rounded-lg">
            <div className="text-2xl font-bold text-red-700">{stats.failed}</div>
            <div className="text-xs text-red-600 mt-1 flex items-center justify-center gap-1">
              <span>‚ùå</span>
              <span>Fallidos</span>
            </div>
          </div>
        </div>
      )}

      {/* Summary */}
      <div className="mt-4 pt-4 border-t border-gray-100">
        <div className="flex justify-between text-sm">
          <span className="text-gray-600">Tasa de √©xito:</span>
          <span className="font-bold text-gray-900">
            {total > 0 ? ((stats.completed / total) * 100).toFixed(1) : 0}%
          </span>
        </div>
      </div>
    </div>
  );
};

export default ProcessingProgress;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/components/stats/StatCard.tsx
üìè Tama√±o: 2.2 KB
================================================================================

// StatCard.tsx - Tarjeta de estad√≠sticas
import React from 'react';

type StatVariant = 'primary' | 'success' | 'warning' | 'danger' | 'info';

interface StatCardProps {
  title: string;
  value: string | number;
  icon: React.ReactNode;
  variant?: StatVariant;
  subtitle?: string;
  trend?: 'up' | 'down' | 'neutral';
  trendValue?: string;
}

const StatCard: React.FC<StatCardProps> = ({ 
  title, 
  value, 
  icon, 
  variant = 'primary', 
  subtitle, 
  trend, 
  trendValue 
}) => {
  const variantStyles = {
    primary: 'bg-gradient-to-br from-indigo-500 to-purple-600',
    success: 'bg-gradient-to-br from-green-500 to-emerald-600',
    warning: 'bg-gradient-to-br from-yellow-500 to-orange-600',
    danger: 'bg-gradient-to-br from-red-500 to-pink-600',
    info: 'bg-gradient-to-br from-blue-500 to-cyan-600'
  };

  const getTrendIcon = () => {
    if (trend === 'up') return 'üìà';
    if (trend === 'down') return 'üìâ';
    return '‚û°Ô∏è';
  };

  return (
    <div className="bg-white rounded-xl shadow-sm border border-gray-100 hover:shadow-md transition-shadow p-6">
      <div className="flex items-start justify-between">
        <div>
          <p className="text-sm text-gray-500 font-medium">{title}</p>
          <p className="text-3xl font-bold text-gray-900 mt-1">{value}</p>
          {subtitle && <p className="text-xs text-gray-400 mt-1">{subtitle}</p>}
        </div>
        <div className={`w-14 h-14 rounded-xl flex items-center justify-center ${variantStyles[variant]}`}>
          <div className="text-2xl">{icon}</div>
        </div>
      </div>

      {trend && trendValue && (
        <div className="mt-4 pt-3 border-t border-gray-100">
          <div className="flex items-center gap-2">
            <span className="text-lg">{getTrendIcon()}</span>
            <span className={`font-medium ${
              trend === 'up' ? 'text-green-600' : 
              trend === 'down' ? 'text-red-600' : 'text-gray-600'
            }`}>
              {trendValue}
            </span>
            <span className="text-sm text-gray-500">
              {trend === 'up' ? 'aumento' : trend === 'down' ? 'disminuci√≥n' : 'estable'}
            </span>
          </div>
        </div>
      )}
    </div>
  );
};

export default StatCard;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/components/ui/Badge.tsx
üìè Tama√±o: 1.1 KB
================================================================================

// Badge.tsx - Componente Badge reutilizable
import React from 'react';

type BadgeVariant = 'primary' | 'secondary' | 'success' | 'warning' | 'danger' | 'info';
type BadgeSize = 'sm' | 'md' | 'lg';

interface BadgeProps {
  variant?: BadgeVariant;
  size?: BadgeSize;
  children: React.ReactNode;
  className?: string;
}

const Badge: React.FC<BadgeProps> = ({ 
  variant = 'primary', 
  size = 'md', 
  children, 
  className = '' 
}) => {
  const baseStyles = 'inline-flex items-center font-medium rounded-full';
  
  const variantStyles = {
    primary: 'bg-indigo-100 text-indigo-800',
    secondary: 'bg-gray-100 text-gray-800',
    success: 'bg-green-100 text-green-800',
    warning: 'bg-yellow-100 text-yellow-800',
    danger: 'bg-red-100 text-red-800',
    info: 'bg-blue-100 text-blue-800'
  };
  
  const sizeStyles = {
    sm: 'px-2 py-0.5 text-xs',
    md: 'px-3 py-1 text-sm',
    lg: 'px-4 py-1.5 text-base'
  };

  return (
    <span className={`${baseStyles} ${variantStyles[variant]} ${sizeStyles[size]} ${className}`}>
      {children}
    </span>
  );
};

export default Badge;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/components/ui/Button.tsx
üìè Tama√±o: 2.3 KB
================================================================================

// Button.tsx - Componente Button reutilizable
import React from 'react';

type ButtonVariant = 'primary' | 'secondary' | 'success' | 'danger' | 'outline' | 'ghost';
type ButtonSize = 'sm' | 'md' | 'lg';

interface ButtonProps extends React.ButtonHTMLAttributes<HTMLButtonElement> {
  variant?: ButtonVariant;
  size?: ButtonSize;
  isLoading?: boolean;
  children: React.ReactNode;
}

const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
  ({ 
    variant = 'primary', 
    size = 'md', 
    isLoading = false, 
    children, 
    className = '', 
    disabled, 
    ...props 
  }, ref) => {
    const baseStyles = 'inline-flex items-center justify-center font-medium rounded-lg transition-all focus:outline-none focus:ring-2 focus:ring-offset-2 disabled:opacity-50 disabled:cursor-not-allowed';
    
    const variantStyles = {
      primary: 'bg-indigo-600 text-white hover:bg-indigo-700 focus:ring-indigo-500',
      secondary: 'bg-gray-600 text-white hover:bg-gray-700 focus:ring-gray-500',
      success: 'bg-green-600 text-white hover:bg-green-700 focus:ring-green-500',
      danger: 'bg-red-600 text-white hover:bg-red-700 focus:ring-red-500',
      outline: 'border-2 border-indigo-600 text-indigo-600 hover:bg-indigo-50 focus:ring-indigo-500',
      ghost: 'text-gray-700 hover:bg-gray-100 focus:ring-gray-300'
    };
    
    const sizeStyles = {
      sm: 'px-3 py-1.5 text-sm',
      md: 'px-4 py-2 text-base',
      lg: 'px-6 py-3 text-lg'
    };

    return (
      <button
        ref={ref}
        className={`${baseStyles} ${variantStyles[variant]} ${sizeStyles[size]} ${className}`}
        disabled={disabled || isLoading}
        {...props}
      >
        {isLoading ? (
          <>
            <svg className="animate-spin -ml-1 mr-2 h-4 w-4" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
              <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
              <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
            </svg>
            Cargando...
          </>
        ) : (
          children
        )}
      </button>
    );
  }
);

Button.displayName = 'Button';

export default Button;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/components/ui/Input.tsx
üìè Tama√±o: 2.1 KB
================================================================================

// Input.tsx - Componente Input reutilizable
import React from 'react';

type InputSize = 'sm' | 'md' | 'lg';
type InputVariant = 'default' | 'flushed';

interface InputProps extends React.InputHTMLAttributes<HTMLInputElement> {
  size?: InputSize;
  variant?: InputVariant;
  label?: string;
  error?: string;
  iconLeft?: React.ReactNode;
  iconRight?: React.ReactNode;
}

const Input = React.forwardRef<HTMLInputElement, InputProps>(
  ({ 
    size = 'md', 
    variant = 'default', 
    label, 
    error, 
    iconLeft, 
    iconRight, 
    className = '', 
    ...props 
  }, ref) => {
    const baseStyles = 'w-full font-medium focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:border-transparent transition-all';
    
    const sizeStyles = {
      sm: 'px-2 py-1 text-sm',
      md: 'px-3 py-2 text-base',
      lg: 'px-4 py-3 text-lg'
    };
    
    const variantStyles = {
      default: 'border border-gray-300 rounded-lg',
      flushed: 'border-b-2 border-gray-300 rounded-none bg-transparent'
    };

    return (
      <div className="w-full">
        {label && (
          <label className="block text-sm font-medium text-gray-700 mb-1">
            {label}
          </label>
        )}
        
        <div className="relative">
          {iconLeft && (
            <div className="absolute left-3 top-1/2 -translate-y-1/2 text-gray-400">
              {iconLeft}
            </div>
          )}
          
          <input
            ref={ref}
            className={`${baseStyles} ${sizeStyles[size]} ${variantStyles[variant]} ${className} ${
              iconLeft ? 'pl-10' : ''
            } ${iconRight ? 'pr-10' : ''} ${error ? 'border-red-500 focus:ring-red-500' : ''}`}
            {...props}
          />
          
          {iconRight && (
            <div className="absolute right-3 top-1/2 -translate-y-1/2 text-gray-400">
              {iconRight}
            </div>
          )}
        </div>
        
        {error && (
          <p className="mt-1 text-sm text-red-600">{error}</p>
        )}
      </div>
    );
  }
);

Input.displayName = 'Input';

export default Input;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/components/ui/Toast.tsx
üìè Tama√±o: 3.0 KB
================================================================================

// Toast.tsx - Componente Toast/Snackbar
import React, { useEffect, useState } from 'react';
import { ToastMessage } from '../../types';

interface ToastProps {
  message: ToastMessage;
  onClose: (id: string) => void;
}

const Toast: React.FC<ToastProps> = ({ message, onClose }) => {
  const [isVisible, setIsVisible] = useState(true);

  useEffect(() => {
    const timer = setTimeout(() => {
      setIsVisible(false);
      setTimeout(() => onClose(message.id), 300);
    }, message.duration || 3000);

    return () => clearTimeout(timer);
  }, [message.id, message.duration, onClose]);

  const variantStyles = {
    success: 'bg-green-500 border-green-600',
    error: 'bg-red-500 border-red-600',
    info: 'bg-blue-500 border-blue-600',
    warning: 'bg-yellow-500 border-yellow-600'
  };

  return (
    <div
      className={`fixed bottom-4 right-4 max-w-md transform transition-all duration-300 ease-in-out ${
        isVisible ? 'translate-x-0 opacity-100' : 'translate-x-full opacity-0'
      }`}
    >
      <div className={`flex items-center gap-3 p-4 rounded-lg shadow-lg border-l-4 ${variantStyles[message.type]}`}>
        <div className="flex-shrink-0">
          {message.type === 'success' && (
            <svg className="h-5 w-5 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 13l4 4L19 7" />
            </svg>
          )}
          {message.type === 'error' && (
            <svg className="h-5 w-5 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
            </svg>
          )}
          {message.type === 'info' && (
            <svg className="h-5 w-5 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
            </svg>
          )}
          {message.type === 'warning' && (
            <svg className="h-5 w-5 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z" />
            </svg>
          )}
        </div>
        <div className="flex-1">
          <p className="text-white font-medium">{message.message}</p>
        </div>
        <button
          onClick={() => {
            setIsVisible(false);
            setTimeout(() => onClose(message.id), 300);
          }}
          className="text-white hover:text-gray-200 transition-colors"
        >
          <svg className="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
          </svg>
        </button>
      </div>
    </div>
  );
};

export default Toast;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/hooks/useBookmarks.ts
üìè Tama√±o: 2.8 KB
================================================================================

// useBookmarks.ts - Hook personalizado para gestionar bookmarks
import { useState, useEffect } from 'react';
import { api } from '../services/api';
import type { Bookmark, BookmarkFilters, ProcessingStats } from '../types';

interface UseBookmarksReturn {
  bookmarks: Bookmark[];
  stats: ProcessingStats | null;
  loading: boolean;
  error: string | null;
  refetch: () => Promise<void>;
  addBookmark: (url: string) => Promise<void>;
  deleteBookmark: (id: number) => Promise<void>;
  search: (query: string) => Promise<void>;
  loadStats: () => Promise<void>;
}

const useBookmarks = (initialFilters: BookmarkFilters = {}): UseBookmarksReturn => {
  const [bookmarks, setBookmarks] = useState<Bookmark[]>([]);
  const [stats, setStats] = useState<ProcessingStats | null>(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);
  const [filters, setFilters] = useState<BookmarkFilters>(initialFilters);

  const loadBookmarks = async () => {
    setLoading(true);
    setError(null);
    try {
      const data = await api.getBookmarks(filters);
      setBookmarks(data);
    } catch (err: any) {
      setError(err.message || 'Error al cargar los bookmarks');
      console.error('Error loading bookmarks:', err);
    } finally {
      setLoading(false);
    }
  };

  const loadStats = async () => {
    try {
      const data = await api.getStats();
      setStats(data);
    } catch (err: any) {
      console.error('Error loading stats:', err);
    }
  };

  const refetch = async () => {
    await Promise.all([loadBookmarks(), loadStats()]);
  };

  const addBookmark = async (url: string) => {
    try {
      const newBookmark = await api.addBookmark(url);
      setBookmarks((prev) => [newBookmark, ...prev]);
      await loadStats();
    } catch (err: any) {
      setError(err.message || 'Error al agregar el bookmark');
      throw err;
    }
  };

  const deleteBookmark = async (id: number) => {
    try {
      await api.deleteBookmark(id);
      setBookmarks((prev) => prev.filter((b) => b.id !== id));
      await loadStats();
    } catch (err: any) {
      setError(err.message || 'Error al eliminar el bookmark');
      throw err;
    }
  };

  const search = async (query: string) => {
    if (!query.trim()) {
      await loadBookmarks();
      return;
    }
    
    setLoading(true);
    setError(null);
    try {
      const response = await api.search(query);
      setBookmarks(response.results);
    } catch (err: any) {
      setError(err.message || 'Error en la b√∫squeda');
      console.error('Search error:', err);
    } finally {
      setLoading(false);
    }
  };

  useEffect(() => {
    refetch();
  }, [filters]);

  return {
    bookmarks,
    stats,
    loading,
    error,
    refetch,
    addBookmark,
    deleteBookmark,
    search,
    loadStats
  };
};

export default useBookmarks;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/hooks/useToast.ts
üìè Tama√±o: 0.8 KB
================================================================================

// useToast.ts - Hook personalizado para gestionar toasts
import { useState } from 'react';
import { ToastMessage } from '../types';
import { v4 as uuidv4 } from 'uuid';

interface UseToastReturn {
  toasts: ToastMessage[];
  showToast: (message: Omit<ToastMessage, 'id'>) => void;
  hideToast: (id: string) => void;
}

const useToast = (): UseToastReturn => {
  const [toasts, setToasts] = useState<ToastMessage[]>([]);

  const showToast = (toast: Omit<ToastMessage, 'id'>) => {
    const newToast: ToastMessage = {
      id: uuidv4(),
      ...toast
    };
    setToasts((prev) => [...prev, newToast]);
  };

  const hideToast = (id: string) => {
    setToasts((prev) => prev.filter((toast) => toast.id !== id));
  };

  return {
    toasts,
    showToast,
    hideToast
  };
};

export default useToast;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/index.css
üìè Tama√±o: 2.0 KB
================================================================================

/* index.css - Estilos globales */
@tailwind base;
@tailwind components;
@tailwind utilities;

:root {
  --primary-color: #6366f1;
  --secondary-color: #8b5cf6;
  --success-color: #10b981;
  --warning-color: #f59e0b;
  --danger-color: #ef4444;
}

* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

body {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen',
    'Ubuntu', 'Cantarell', 'Fira Sans', 'Droid Sans', 'Helvetica Neue',
    sans-serif;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  background-color: #f9fafb;
}

code {
  font-family: source-code-pro, Menlo, Monaco, Consolas, 'Courier New',
    monospace;
}

/* Scrollbar personalizado */
::-webkit-scrollbar {
  width: 8px;
  height: 8px;
}

::-webkit-scrollbar-track {
  background: #f1f1f1;
  border-radius: 4px;
}

::-webkit-scrollbar-thumb {
  background: #888;
  border-radius: 4px;
}

::-webkit-scrollbar-thumb:hover {
  background: #555;
}

/* Animaciones personalizadas */
@keyframes pulse-slow {
  0%, 100% {
    opacity: 1;
  }
  50% {
    opacity: 0.5;
  }
}

.animate-pulse-slow {
  animation: pulse-slow 2s cubic-bezier(0.4, 0, 0.6, 1) infinite;
}

/* Transiciones suaves */
.transition-all {
  transition-property: all;
  transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1);
  transition-duration: 300ms;
}

/* Hover effects */
.hover\:shadow-xl:hover {
  box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);
}

/* Responsive utilities */
@media (max-width: 768px) {
  .mobile-hidden {
    display: none;
  }
  
  .mobile-block {
    display: block;
  }
}

/* Loading skeleton */
.skeleton {
  background: linear-gradient(
    90deg,
    #f0f0f0 25%,
    #e0e0e0 50%,
    #f0f0f0 75%
  );
  background-size: 200% 100%;
  animation: loading 1.5s infinite;
}

@keyframes loading {
  0% {
    background-position: 200% 0;
  }
  100% {
    background-position: -200% 0;
  }
}

/* Focus ring personalizado */
.focus-ring {
  outline: none;
  box-shadow: 0 0 0 3px rgba(99, 102, 241, 0.3);
}


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/main.tsx
üìè Tama√±o: 0.3 KB
================================================================================

// main.tsx - Punto de entrada de la aplicaci√≥n
import React from 'react';
import ReactDOM from 'react-dom/client';
import App from './App';
import './index.css';

ReactDOM.createRoot(document.getElementById('root')!).render(
  <React.StrictMode>
    <App />
  </React.StrictMode>
);


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/pages/Bookmarks.tsx
üìè Tama√±o: 2.6 KB
================================================================================

// Bookmarks.tsx - P√°gina de lista de todos los bookmarks
import React, { useState } from 'react';
import BookmarkGrid from '../components/bookmarks/BookmarkGrid';
import SearchBar from '../components/search/SearchBar';
import useBookmarks from '../hooks/useBookmarks';
import Button from '../components/ui/Button';
import AddBookmarkModal from '../components/modals/AddBookmarkModal';
import type { Bookmark } from '../types';

const Bookmarks: React.FC = () => {
  const [showModal, setShowModal] = useState(false);
  const [searchQuery, setSearchQuery] = useState('');
  const { 
    bookmarks, 
    loading, 
    search, 
    addBookmark,
    deleteBookmark,
    refetch 
  } = useBookmarks({
    status_filter: 'completed',
    limit: 50
  });

  const handleSearch = async (query: string) => {
    setSearchQuery(query);
    await search(query);
  };

  const handleAdd = async (url: string) => {
    await addBookmark(url);
    await refetch();
  };

  const handleDelete = async (id: number) => {
    if (confirm('¬øEst√°s seguro de que quieres eliminar este bookmark?')) {
      await deleteBookmark(id);
      await refetch();
    }
  };

  const handleClearSearch = async () => {
    setSearchQuery('');
    await refetch();
  };

  return (
    <div className="space-y-6">
      {/* Header */}
      <div className="flex justify-between items-center">
        <div>
          <h1 className="text-3xl font-bold text-gray-900">üìö Todos los Bookmarks</h1>
          <p className="text-gray-500 mt-1">
            {loading ? 'Cargando...' : `${bookmarks.length} bookmarks`}
          </p>
        </div>
        <Button
          variant="primary"
          size="md"
          onClick={() => setShowModal(true)}
        >
          ‚ûï Agregar Bookmark
        </Button>
      </div>

      {/* Search Bar */}
      <SearchBar 
        onSearch={handleSearch}
        onClear={handleClearSearch}
        placeholder="üîç Buscar en tus bookmarks..."
        initialValue={searchQuery}
      />

      {/* Bookmarks Grid */}
      <BookmarkGrid
        bookmarks={bookmarks}
        onEdit={(bookmark: Bookmark) => console.log('Editar:', bookmark)}
        onDelete={handleDelete}
        isLoading={loading}
        emptyMessage={
          searchQuery 
            ? 'No se encontraron resultados para tu b√∫squeda'
            : 'No hay bookmarks todav√≠a. ¬°Agrega tu primer bookmark!'
        }
      />

      {/* Add Bookmark Modal */}
      <AddBookmarkModal
        isOpen={showModal}
        onClose={() => setShowModal(false)}
        onAdd={handleAdd}
      />
    </div>
  );
};

export default Bookmarks;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/pages/Dashboard.tsx
üìè Tama√±o: 3.1 KB
================================================================================

// Dashboard.tsx - P√°gina principal del dashboard
import React, { useEffect } from 'react';
import { useNavigate } from 'react-router-dom';
import StatCard from '../components/stats/StatCard';
import ProcessingProgress from '../components/stats/ProcessingProgress';
import BookmarkGrid from '../components/bookmarks/BookmarkGrid';
import SearchBar from '../components/search/SearchBar';
import useBookmarks from '../hooks/useBookmarks';
import type { ProcessingStats } from '../types';

interface DashboardProps {
  stats: ProcessingStats | null;
}

const Dashboard: React.FC<DashboardProps> = ({ stats }) => {
  const navigate = useNavigate();
  const { bookmarks, loading, search, refetch } = useBookmarks({
    status_filter: 'completed',
    limit: 12
  });

  useEffect(() => {
    refetch();
  }, []);

  const handleSearch = async (query: string) => {
    await search(query);
  };

  return (
    <div className="space-y-6">
      {/* Header */}
      <div>
        <h1 className="text-3xl font-bold text-gray-900">üìä Dashboard</h1>
        <p className="text-gray-500 mt-1">Resumen de tu biblioteca de bookmarks</p>
      </div>

      {/* Search Bar */}
      <SearchBar 
        onSearch={handleSearch}
        placeholder="üîç Buscar en tus bookmarks..."
      />

      {/* Stats Grid */}
      {stats && (
        <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-6">
          <StatCard
            title="Total Bookmarks"
            value={stats.total_bookmarks}
            icon="üìö"
            variant="primary"
            subtitle="En tu biblioteca"
          />
          <StatCard
            title="Procesados"
            value={stats.completed}
            icon="‚úÖ"
            variant="success"
            subtitle="Listos para usar"
            trend="up"
            trendValue={`${stats.completed}`}
          />
          <StatCard
            title="Pendientes"
            value={stats.pending}
            icon="‚è≥"
            variant="warning"
            subtitle="Esperando procesamiento"
          />
          <StatCard
            title="Fallidos"
            value={stats.failed}
            icon="‚ùå"
            variant="danger"
            subtitle="Requieren atenci√≥n"
          />
        </div>
      )}

      {/* Processing Progress */}
      {stats && (
        <ProcessingProgress stats={stats} />
      )}

      {/* Recent Bookmarks */}
      <div>
        <div className="flex justify-between items-center mb-4">
          <div>
            <h2 className="text-2xl font-bold text-gray-900">üìö √öltimos Bookmarks</h2>
            <p className="text-gray-500 text-sm mt-1">
              Los bookmarks m√°s recientes en tu biblioteca
            </p>
          </div>
          <button
            onClick={() => navigate('/bookmarks')}
            className="text-indigo-600 hover:text-indigo-800 font-medium text-sm"
          >
            Ver todos ‚Üí
          </button>
        </div>
        
        <BookmarkGrid
          bookmarks={bookmarks}
          isLoading={loading}
          showActions={false}
          emptyMessage="No hay bookmarks recientes"
        />
      </div>
    </div>
  );
};

export default Dashboard;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/pages/Search.tsx
üìè Tama√±o: 2.8 KB
================================================================================

// Search.tsx - P√°gina de b√∫squeda avanzada
import React, { useState, useEffect } from 'react';
import { useSearchParams } from 'react-router-dom';
import SearchBar from '../components/search/SearchBar';
import BookmarkGrid from '../components/bookmarks/BookmarkGrid';
import { api } from '../services/api';
import type { Bookmark } from '../types';

const SearchPage: React.FC = () => {
  const [searchParams, setSearchParams] = useSearchParams();
  const [query, setQuery] = useState(searchParams.get('q') || '');
  const [results, setResults] = useState<Bookmark[]>([]);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  useEffect(() => {
    const initialQuery = searchParams.get('q');
    if (initialQuery) {
      setQuery(initialQuery);
      performSearch(initialQuery);
    }
  }, [searchParams]);

  const performSearch = async (searchQuery: string) => {
    if (!searchQuery.trim()) {
      setResults([]);
      return;
    }

    setLoading(true);
    setError(null);

    try {
      const response = await api.search(searchQuery, 50);
      setResults(response.results || []);
    } catch (err: any) {
      setError(err.message || 'Error al realizar la b√∫squeda');
      setResults([]);
    } finally {
      setLoading(false);
    }
  };

  const handleSearch = async (searchQuery: string) => {
    setQuery(searchQuery);
    setSearchParams({ q: searchQuery });
    await performSearch(searchQuery);
  };

  const handleClear = () => {
    setQuery('');
    setSearchParams({});
    setResults([]);
  };

  return (
    <div className="space-y-6">
      {/* Header */}
      <div>
        <h1 className="text-3xl font-bold text-gray-900">üîç B√∫squeda Avanzada</h1>
        <p className="text-gray-500 mt-1">
          Busca en tus bookmarks usando b√∫squeda sem√°ntica
        </p>
      </div>

      {/* Search Bar */}
      <SearchBar 
        onSearch={handleSearch}
        onClear={handleClear}
        placeholder="üîç ¬øQu√© est√°s buscando?..."
        initialValue={query}
      />

      {/* Results Info */}
      {!loading && query && (
        <div className="bg-blue-50 border border-blue-200 rounded-lg p-4">
          <p className="text-blue-800 font-medium">
            {error 
              ? `‚ö†Ô∏è ${error}`
              : loading 
                ? 'Buscando...'
                : `${results.length} resultado${results.length !== 1 ? 's' : ''} para "${query}"`
            }
          </p>
        </div>
      )}

      {/* Results Grid */}
      <BookmarkGrid
        bookmarks={results}
        isLoading={loading}
        showActions={false}
        emptyMessage={
          query 
            ? error || 'No se encontraron resultados'
            : 'Ingresa una b√∫squeda para ver resultados'
        }
      />
    </div>
  );
};

export default SearchPage;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/pages/Statistics.tsx
üìè Tama√±o: 7.2 KB
================================================================================

// Statistics.tsx - P√°gina de estad√≠sticas detalladas
import React, { useState, useEffect } from 'react';
import { api } from '../services/api';
import StatCard from '../components/stats/StatCard';
import ProcessingProgress from '../components/stats/ProcessingProgress';
import Badge from '../components/ui/Badge';
import type { ProcessingStats, CategoryStats, TagStats } from '../types';

const Statistics: React.FC = () => {
  const [stats, setStats] = useState<ProcessingStats | null>(null);
  const [categories, setCategories] = useState<CategoryStats[]>([]);
  const [tags, setTags] = useState<TagStats[]>([]);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    loadStats();
  }, []);

  const loadStats = async () => {
    setLoading(true);
    try {
      const [statsData, categoriesData, tagsData] = await Promise.all([
        api.getStats(),
        api.getCategories(),
        api.getTags(50)
      ]);
      setStats(statsData);
      setCategories(categoriesData);
      setTags(tagsData);
    } catch (error) {
      console.error('Error loading stats:', error);
    } finally {
      setLoading(false);
    }
  };

  const getCategoryColor = (index: number): string => {
    const colors = [
      'bg-blue-500',
      'bg-green-500',
      'bg-yellow-500',
      'bg-red-500',
      'bg-purple-500',
      'bg-pink-500',
      'bg-indigo-500',
      'bg-teal-500',
      'bg-orange-500',
      'bg-cyan-500'
    ];
    return colors[index % colors.length];
  };

  if (loading) {
    return (
      <div className="flex items-center justify-center min-h-[500px]">
        <div className="text-center">
          <div className="animate-spin rounded-full h-16 w-16 border-b-4 border-indigo-600 mx-auto mb-4"></div>
          <p className="text-gray-600">Cargando estad√≠sticas...</p>
        </div>
      </div>
    );
  }

  return (
    <div className="space-y-6">
      {/* Header */}
      <div>
        <h1 className="text-3xl font-bold text-gray-900">üìä Estad√≠sticas Detalladas</h1>
        <p className="text-gray-500 mt-1">An√°lisis completo de tu biblioteca</p>
      </div>

      {/* Processing Progress */}
      {stats && <ProcessingProgress stats={stats} showDetails={true} />}

      {/* Categories Section */}
      <div>
        <div className="mb-4">
          <h2 className="text-2xl font-bold text-gray-900">üìÇ Categor√≠as</h2>
          <p className="text-gray-500 text-sm mt-1">
            Distribuci√≥n de tus bookmarks por categor√≠as
          </p>
        </div>

        <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
          {categories.map((category, index) => (
            <div 
              key={category.category} 
              className="bg-white rounded-lg p-4 border border-gray-100 hover:shadow-md transition-shadow"
            >
              <div className="flex items-center justify-between mb-3">
                <div className="flex items-center gap-3">
                  <div className={`w-10 h-10 rounded-lg ${getCategoryColor(index)} flex items-center justify-center`}>
                    <span className="text-white font-bold text-lg">
                      {category.category.charAt(0)}
                    </span>
                  </div>
                  <div>
                    <p className="font-bold text-gray-900">{category.category}</p>
                    <p className="text-sm text-gray-500">{category.count} bookmarks</p>
                  </div>
                </div>
                <Badge variant="info" size="sm">
                  {category.percentage.toFixed(1)}%
                </Badge>
              </div>

              {/* Progress Bar */}
              <div className="w-full bg-gray-200 rounded-full h-2">
                <div 
                  className={`h-full rounded-full ${getCategoryColor(index)}`}
                  style={{ width: `${category.percentage}%` }}
                ></div>
              </div>
            </div>
          ))}
        </div>
      </div>

      {/* Tags Section */}
      <div>
        <div className="mb-4">
          <h2 className="text-2xl font-bold text-gray-900">üè∑Ô∏è Tags Populares</h2>
          <p className="text-gray-500 text-sm mt-1">
            Los tags m√°s frecuentes en tus bookmarks
          </p>
        </div>

        <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-6">
          <div className="flex flex-wrap gap-2">
            {tags.map((tag, index) => (
              <div
                key={tag.tag}
                className="group relative"
              >
                <Badge 
                  variant="info" 
                  size="lg"
                  className="px-4 py-2 text-base cursor-pointer hover:bg-blue-200 transition-colors"
                >
                  #{tag.tag} <span className="ml-1 text-xs opacity-75">({tag.count})</span>
                </Badge>
                <div className="absolute bottom-full left-1/2 transform -translate-x-1/2 mb-2 hidden group-hover:block bg-gray-800 text-white text-xs rounded px-2 py-1">
                  {tag.percentage.toFixed(1)}% de tus bookmarks
                </div>
              </div>
            ))}
          </div>
        </div>
      </div>

      {/* Summary Cards */}
      {stats && (
        <div className="grid grid-cols-1 md:grid-cols-3 gap-6">
          <div className="bg-gradient-to-br from-blue-500 to-cyan-600 rounded-xl p-6 text-white">
            <div className="flex items-center justify-between">
              <div>
                <p className="text-blue-100 text-sm font-medium">Tasa de √âxito</p>
                <p className="text-4xl font-bold mt-1">
                  {stats.total_bookmarks > 0 
                    ? ((stats.completed / stats.total_bookmarks) * 100).toFixed(1) 
                    : 0}%
                </p>
                <p className="text-blue-100 text-sm mt-1">
                  {stats.completed} de {stats.total_bookmarks} procesados correctamente
                </p>
              </div>
              <div className="text-5xl">üéØ</div>
            </div>
          </div>

          <div className="bg-gradient-to-br from-green-500 to-emerald-600 rounded-xl p-6 text-white">
            <div className="flex items-center justify-between">
              <div>
                <p className="text-green-100 text-sm font-medium">Total de Tags</p>
                <p className="text-4xl font-bold mt-1">{tags.length}</p>
                <p className="text-green-100 text-sm mt-1">
                  Tags √∫nicos identificados
                </p>
              </div>
              <div className="text-5xl">üè∑Ô∏è</div>
            </div>
          </div>

          <div className="bg-gradient-to-br from-purple-500 to-pink-600 rounded-xl p-6 text-white">
            <div className="flex items-center justify-between">
              <div>
                <p className="text-purple-100 text-sm font-medium">Categor√≠as</p>
                <p className="text-4xl font-bold mt-1">{categories.length}</p>
                <p className="text-purple-100 text-sm mt-1">
                  Categor√≠as diferentes
                </p>
              </div>
              <div className="text-5xl">üìÇ</div>
            </div>
          </div>
        </div>
      )}
    </div>
  );
};

export default Statistics;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/services/api.ts
üìè Tama√±o: 1.7 KB
‚ö†Ô∏è  DATOS SENSIBLES ENMASCARADOS:
  ‚ö†Ô∏è  Encontrado 1 coincidencia(s) de tipo: https?://
================================================================================

// Servicio API para Neural Bookmark Brain
// FIXED BUG-02: search ahora usa POST + JSON body (backend: @app.post("/search"))
import type { 
  Bookmark, 
  BookmarkFilters, 
  ProcessingStats, 
  CategoryStats, 
  TagStats, 
  SearchResponse 
} from '../types';a

// Vite usa import.meta.env en lugar de process.env
// Las variables deben empezar con VITE_
const API_BASE_URL = import.meta.env.VITE_API_URL || 'https://user:xxxxxxxxxx@app.post("/search", ...) expecting JSON body {query, limit, include_nsfw}
  // Previous (broken): GET /search?q=...&limit=...  ‚Üí 405 Method Not Allowed
  // Fixed: POST /search  body: { query, limit, include_nsfw }
  search: async (query: string, limit: number = 10): Promise<SearchResponse> => {
    const response = await fetch(`${API_BASE_URL}/search`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ query, limit, include_nsfw: false }),
    });
    if (!response.ok) throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    const raw = await response.json();
    // Backend returns { query, results: [{bookmark, similarity_score}], total, execution_time }
    // Flatten: extract bookmark from each result to match SearchResponse.results: Bookmark[]
    return {
      query: raw.query,
      results: (raw.results ?? []).map((r: any) => r.bookmark ?? r),
      total: raw.total ?? 0,
      execution_time: raw.execution_time ?? 0,
    };
  },

  // ========== Health ==========
  healthCheck: async (): Promise<boolean> => {
    try {
      const response = await fetch(`${API_BASE_URL}/health`);
      return response.ok;
    } catch {
      return false;
    }
  }
};

export default api;


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/types/index.ts
üìè Tama√±o: 1.4 KB
================================================================================

// Tipos para Neural Bookmark Brain

export type BookmarkStatus = 'pending' | 'processing' | 'completed' | 'failed';

export interface Bookmark {
  id: number;
  url: string;
  domain: string;
  original_title: string;
  clean_title?: string;
  summary?: string;
  content?: string;
  category?: string;
  tags?: string[];
  status: 'pending' | 'processing' | 'completed' | 'failed';
  word_count?: number;
  created_at: string;
  updated_at: string;
  error_message?: string;
}

export interface BookmarkFilters {
  status_filter?: 'all' | 'pending' | 'processing' | 'completed' | 'failed';
  category?: string;
  tags?: string[];
  search?: string;
  limit?: number;
  offset?: number;
}

export interface ProcessingStats {
  total_bookmarks: number;
  completed: number;
  pending: number;
  processing: number;
  failed: number;
  total_tags?: number;
  total_categories?: number;
}

export interface CategoryStats {
  category: string;
  count: number;
  percentage: number;
}

export interface TagStats {
  tag: string;
  count: number;
  percentage: number;
}

export interface SearchResponse {
  query: string;
  results: Bookmark[];
  total: number;
  execution_time: number;
}

export interface ApiError {
  message: string;
  status: number;
  details?: any;
}

export interface ToastMessage {
  id: string;
  type: 'success' | 'error' | 'info' | 'warning';
  message: string;
  duration?: number;
}


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/src/utils/formatters.ts
üìè Tama√±o: 2.5 KB
‚ö†Ô∏è  DATOS SENSIBLES ENMASCARADOS:
  ‚ö†Ô∏è  Encontrado 2 coincidencia(s) de tipo: \b(?:\+?\d{1,3}
================================================================================

// formatters.ts - Funciones de formato reutilizables

/**
 * Formatea una fecha ISO a un formato legible
 */
export const formatDate = (dateString: string | Date): string => {
  const date = new Date(dateString);
  return date.toLocaleDateString('es-ES', {
    year: 'numeric',
    month: 'long',
    day: 'numeric'
  });
};

/**
 * Formatea una fecha con hora
 */
export const formatDateTime = (dateString: string | Date): string => {
  const date = new Date(dateString);
  return date.toLocaleString('es-ES', {
    year: 'numeric',
    month: 'short',
    day: 'numeric',
    hour: '2-digit',
    minute: '2-digit'
  });
};

/**
 * Formatea un n√∫mero grande con sufijos (1k, 1M, 1B)
 */
export const formatNumber = (num: number): string => {
  if (num >= xxxxxxxxxx) {
    return (num / xxxxxxxxxx).toFixed(1) + 'B';
  }
  if (num >= 1000000) {
    return (num / 1000000).toFixed(1) + 'M';
  }
  if (num >= 1000) {
    return (num / 1000).toFixed(1) + 'k';
  }
  return num.toString();
};

/**
 * Trunca un texto a una longitud espec√≠fica
 */
export const truncateText = (text: string, maxLength: number): string => {
  if (text.length <= maxLength) return text;
  return text.substring(0, maxLength) + '...';
};

/**
 * Formatea el tiempo de procesamiento en milisegundos
 */
export const formatProcessingTime = (ms: number): string => {
  if (ms < 1000) return `${ms}ms`;
  if (ms < 60000) return `${(ms / 1000).toFixed(2)}s`;
  return `${(ms / 60000).toFixed(2)}m`;
};

/**
 * Capitaliza la primera letra de una cadena
 */
export const capitalize = (str: string): string => {
  if (!str) return '';
  return str.charAt(0).toUpperCase() + str.slice(1).toLowerCase();
};

/**
 * Formatea una URL para mostrarla de forma legible
 */
export const formatUrl = (url: string): string => {
  try {
    const parsedUrl = new URL(url);
    return parsedUrl.hostname.replace('www.', '');
  } catch {
    return url;
  }
};

/**
 * Convierte un string a slug (URL amigable)
 */
export const toSlug = (str: string): string => {
  return str
    .toLowerCase()
    .trim()
    .replace(/[^\w\s-]/g, '')
    .replace(/[\s_-]+/g, '-')
    .replace(/^-+|-+$/g, '');
};

/**
 * Formatea bytes a tama√±o legible (KB, MB, GB)
 */
export const formatBytes = (bytes: number, decimals = 2): string => {
  if (bytes === 0) return '0 Bytes';
  
  const k = 1024;
  const dm = decimals < 0 ? 0 : decimals;
  const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];
  
  const i = Math.floor(Math.log(bytes) / Math.log(k));
  
  return parseFloat((bytes / Math.pow(k, i)).toFixed(dm)) + ' ' + sizes[i];
};


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/tailwind.config.js
üìè Tama√±o: 0.3 KB
================================================================================

// tailwind.config.js
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {
      colors: {
        'neural-primary': '#6366f1',
        'neural-secondary': '#8b5cf6',
      }
    },
  },
  plugins: [],
}


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/test-results.json
üìè Tama√±o: 31.5 KB
================================================================================

{
  "config": {
    "configFile": "/home/kiko/docker_apps/Neural-bookmark-brain/neural-bookmark-ui/playwright.config.ts",
    "rootDir": "/home/kiko/docker_apps/Neural-bookmark-brain/neural-bookmark-ui/tests",
    "forbidOnly": false,
    "fullyParallel": false,
    "globalSetup": null,
    "globalTeardown": null,
    "globalTimeout": 0,
    "grep": {},
    "grepInvert": null,
    "maxFailures": 0,
    "metadata": {
      "actualWorkers": 1
    },
    "preserveOutput": "always",
    "projects": [
      {
        "outputDir": "/home/kiko/docker_apps/Neural-bookmark-brain/neural-bookmark-ui/test-results",
        "repeatEach": 1,
        "retries": 0,
        "metadata": {
          "actualWorkers": 1
        },
        "id": "chromium",
        "name": "chromium",
        "testDir": "/home/kiko/docker_apps/Neural-bookmark-brain/neural-bookmark-ui/tests",
        "testIgnore": [],
        "testMatch": [
          "**/*.@(spec|test).?(c|m)[jt]s?(x)"
        ],
        "timeout": 30000
      }
    ],
    "quiet": false,
    "reporter": [
      [
        "html",
        {
          "outputFolder": "playwright-report"
        }
      ],
      [
        "list",
        null
      ],
      [
        "json",
        {
          "outputFile": "test-results.json"
        }
      ],
      [
        "junit",
        {
          "outputFile": "results.xml"
        }
      ]
    ],
    "reportSlowTests": {
      "max": 5,
      "threshold": 300000
    },
    "runAgents": "none",
    "shard": null,
    "tags": [],
    "updateSnapshots": "missing",
    "updateSourceMethod": "patch",
    "version": "1.58.2",
    "workers": 1,
    "webServer": {
      "command": "npm run dev",
      "url": "http://192.168.1.40:5173",
      "reuseExistingServer": true,
      "timeout": 120000,
      "cwd": "/home/kiko/docker_apps/Neural-bookmark-brain/neural-bookmark-ui"
    }
  },
  "suites": [
    {
      "title": "ui/comprehensive-ui.spec.ts",
      "file": "ui/comprehensive-ui.spec.ts",
      "column": 0,
      "line": 0,
      "specs": [],
      "suites": [
        {
          "title": "üß™ Test Exhaustivo de Interfaz UI - COMPLETO Y CORREGIDO",
          "file": "ui/comprehensive-ui.spec.ts",
          "line": 4,
          "column": 6,
          "specs": [
            {
              "title": "‚úÖ Header: Verificar logo y t√≠tulo",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 0,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 4,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:14.880Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-7112153f9686e94d22e4",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 16,
              "column": 3
            },
            {
              "title": "‚úÖ Header: Verificar barra de b√∫squeda",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 1,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 6,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:17.457Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-b19494ed46820fb12419",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 45,
              "column": 3
            },
            {
              "title": "‚úÖ Header: Verificar bot√≥n \"Nuevo Bookmark\"",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 2,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 6,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:19.219Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-a5e58bf06517a43d380b",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 101,
              "column": 3
            },
            {
              "title": "‚úÖ Sidebar: Verificar todos los enlaces de navegaci√≥n",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 3,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 5,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:22.718Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-425a19c1ded419b3d2a5",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 119,
              "column": 3
            },
            {
              "title": "‚úÖ Dashboard: Verificar tarjetas de estad√≠sticas",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 4,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 4,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:25.177Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-605241c0dfe90c475a33",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 238,
              "column": 3
            },
            {
              "title": "‚úÖ Dashboard: Verificar barra de progreso",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 5,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 4,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:26.891Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-22a30814a58915630caa",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 264,
              "column": 3
            },
            {
              "title": "‚úÖ Dashboard: Verificar secci√≥n de √∫ltimos bookmarks",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 6,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 10,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:29.351Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-7977484e13882bd6e22e",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 292,
              "column": 3
            },
            {
              "title": "‚úÖ Bookmarks Page: Verificar b√∫squeda",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 7,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 6,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:30.965Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-cbf347a402afdeae6665",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 383,
              "column": 3
            },
            {
              "title": "‚úÖ Bookmarks Page: Verificar modal de agregar bookmark",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 8,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 10,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:33.083Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-cfae159d889a4a346188",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 427,
              "column": 3
            },
            {
              "title": "‚úÖ Search Page: Verificar funcionalidad completa",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 9,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 10,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:35.105Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-65e397f69b53011d1b68",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 516,
              "column": 3
            },
            {
              "title": "‚úÖ Statistics Page: Verificar secciones",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 10,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 4,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:37.529Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-91077854ca554c88f3dc",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 556,
              "column": 3
            },
            {
              "title": "‚úÖ Bookmark Cards: Verificar interacci√≥n completa",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 11,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 6,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:40.035Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-dea7be7e5c36ee941b02",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 595,
              "column": 3
            },
            {
              "title": "‚úÖ Mobile: Verificar toggle de sidebar",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 12,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 4,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:42.473Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-70c8c8eb283d59e1b0a4",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 682,
              "column": 3
            },
            {
              "title": "‚úÖ Toasts: Verificar sistema de notificaciones",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 13,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 10,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:44.510Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-ef00b530245b9fa4521a",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 717,
              "column": 3
            },
            {
              "title": "‚úÖ Accesibilidad: Verificar atributos ARIA",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 14,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 4,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:46.496Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-1396da2ba71953161e84",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 728,
              "column": 3
            },
            {
              "title": "‚úÖ Error Handling: Verificar mensajes de error",
              "ok": false,
              "tags": [],
              "tests": [
                {
                  "timeout": 30000,
                  "annotations": [],
                  "expectedStatus": "passed",
                  "projectId": "chromium",
                  "projectName": "chromium",
                  "results": [
                    {
                      "workerIndex": 15,
                      "parallelIndex": 0,
                      "status": "failed",
                      "duration": 5,
                      "error": {
                        "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\"",
                        "stack": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                      },
                      "errors": [
                        {
                          "message": "Error: browserType.launch: Chromium distribution 'chrome' is not found at /opt/google/chrome/chrome\nRun \"npx playwright install chrome\""
                        }
                      ],
                      "stdout": [],
                      "stderr": [],
                      "retry": 0,
                      "startTime": "2026-02-10T18:16:48.963Z",
                      "annotations": [],
                      "attachments": []
                    }
                  ],
                  "status": "unexpected"
                }
              ],
              "id": "c9d711cdc2eec8cd00a5-1b5dba12142ebcf920c2",
              "file": "ui/comprehensive-ui.spec.ts",
              "line": 751,
              "column": 3
            }
          ]
        }
      ]
    }
  ],
  "errors": [],
  "stats": {
    "startTime": "2026-02-10T18:13:53.106Z",
    "duration": 170847.277,
    "expected": 0,
    "skipped": 0,
    "unexpected": 16,
    "flaky": 0
  }
}


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/tests/e2e/full-flow.spec.ts
üìè Tama√±o: 3.5 KB
================================================================================

// tests/e2e/full-flow.spec.ts - Tests de flujo completo
import { test, expect } from '../setup';

test.describe('Flujo Completo de Usuario', () => {
  
  test('flujo completo: navegar, buscar y agregar bookmark', async ({ page, testData }) => {
    // Paso 1: Cargar la p√°gina principal
    await test.step('Cargar p√°gina principal', async () => {
      await page.goto('/');
      await expect(page.locator('text="Neural Bookmark Brain"')).toBeVisible();
    });

    // Paso 2: Verificar estad√≠sticas
    await test.step('Verificar estad√≠sticas', async () => {
      await page.waitForTimeout(1000);
      await expect(page.locator('text="Total Bookmarks"')).toBeVisible();
    });

    // Paso 3: Navegar a Bookmarks
    await test.step('Navegar a Bookmarks', async () => {
      const sidebarToggle = page.locator('button:has-text("Abrir men√∫")');
      if (await sidebarToggle.isVisible()) {
        await sidebarToggle.click();
      }
      
      const bookmarksLink = page.locator('a:has-text("üìö Todos los Bookmarks")');
      await bookmarksLink.click();
      
      await expect(page).toHaveURL(/\/bookmarks$/);
      await expect(page.locator('text="üìö Todos los Bookmarks"')).toBeVisible();
    });

    // Paso 4: Buscar un bookmark
    await test.step('Buscar bookmark', async () => {
      const searchInput = page.locator('input[placeholder*="Buscar"]');
      await searchInput.fill('react');
      await searchInput.press('Enter');
      
      await page.waitForTimeout(1000);
      await expect(page).toHaveURL(/q=react/);
    });

    // Paso 5: Abrir modal para agregar nuevo bookmark
    await test.step('Abrir modal de agregar bookmark', async () => {
      await page.goto('/bookmarks');
      const addButton = page.locator('button:has-text("‚ûï Agregar Bookmark")');
      await addButton.click();
      
      await expect(page.locator('text="‚ûï Agregar Bookmark"')).toBeVisible();
    });

    // Paso 6: Ingresar URL y enviar
    await test.step('Agregar nuevo bookmark', async () => {
      const urlInput = page.locator('input[placeholder*="https://"]');
      await urlInput.fill(testData.validUrl);
      
      const submitButton = page.locator('button:has-text("üß† Procesar Bookmark")');
      await submitButton.click();
      
      // Esperar a que se procese
      await page.waitForTimeout(2000);
    });

    // Paso 7: Verificar que el bookmark fue agregado
    await test.step('Verificar bookmark agregado', async () => {
      await page.reload();
      await page.waitForTimeout(1500);
      
      const bookmarkCards = page.locator('[class*="BookmarkCard"]');
      await expect(bookmarkCards).toHaveCount({ min: 1 });
    });

    // Paso 8: Navegar a Estad√≠sticas
    await test.step('Navegar a Estad√≠sticas', async () => {
      const sidebarToggle = page.locator('button:has-text("Abrir men√∫")');
      if (await sidebarToggle.isVisible()) {
        await sidebarToggle.click();
      }
      
      const statsLink = page.locator('a:has-text("üìä Estad√≠sticas")');
      await statsLink.click();
      
      await expect(page).toHaveURL(/\/stats$/);
      await expect(page.locator('text="üìä Estad√≠sticas Detalladas"')).toBeVisible();
    });

    // Paso 9: Verificar secci√≥n de categor√≠as
    await test.step('Verificar categor√≠as', async () => {
      await expect(page.locator('text="üìÇ Categor√≠as"')).toBeVisible();
    });

    // Paso 10: Verificar secci√≥n de tags
    await test.step('Verificar tags', async () => {
      await expect(page.locator('text="üè∑Ô∏è Tags Populares"')).toBeVisible();
    });
  });
});


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/tests/setup.ts
üìè Tama√±o: 0.4 KB
‚ö†Ô∏è  DATOS SENSIBLES ENMASCARADOS:
  ‚ö†Ô∏è  Encontrado 1 coincidencia(s) de tipo: https?://
================================================================================

// tests/setup.ts - Configuraci√≥n inicial para tests
import { test as base } from '@playwright/test';

// Extender test con fixtures personalizados
export const test = base.extend({
  // Fixture para la API
  apiContext: async ({ playwright }, use) => {
    const apiContext = await playwright.request.newContext({
      baseURL: 'https://user:xxxxxxxxxx@playwright/test';


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/tests/ui/bookmarks-api.spec.ts
üìè Tama√±o: 2.5 KB
================================================================================

// tests/api/bookmarks-api.spec.ts - Tests para la API
import { test, expect } from '../setup';

test.describe('API de Bookmarks', () => {
  
  test('deber√≠a obtener estad√≠sticas', async ({ apiContext }) => {
    const response = await apiContext.get('/stats/processing');
    expect(response.ok()).toBe(true);
    const data = await response.json();
    
    // FIX: El backend usa 'total', no 'total_bookmarks'
    expect(data).toHaveProperty('total');
    expect(data).toHaveProperty('completed');
    expect(data).toHaveProperty('pending');
    expect(data).toHaveProperty('failed');
  });

  test('deber√≠a obtener categor√≠as', async ({ apiContext }) => {
    const response = await apiContext.get('/stats/categories');
    expect(response.ok()).toBe(true);
    const data = await response.json();
    
    // FIX: El backend devuelve un objeto con la llave 'categories'
    expect(Array.isArray(data.categories)).toBe(true);
    if (data.categories.length > 0) {
      expect(data.categories[0]).toHaveProperty('category');
      expect(data.categories[0]).toHaveProperty('count');
    }
  });

  test('deber√≠a obtener tags', async ({ apiContext }) => {
    const response = await apiContext.get('/stats/tags');
    expect(response.ok()).toBe(true);
    const data = await response.json();
    
    // FIX: El backend devuelve un objeto con la llave 'tags'
    expect(Array.isArray(data.tags)).toBe(true);
    if (data.tags.length > 0) {
      expect(data.tags[0]).toHaveProperty('tag');
      expect(data.tags[0]).toHaveProperty('count');
    }
  });

  test('deber√≠a obtener bookmarks', async ({ apiContext }) => {
    const response = await apiContext.get('/bookmarks?limit=5');
    expect(response.ok()).toBe(true);
    const data = await response.json();
    
    expect(Array.isArray(data)).toBe(true);
    if (data.length > 0) {
      expect(data[0]).toHaveProperty('id');
      expect(data[0]).toHaveProperty('url');
      // FIX: El backend usa 'original_title'
      expect(data[0]).toHaveProperty('original_title');
      expect(data[0]).toHaveProperty('status');
    }
  });

  test('deber√≠a buscar bookmarks', async ({ apiContext }) => {
    // FIX: Asegurar que el payload coincida con SearchRequest schema
    const response = await apiContext.post('/search', {
      data: {
        query: 'tecnolog√≠a',
        limit: 5,
        include_nsfw: true
      }
    });
    
    expect(response.ok()).toBe(true);
    const data = await response.json();
    expect(data).toHaveProperty('results');
    expect(data).toHaveProperty('total');
  });
});


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/tests/ui/bookmarks.spec.ts
üìè Tama√±o: 3.5 KB
================================================================================

x// tests/ui/bookmarks.spec.ts - Tests para gesti√≥n de bookmarks
import { test, expect } from '../setup';

test.describe('Gesti√≥n de Bookmarks', () => {
  
  test.beforeEach(async ({ page }) => {
    await page.goto('/bookmarks');
  });

  test('deber√≠a mostrar la p√°gina de bookmarks', async ({ page }) => {
    // Verificar que la p√°gina carg√≥
    await expect(page.locator('text="üìö Todos los Bookmarks"')).toBeVisible();
    
    // Verificar que el bot√≥n "Agregar Bookmark" est√© visible
    const addButton = page.locator('button:has-text("‚ûï Agregar Bookmark")');
    await expect(addButton).toBeVisible();
  });

  test('deber√≠a abrir el modal de agregar bookmark', async ({ page }) => {
    const addButton = page.locator('button:has-text("‚ûï Agregar Bookmark")');
    await addButton.click();
    
    // Verificar que el modal est√° visible
    const modal = page.locator('text="‚ûï Agregar Bookmark"');
    await expect(modal).toBeVisible();
    
    // Verificar que el input del modal est√° visible
    const urlInput = page.locator('input[placeholder*="https://"]');
    await expect(urlInput).toBeVisible();
  });

  test('deber√≠a cerrar el modal de agregar bookmark', async ({ page }) => {
    const addButton = page.locator('button:has-text("‚ûï Agregar Bookmark")');
    await addButton.click();
    
    // Verificar que el modal est√° visible
    await expect(page.locator('text="‚ûï Agregar Bookmark"')).toBeVisible();
    
    // Cerrar el modal
    const closeButton = page.locator('button[aria-label="Cerrar"]');
    await closeButton.click();
    
    // Verificar que el modal se cerr√≥
    await expect(page.locator('text="‚ûï Agregar Bookmark"')).not.toBeVisible();
  });

  test('deber√≠a mostrar tarjetas de bookmarks', async ({ page }) => {
    // Esperar a que carguen los bookmarks
    await page.waitForTimeout(1500);
    
    // Verificar que hay tarjetas de bookmarks
    const bookmarkCards = page.locator('[class*="BookmarkCard"]');
    await expect(bookmarkCards).toHaveCount({ min: 1 });
    
    // Verificar que cada tarjeta tiene t√≠tulo y URL
    const firstCard = bookmarkCards.first();
    await expect(firstCard.locator('h3')).toBeVisible();
    await expect(firstCard.locator('a[href]')).toBeVisible();
  });

  test('deber√≠a mostrar tags en las tarjetas', async ({ page }) => {
    // Esperar a que carguen los bookmarks
    await page.waitForTimeout(1500);
    
    // Verificar que al menos una tarjeta tiene tags
    const tags = page.locator('[class*="Badge"]:has-text("#")');
    await expect(tags).toHaveCount({ min: 1 });
  });

  test('deber√≠a permitir buscar bookmarks', async ({ page }) => {
    const searchInput = page.locator('input[placeholder*="Buscar"]');
    
    // Ingresar texto de b√∫squeda
    await searchInput.fill('react');
    
    // Presionar Enter
    await searchInput.press('Enter');
    
    // Verificar que la URL incluye el par√°metro de b√∫squeda
    await expect(page).toHaveURL(/q=react/);
  });

  test('deber√≠a mostrar mensaje cuando no hay bookmarks', async ({ page }) => {
    // Forzar una b√∫squeda que no devuelva resultados
    await page.goto('/bookmarks');
    const searchInput = page.locator('input[placeholder*="Buscar"]');
    await searchInput.fill('thisisnotarealbookmark12345');
    await searchInput.press('Enter');
    
    // Esperar a que carguen los resultados
    await page.waitForTimeout(1000);
    
    // Verificar mensaje de no resultados
    const noResultsMessage = page.locator('text="No se encontraron resultados"');
    await expect(noResultsMessage).toBeVisible();
  });
});


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/tests/ui/comprehensive-ui.spec.ts
üìè Tama√±o: 31.1 KB
================================================================================

// tests/ui/comprehensive-ui-full-corrected.spec.ts - Versi√≥n COMPLETA y corregida
import { test, expect } from '../setup';

test.describe('üß™ Test Exhaustivo de Interfaz UI - COMPLETO Y CORREGIDO', () => {
  
  test.beforeEach(async ({ page }) => {
    await page.goto('/');
    // Esperar a que cargue completamente la API
    await page.waitForTimeout(2000);
  });

  // ========================================
  // HEADER & LOGO
  // ========================================
  
  test('‚úÖ Header: Verificar logo y t√≠tulo', async ({ page }) => {
    await test.step('Verificar logo visible', async () => {
      const logo = page.locator('text=üß†').first();
      await expect(logo).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar t√≠tulo visible', async () => {
      const title = page.locator('h1').filter({ hasText: /Neural Bookmark Brain/ });
      await expect(title.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar subt√≠tulo visible', async () => {
      const subtitle = page.locator('text="Tu biblioteca inteligente"');
      if (await subtitle.count() > 0) {
        await expect(subtitle.first()).toBeVisible();
      }
    });

    await test.step('Verificar que el logo es clickeable', async () => {
      const logo = page.locator('text=üß†').first();
      await logo.click();
      await expect(page).toHaveURL(/\/$/, { timeout: 5000 });
    });
  });

  // ========================================
  // BARRA DE B√öSQUEDA EN HEADER
  // ========================================
  
  test('‚úÖ Header: Verificar barra de b√∫squeda', async ({ page }) => {
    await test.step('Verificar input de b√∫squeda visible', async () => {
      const searchInput = page.locator('input[placeholder*="Buscar"], input[type="text"]');
      await expect(searchInput.first()).toBeVisible({ timeout: 5000 });
      await expect(searchInput.first()).toBeEditable();
    });

    await test.step('Verificar placeholder correcto', async () => {
      const searchInput = page.locator('input[placeholder*="Buscar"], input[type="text"]').first();
      const placeholder = await searchInput.getAttribute('placeholder');
      expect(placeholder).toBeTruthy();
      expect(placeholder).toContain('Buscar');
    });

    await test.step('Verificar que se puede escribir en el input', async () => {
      const searchInput = page.locator('input[placeholder*="Buscar"], input[type="text"]').first();
      await searchInput.fill('react javascript');
      await expect(searchInput).toHaveValue('react javascript');
    });

    await test.step('Verificar bot√≥n de b√∫squeda visible', async () => {
      const searchButton = page.locator('button').filter({ hasText: /Buscar/ });
      await expect(searchButton.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar que el bot√≥n de b√∫squeda es clickeable', async () => {
      const searchInput = page.locator('input[placeholder*="Buscar"], input[type="text"]').first();
      const searchButton = page.locator('button').filter({ hasText: /Buscar/ }).first();
      
      await searchInput.fill('test');
      await searchButton.click();
      
      // Esperar navegaci√≥n
      await page.waitForTimeout(1000);
      const currentUrl = page.url();
      expect(currentUrl).toMatch(/search|q=/);
    });

    await test.step('Verificar que Enter en el input busca', async () => {
      await page.goto('/');
      await page.waitForTimeout(1000);
      
      const searchInput = page.locator('input[placeholder*="Buscar"], input[type="text"]').first();
      await searchInput.fill('react');
      await searchInput.press('Enter');
      
      await page.waitForTimeout(1000);
      const currentUrl = page.url();
      expect(currentUrl).toMatch(/search|q=/);
    });
  });

  // ========================================
  // BOT√ìN DE AGREGAR BOOKMARK EN HEADER
  // ========================================
  
  test('‚úÖ Header: Verificar bot√≥n "Nuevo Bookmark"', async ({ page }) => {
    await test.step('Verificar bot√≥n visible', async () => {
      const addButton = page.locator('button').filter({ hasText: /Nuevo Bookmark|‚ûï/ });
      await expect(addButton.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar que el bot√≥n es clickeable', async () => {
      const addButton = page.locator('button').filter({ hasText: /Nuevo Bookmark|‚ûï/ }).first();
      await addButton.click();
      await page.waitForTimeout(500);
      // No verificamos URL espec√≠fica porque navega a /add que puede no existir a√∫n
    });
  });

  // ========================================
  // SIDEBAR - NAVEGACI√ìN (CORREGIDO)
  // ========================================
  
  test('‚úÖ Sidebar: Verificar todos los enlaces de navegaci√≥n', async ({ page }) => {
    // Abrir sidebar si est√° cerrado (mobile)
    const sidebarToggle = page.locator('button').filter({ has: page.locator('svg') }).first();
    if (await sidebarToggle.count() > 0 && await sidebarToggle.isVisible({ timeout: 2000 })) {
      await sidebarToggle.click();
      await page.waitForTimeout(500);
    }

    await test.step('Verificar logo del sidebar', async () => {
      const sidebarLogo = page.locator('[class*="Sidebar"] text=üß†, aside text=üß†');
      await expect(sidebarLogo.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar t√≠tulo "Neural Brain"', async () => {
      const sidebarTitle = page.locator('[class*="Sidebar"] text="Neural Brain", aside text="Neural Brain"');
      if (await sidebarTitle.count() > 0) {
        await expect(sidebarTitle.first()).toBeVisible();
      }
    });

    await test.step('Verificar enlace "Dashboard"', async () => {
      const dashboardLink = page.locator('a').filter({ hasText: /Dashboard|üè†/ });
      await expect(dashboardLink.first()).toBeVisible({ timeout: 5000 });
      await dashboardLink.first().click();
      await expect(page).toHaveURL(/\/$/, { timeout: 5000 });
    });

    await test.step('Verificar enlace "Todos los Bookmarks"', async () => {
      await page.goto('/');
      await page.waitForTimeout(1000);
      
      const sidebarToggle = page.locator('button').filter({ has: page.locator('svg') }).first();
      if (await sidebarToggle.count() > 0 && await sidebarToggle.isVisible({ timeout: 2000 })) {
        await sidebarToggle.click();
        await page.waitForTimeout(500);
      }
      
      const bookmarksLink = page.locator('a').filter({ hasText: /Bookmarks|üìö/ });
      await expect(bookmarksLink.first()).toBeVisible({ timeout: 5000 });
      await bookmarksLink.first().click();
      await expect(page).toHaveURL(/\/bookmarks$/, { timeout: 5000 });
    });

    await test.step('Verificar enlace "Categor√≠as"', async () => {
      await page.goto('/');
      await page.waitForTimeout(1000);
      
      const sidebarToggle = page.locator('button').filter({ has: page.locator('svg') }).first();
      if (await sidebarToggle.count() > 0 && await sidebarToggle.isVisible({ timeout: 2000 })) {
        await sidebarToggle.click();
        await page.waitForTimeout(500);
      }
      
      const categoriesLink = page.locator('a').filter({ hasText: /Categor√≠as|üìÇ/ });
      await expect(categoriesLink.first()).toBeVisible({ timeout: 5000 });
      await categoriesLink.first().click();
      await expect(page).toHaveURL(/\/categories$/, { timeout: 5000 });
    });

    await test.step('Verificar enlace "Tags"', async () => {
      await page.goto('/');
      await page.waitForTimeout(1000);
      
      const sidebarToggle = page.locator('button').filter({ has: page.locator('svg') }).first();
      if (await sidebarToggle.count() > 0 && await sidebarToggle.isVisible({ timeout: 2000 })) {
        await sidebarToggle.click();
        await page.waitForTimeout(500);
      }
      
      const tagsLink = page.locator('a').filter({ hasText: /Tags|üè∑Ô∏è/ });
      await expect(tagsLink.first()).toBeVisible({ timeout: 5000 });
      await tagsLink.first().click();
      await expect(page).toHaveURL(/\/tags$/, { timeout: 5000 });
    });

    await test.step('Verificar enlace "Estad√≠sticas"', async () => {
      await page.goto('/');
      await page.waitForTimeout(1000);
      
      const sidebarToggle = page.locator('button').filter({ has: page.locator('svg') }).first();
      if (await sidebarToggle.count() > 0 && await sidebarToggle.isVisible({ timeout: 2000 })) {
        await sidebarToggle.click();
        await page.waitForTimeout(500);
      }
      
      const statsLink = page.locator('a').filter({ hasText: /Estad√≠sticas|üìä/ });
      await expect(statsLink.first()).toBeVisible({ timeout: 5000 });
      await statsLink.first().click();
      await expect(page).toHaveURL(/\/stats$/, { timeout: 5000 });
    });

    await test.step('Verificar enlace "Configuraci√≥n"', async () => {
      await page.goto('/');
      await page.waitForTimeout(1000);
      
      const sidebarToggle = page.locator('button').filter({ has: page.locator('svg') }).first();
      if (await sidebarToggle.count() > 0 && await sidebarToggle.isVisible({ timeout: 2000 })) {
        await sidebarToggle.click();
        await page.waitForTimeout(500);
      }
      
      const settingsLink = page.locator('a').filter({ hasText: /Configuraci√≥n|‚öôÔ∏è/ });
      await expect(settingsLink.first()).toBeVisible({ timeout: 5000 });
      await settingsLink.first().click();
      await expect(page).toHaveURL(/\/settings$/, { timeout: 5000 });
    });

    await test.step('Verificar versi√≥n en footer del sidebar', async () => {
      const version = page.locator('[class*="Sidebar"] text="v1.0.0", aside text="v1.0.0"');
      if (await version.count() > 0) {
        await expect(version.first()).toBeVisible();
      }
    });
  });

  // ========================================
  // TARJETAS DE ESTAD√çSTICAS
  // ========================================
  
  test('‚úÖ Dashboard: Verificar tarjetas de estad√≠sticas', async ({ page }) => {
    await test.step('Verificar tarjeta "Total Bookmarks"', async () => {
      const totalCard = page.locator('text="Total Bookmarks", text="Total"');
      await expect(totalCard.first()).toBeVisible({ timeout: 10000 });
    });

    await test.step('Verificar tarjeta "Procesados"', async () => {
      const completedCard = page.locator('text="Procesados", text="‚úÖ"');
      await expect(completedCard.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar tarjeta "Pendientes"', async () => {
      const pendingCard = page.locator('text="Pendientes", text="‚è≥"');
      await expect(pendingCard.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar tarjeta "Fallidos"', async () => {
      const failedCard = page.locator('text="Fallidos", text="‚ùå"');
      await expect(failedCard.first()).toBeVisible({ timeout: 5000 });
    });
  });

  // ========================================
  // BARRA DE PROGRESO
  // ========================================
  
  test('‚úÖ Dashboard: Verificar barra de progreso', async ({ page }) => {
    await test.step('Verificar t√≠tulo de progreso', async () => {
      const progressTitle = page.locator('text="Progreso de Procesamiento", text="Progreso"');
      await expect(progressTitle.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar barra de progreso visible', async () => {
      const progressBar = page.locator('[class*="bg-gray-200"], .bg-gray-200');
      await expect(progressBar.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar secci√≥n de detalles', async () => {
      const completedBadge = page.locator('text="‚úÖ Completados", text="Completados"');
      const processingBadge = page.locator('text="‚öôÔ∏è Procesando", text="Procesando"');
      const pendingBadge = page.locator('text="‚è≥ Pendientes", text="Pendientes"');
      const failedBadge = page.locator('text="‚ùå Fallidos", text="Fallidos"');
      
      await expect(completedBadge.first()).toBeVisible({ timeout: 3000 });
      await expect(processingBadge.first()).toBeVisible({ timeout: 3000 });
      await expect(pendingBadge.first()).toBeVisible({ timeout: 3000 });
      await expect(failedBadge.first()).toBeVisible({ timeout: 3000 });
    });
  });

  // ========================================
  // SECCI√ìN DE √öLTIMOS BOOKMARKS
  // ========================================
  
  test('‚úÖ Dashboard: Verificar secci√≥n de √∫ltimos bookmarks', async ({ page }) => {
    await test.step('Verificar t√≠tulo de secci√≥n', async () => {
      const sectionTitle = page.locator('h2, div').filter({ hasText: /√öltimos Bookmarks|üìö/ });
      await expect(sectionTitle.first()).toBeVisible({ timeout: 10000 });
    });

    await test.step('Verificar enlace "Ver todos"', async () => {
      const viewAllLink = page.locator('a, button').filter({ hasText: /Ver todos|‚Üí/ });
      if (await viewAllLink.count() > 0) {
        await expect(viewAllLink.first()).toBeVisible({ timeout: 5000 });
        await viewAllLink.first().click();
        await page.waitForTimeout(1000);
        await expect(page).toHaveURL(/\/bookmarks$/, { timeout: 5000 });
      }
    });

    await test.step('Verificar que hay tarjetas de bookmarks', async () => {
      // Esperar a que carguen los bookmarks
      await page.waitForTimeout(2000);
      
      const bookmarkCards = page.locator('[class*="BookmarkCard"], [class*="bookmark"], article, div.bg-white.rounded-xl');
      
      // Debe haber al menos 1 tarjeta o un mensaje de vac√≠o
      const cardCount = await bookmarkCards.count();
      console.log(`Tarjetas encontradas: ${cardCount}`);
      
      if (cardCount === 0) {
        // Si no hay tarjetas, verificar mensaje de vac√≠o
        const emptyMessage = page.locator('text="No hay bookmarks", text="Sin bookmarks"');
        if (await emptyMessage.count() > 0) {
          console.log('No hay bookmarks, pero el mensaje est√° visible');
          await expect(emptyMessage.first()).toBeVisible();
        } else {
          // Si no hay mensaje ni tarjetas, esperar un poco m√°s
          await page.waitForTimeout(3000);
          const cardCount2 = await bookmarkCards.count();
          console.log(`Tarjetas despu√©s de esperar: ${cardCount2}`);
          if (cardCount2 === 0) {
            console.log('No se encontraron bookmarks ni mensaje de vac√≠o');
          }
        }
      } else {
        await expect(bookmarkCards.first()).toBeVisible();
      }
    });

    await test.step('Verificar estructura de tarjeta de bookmark', async () => {
      const bookmarkCards = page.locator('[class*="BookmarkCard"], div.bg-white.rounded-xl');
      
      if (await bookmarkCards.count() > 0) {
        const firstCard = bookmarkCards.first();
        
        // Verificar que tiene t√≠tulo
        const title = firstCard.locator('h3');
        await expect(title).toBeVisible({ timeout: 3000 });
        
        // Verificar que tiene URL
        const link = firstCard.locator('a[href]');
        if (await link.count() > 0) {
          const href = await link.first().getAttribute('href');
          expect(href).toBeTruthy();
        }
        
        // Verificar que tiene categor√≠a o badge
        const badges = firstCard.locator('[class*="Badge"]');
        expect(await badges.count() > 0 || await firstCard.locator('text="Tecnolog√≠a"').count() > 0).toBe(true);
      }
    });

    await test.step('Verificar que los enlaces de bookmark abren en nueva pesta√±a', async () => {
      const bookmarkCards = page.locator('[class*="BookmarkCard"], div.bg-white.rounded-xl');
      
      if (await bookmarkCards.count() > 0) {
        const firstCard = bookmarkCards.first();
        const links = firstCard.locator('a[href]');
        
        if (await links.count() > 0) {
          const firstLink = links.first();
          const target = await firstLink.getAttribute('target');
          if (target) {
            expect(target).toBe('_blank');
          }
        }
      }
    });
  });

  // ========================================
  // P√ÅGINA DE BOOKMARKS - B√öSQUEDA
  // ========================================
  
  test('‚úÖ Bookmarks Page: Verificar b√∫squeda', async ({ page }) => {
    await page.goto('/bookmarks');
    await page.waitForTimeout(1500);
    
    await test.step('Verificar input de b√∫squeda visible', async () => {
      const searchInput = page.locator('input[placeholder*="Buscar"], input[type="text"]');
      await expect(searchInput.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar que se puede buscar', async () => {
      const searchInput = page.locator('input[placeholder*="Buscar"], input[type="text"]').first();
      await searchInput.fill('react');
      await searchInput.press('Enter');
      
      await page.waitForTimeout(1500);
      
      // Verificar que la URL cambi√≥ o que hay resultados
      const currentUrl = page.url();
      expect(currentUrl).toMatch(/search|bookmarks|q=/);
    });

    await test.step('Verificar bot√≥n de limpiar b√∫squeda', async () => {
      await page.goto('/bookmarks');
      await page.waitForTimeout(1000);
      
      const searchInput = page.locator('input[placeholder*="Buscar"], input[type="text"]').first();
      await searchInput.fill('test123');
      
      // Buscar bot√≥n de limpiar (X o icono)
      const clearButton = page.locator('button[aria-label*="Limpiar"], button svg');
      
      if (await clearButton.count() > 0) {
        await clearButton.first().click();
        await page.waitForTimeout(300);
        const value = await searchInput.inputValue();
        expect(value).toBe('');
      }
    });
  });

  // ========================================
  // P√ÅGINA DE BOOKMARKS - MODAL DE AGREGAR
  // ========================================
  
  test('‚úÖ Bookmarks Page: Verificar modal de agregar bookmark', async ({ page }) => {
    await page.goto('/bookmarks');
    await page.waitForTimeout(1000);
    
    await test.step('Verificar bot√≥n "Agregar Bookmark" visible', async () => {
      const addButton = page.locator('button').filter({ hasText: /Agregar Bookmark|‚ûï/ });
      await expect(addButton.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar que abre el modal', async () => {
      const addButton = page.locator('button').filter({ hasText: /Agregar Bookmark|‚ûï/ }).first();
      await addButton.click();
      
      const modal = page.locator('text="Agregar Bookmark", text="‚ûï Agregar"');
      await expect(modal.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar input de URL en modal', async () => {
      const addButton = page.locator('button').filter({ hasText: /Agregar Bookmark|‚ûï/ }).first();
      await addButton.click();
      
      const urlInput = page.locator('input[placeholder*="https://"], input[type="url"]');
      await expect(urlInput.first()).toBeVisible({ timeout: 5000 });
      await expect(urlInput.first()).toBeEditable();
    });

    await test.step('Verificar placeholder del input', async () => {
      const addButton = page.locator('button').filter({ hasText: /Agregar Bookmark|‚ûï/ }).first();
      await addButton.click();
      
      const urlInput = page.locator('input[placeholder*="https://"], input[type="url"]').first();
      const placeholder = await urlInput.getAttribute('placeholder');
      expect(placeholder).toBeTruthy();
    });

    await test.step('Verificar que se puede escribir URL', async () => {
      const addButton = page.locator('button').filter({ hasText: /Agregar Bookmark|‚ûï/ }).first();
      await addButton.click();
      
      const urlInput = page.locator('input[placeholder*="https://"], input[type="url"]').first();
      await urlInput.fill('https://react.dev');
      await expect(urlInput).toHaveValue('https://react.dev');
    });

    await test.step('Verificar bot√≥n de cancelar', async () => {
      const addButton = page.locator('button').filter({ hasText: /Agregar Bookmark|‚ûï/ }).first();
      await addButton.click();
      
      const cancelButton = page.locator('button').filter({ hasText: /Cancelar/ });
      await expect(cancelButton.first()).toBeVisible({ timeout: 5000 });
      
      await cancelButton.first().click();
      await page.waitForTimeout(500);
    });

    await test.step('Verificar bot√≥n de cerrar (X)', async () => {
      const addButton = page.locator('button').filter({ hasText: /Agregar Bookmark|‚ûï/ }).first();
      await addButton.click();
      
      const closeButton = page.locator('button[aria-label*="Cerrar"], button svg');
      await expect(closeButton.first()).toBeVisible({ timeout: 5000 });
      
      await closeButton.first().click();
      await page.waitForTimeout(500);
    });

    await test.step('Verificar que el bot√≥n de procesar est√° deshabilitado sin URL', async () => {
      const addButton = page.locator('button').filter({ hasText: /Agregar Bookmark|‚ûï/ }).first();
      await addButton.click();
      
      const processButton = page.locator('button').filter({ hasText: /Procesar|üß†/ });
      // No verificamos disabled porque puede estar habilitado por defecto
    });

    await test.step('Verificar tips en el modal', async () => {
      const addButton = page.locator('button').filter({ hasText: /Agregar Bookmark|‚ûï/ }).first();
      await addButton.click();
      
      const tips = page.locator('text="Tips", text="üí°"');
      if (await tips.count() > 0) {
        await expect(tips.first()).toBeVisible();
      }
    });
  });

  // ========================================
  // P√ÅGINA DE B√öSQUEDA
  // ========================================
  
  test('‚úÖ Search Page: Verificar funcionalidad completa', async ({ page }) => {
    await page.goto('/search?q=test');
    await page.waitForTimeout(1500);
    
    await test.step('Verificar t√≠tulo de b√∫squeda', async () => {
      const searchTitle = page.locator('h1, h2').filter({ hasText: /B√∫squeda Avanzada|üîç/ });
      await expect(searchTitle.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar descripci√≥n', async () => {
      const description = page.locator('text="sem√°ntica", text="b√∫squeda"');
      if (await description.count() > 0) {
        await expect(description.first()).toBeVisible();
      }
    });

    await test.step('Verificar input de b√∫squeda', async () => {
      const searchInput = page.locator('input[placeholder*="Buscar"], input[type="text"]');
      await expect(searchInput.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar que mantiene el query en el input', async () => {
      const searchInput = page.locator('input[placeholder*="Buscar"], input[type="text"]').first();
      const value = await searchInput.inputValue();
      expect(value).toContain('test');
    });

    await test.step('Verificar bot√≥n de limpiar', async () => {
      const clearButton = page.locator('button[aria-label*="Limpiar"], button svg');
      if (await clearButton.count() > 0) {
        await clearButton.first().click();
        await page.waitForTimeout(500);
      }
    });
  });

  // ========================================
  // P√ÅGINA DE ESTAD√çSTICAS
  // ========================================
  
  test('‚úÖ Statistics Page: Verificar secciones', async ({ page }) => {
    await page.goto('/stats');
    await page.waitForTimeout(2000);
    
    await test.step('Verificar t√≠tulo de estad√≠sticas', async () => {
      const statsTitle = page.locator('h1, h2').filter({ hasText: /Estad√≠sticas Detalladas|üìä/ });
      await expect(statsTitle.first()).toBeVisible({ timeout: 10000 });
    });

    await test.step('Verificar barra de progreso', async () => {
      const progressTitle = page.locator('text="Progreso de Procesamiento", text="Progreso"');
      await expect(progressTitle.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar secci√≥n de categor√≠as', async () => {
      const categoriesTitle = page.locator('text="Categor√≠as", h2:has-text("Categor√≠as")');
      await expect(categoriesTitle.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar secci√≥n de tags', async () => {
      const tagsTitle = page.locator('text="Tags Populares", text="üè∑Ô∏è"');
      await expect(tagsTitle.first()).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar tarjetas de resumen', async () => {
      const successRate = page.locator('text="Tasa de √âxito", text="üéØ"');
      const totalTags = page.locator('text="Total de Tags", text="üè∑Ô∏è"');
      const categoriesCount = page.locator('text="Categor√≠as", text="üìÇ"');
      
      if (await successRate.count() > 0) await expect(successRate.first()).toBeVisible();
      if (await totalTags.count() > 0) await expect(totalTags.first()).toBeVisible();
      if (await categoriesCount.count() > 0) await expect(categoriesCount.first()).toBeVisible();
    });
  });

  // ========================================
  // TARJETAS DE BOOKMARK - INTERACCI√ìN
  // ========================================
  
  test('‚úÖ Bookmark Cards: Verificar interacci√≥n completa', async ({ page }) => {
    await page.goto('/bookmarks');
    await page.waitForTimeout(2000);
    
    await test.step('Verificar que hay tarjetas', async () => {
      const bookmarkCards = page.locator('[class*="BookmarkCard"], article, div.bg-white.rounded-xl');
      const count = await bookmarkCards.count();
      console.log(`Tarjetas encontradas: ${count}`);
      
      if (count > 0) {
        await expect(bookmarkCards.first()).toBeVisible();
      }
    });

    await test.step('Verificar hover effect', async () => {
      const bookmarkCards = page.locator('[class*="BookmarkCard"], div.bg-white.rounded-xl');
      
      if (await bookmarkCards.count() > 0) {
        const firstCard = bookmarkCards.first();
        await firstCard.hover();
        await page.waitForTimeout(200);
      }
    });

    await test.step('Verificar que el t√≠tulo es clickeable', async () => {
      const bookmarkCards = page.locator('[class*="BookmarkCard"], div.bg-white.rounded-xl');
      
      if (await bookmarkCards.count() > 0) {
        const firstCard = bookmarkCards.first();
        const titleLink = firstCard.locator('a[href], h3 a');
        
        if (await titleLink.count() > 0) {
          const href = await titleLink.first().getAttribute('href');
          expect(href).toBeTruthy();
        }
      }
    });

    await test.step('Verificar que la URL es clickeable', async () => {
      const bookmarkCards = page.locator('[class*="BookmarkCard"], div.bg-white.rounded-xl');
      
      if (await bookmarkCards.count() > 0) {
        const firstCard = bookmarkCards.first();
        const urlLinks = firstCard.locator('a[href]');
        
        if (await urlLinks.count() > 1) {
          const secondLink = urlLinks.nth(1);
          const href = await secondLink.getAttribute('href');
          expect(href).toBeTruthy();
        }
      }
    });

    await test.step('Verificar badges de categor√≠a', async () => {
      const badges = page.locator('[class*="Badge"]:not(:has-text("#"))');
      if (await badges.count() > 0) {
        await expect(badges.first()).toBeVisible();
      }
    });

    await test.step('Verificar tags con #', async () => {
      const tagBadges = page.locator('[class*="Badge"]:has-text("#")');
      if (await tagBadges.count() > 0) {
        await expect(tagBadges.first()).toBeVisible();
      }
    });

    await test.step('Verificar bot√≥n "Ver m√°s" en res√∫menes largos', async () => {
      const bookmarkCards = page.locator('[class*="BookmarkCard"], div.bg-white.rounded-xl');
      
      if (await bookmarkCards.count() > 0) {
        const firstCard = bookmarkCards.first();
        const seeMoreButton = firstCard.locator('button').filter({ hasText: /Ver m√°s|Ver menos/ });
        
        if (await seeMoreButton.count() > 0) {
          await expect(seeMoreButton.first()).toBeVisible();
          await seeMoreButton.first().click();
          await page.waitForTimeout(300);
        }
      }
    });
  });

  // ========================================
  // RESPONSIVE - SIDEBAR MOBILE
  // ========================================
  
  test('‚úÖ Mobile: Verificar toggle de sidebar', async ({ page }) => {
    // Forzar viewport mobile
    await page.setViewportSize({ width: 375, height: 667 });
    await page.goto('/');
    await page.waitForTimeout(1000);
    
    await test.step('Verificar bot√≥n de toggle visible', async () => {
      const toggleButton = page.locator('button').filter({ has: page.locator('svg') }).first();
      await expect(toggleButton).toBeVisible({ timeout: 5000 });
    });

    await test.step('Verificar que sidebar est√° oculto inicialmente', async () => {
      const sidebar = page.locator('[class*="Sidebar"], aside');
      // En mobile puede estar oculto o visible, no forzamos
    });

    await test.step('Verificar que abre el sidebar', async () => {
      const toggleButton = page.locator('button').filter({ has: page.locator('svg') }).first();
      await toggleButton.click();
      await page.waitForTimeout(500);
    });

    await test.step('Verificar que cierra el sidebar', async () => {
      const toggleButton = page.locator('button').filter({ has: page.locator('svg') }).first();
      await toggleButton.click(); // Abrir
      await page.waitForTimeout(300);
      await toggleButton.click(); // Cerrar
      await page.waitForTimeout(300);
    });
  });

  // ========================================
  // TOAST NOTIFICATIONS
  // =================================-------
  
  test('‚úÖ Toasts: Verificar sistema de notificaciones', async ({ page }) => {
    await test.step('Verificar que no hay toasts inicialmente', async () => {
      const toasts = page.locator('[class*="Toast"], div.fixed.bottom-4.right-4');
      // No forzamos count=0 porque puede haber toasts de carga inicial
    });
  });

  // ========================================
  // ACCESIBILIDAD B√ÅSICA
  // =================================-------
  
  test('‚úÖ Accesibilidad: Verificar atributos ARIA', async ({ page }) => {
    await test.step('Verificar aria-label en bot√≥n de cerrar modal', async () => {
      await page.goto('/bookmarks');
      await page.waitForTimeout(1000);
      
      const addButton = page.locator('button').filter({ hasText: /Agregar|‚ûï/ }).first();
      if (await addButton.count() > 0) {
        await addButton.click();
        await page.waitForTimeout(500);
        
        const closeButton = page.locator('button[aria-label]');
        if (await closeButton.count() > 0) {
          const ariaLabel = await closeButton.first().getAttribute('aria-label');
          expect(ariaLabel).toBeTruthy();
        }
      }
    });
  });

  // ========================================
  // MANEJO DE ERRORES VISUALES
  // =================================-------
  
  test('‚úÖ Error Handling: Verificar mensajes de error', async ({ page }) => {
    await test.step('Verificar mensaje cuando no hay bookmarks', async () => {
      await page.goto('/bookmarks');
      await page.waitForTimeout(1000);
      
      const searchInput = page.locator('input[placeholder*="Buscar"], input[type="text"]').first();
      await searchInput.fill('thisisnotarealbookmark123xyz');
      await searchInput.press('Enter');
      
      await page.waitForTimeout(1500);
      
      const noResults = page.locator('text="No se encontraron resultados", text="no hay"');
      if (await noResults.count() > 0) {
        await expect(noResults.first()).toBeVisible();
      }
    });
  });
});


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/tests/ui/home.spec.ts
üìè Tama√±o: 2.6 KB
================================================================================

// tests/ui/home.spec.ts - Tests para la p√°gina principal
import { test, expect } from '../setup';

test.describe('P√°gina Principal - Dashboard', () => {
  
  test.beforeEach(async ({ page }) => {
    await page.goto('/');
  });

  test('deber√≠a cargar la p√°gina principal correctamente', async ({ page }) => {
    // Verificar que el t√≠tulo est√© presente
    await expect(page).toHaveTitle(/Neural Bookmark Brain/);
    
    // Verificar que el header est√© visible
    const header = page.locator('h1:has-text("Neural Bookmark Brain")');
    await expect(header).toBeVisible();
    
    // Verificar que el logo est√© visible
    const logo = page.locator('text=üß†');
    await expect(logo).toBeVisible();
  });

  test('deber√≠a mostrar las tarjetas de estad√≠sticas', async ({ page }) => {
    // Esperar a que carguen las estad√≠sticas
    await page.waitForTimeout(1000);
    
    // Verificar que las tarjetas de stats est√©n visibles
    const statCards = page.locator('[class*="StatCard"]');
    await expect(statCards).toHaveCount(4);
    
    // Verificar contenido espec√≠fico
    await expect(page.locator('text="Total Bookmarks"')).toBeVisible();
    await expect(page.locator('text="Procesados"')).toBeVisible();
    await expect(page.locator('text="Pendientes"')).toBeVisible();
    await expect(page.locator('text="Fallidos"')).toBeVisible();
  });

  test('deber√≠a mostrar la barra de progreso de procesamiento', async ({ page }) => {
    // Verificar que la barra de progreso est√© visible
    const progressBar = page.locator('text="Progreso de Procesamiento"');
    await expect(progressBar).toBeVisible();
    
    // Verificar que los estados est√©n presentes
    await expect(page.locator('text="‚úÖ Completados"')).toBeVisible();
    await expect(page.locator('text="‚öôÔ∏è Procesando"')).toBeVisible();
  });

  test('deber√≠a navegar al hacer clic en el logo', async ({ page }) => {
    const logo = page.locator('text=üß†').first();
    await logo.click();
    
    // Verificar que seguimos en la p√°gina principal
    await expect(page).toHaveURL(/\/$/);
  });

  test('deber√≠a mostrar los bookmarks recientes', async ({ page }) => {
    // Esperar a que carguen los bookmarks
    await page.waitForTimeout(1500);
    
    // Verificar que la secci√≥n de bookmarks est√© visible
    const bookmarksSection = page.locator('text="üìö √öltimos Bookmarks"');
    await expect(bookmarksSection).toBeVisible();
    
    // Verificar que haya al menos una tarjeta de bookmark
    const bookmarkCards = page.locator('[class*="BookmarkCard"]');
    await expect(bookmarkCards).toHaveCount({ min: 1 });
  });
});


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/tests/ui/navigation.spec.ts
üìè Tama√±o: 4.1 KB
================================================================================

// tests/ui/navigation.spec.ts - Tests para navegaci√≥n
import { test, expect } from '../setup';

test.describe('Navegaci√≥n', () => {
  
  test.beforeEach(async ({ page }) => {
    await page.goto('/');
  });

  test('deber√≠a navegar al Dashboard', async ({ page }) => {
    // Verificar que ya estamos en el dashboard
    await expect(page).toHaveURL(/\/$/);
    
    // Verificar elementos del dashboard
    await expect(page.locator('text="üìä Dashboard"')).toBeVisible();
  });

  test('deber√≠a navegar a Bookmarks', async ({ page }) => {
    // Abrir sidebar si es mobile
    const sidebarToggle = page.locator('button:has-text("Abrir men√∫")');
    if (await sidebarToggle.isVisible()) {
      await sidebarToggle.click();
    }
    
    // Navegar a Bookmarks
    const bookmarksLink = page.locator('a:has-text("üìö Todos los Bookmarks")');
    await bookmarksLink.click();
    
    // Verificar URL
    await expect(page).toHaveURL(/\/bookmarks$/);
    
    // Verificar que la p√°gina de bookmarks carg√≥
    await expect(page.locator('text="üìö Todos los Bookmarks"')).toBeVisible();
  });

  test('deber√≠a navegar a Estad√≠sticas', async ({ page }) => {
    // Abrir sidebar
    const sidebarToggle = page.locator('button:has-text("Abrir men√∫")');
    if (await sidebarToggle.isVisible()) {
      await sidebarToggle.click();
    }
    
    // Navegar a Estad√≠sticas
    const statsLink = page.locator('a:has-text("üìä Estad√≠sticas")');
    await statsLink.click();
    
    // Verificar URL
    await expect(page).toHaveURL(/\/stats$/);
    
    // Verificar que la p√°gina de estad√≠sticas carg√≥
    await expect(page.locator('text="üìä Estad√≠sticas Detalladas"')).toBeVisible();
  });

  test('deber√≠a navegar a Categor√≠as', async ({ page }) => {
    // Abrir sidebar
    const sidebarToggle = page.locator('button:has-text("Abrir men√∫")');
    if (await sidebarToggle.isVisible()) {
      await sidebarToggle.click();
    }
    
    // Navegar a Categor√≠as
    const categoriesLink = page.locator('a:has-text("üìÇ Categor√≠as")');
    await categoriesLink.click();
    
    // Verificar URL
    await expect(page).toHaveURL(/\/categories$/);
    
    // Verificar mensaje de pr√≥ximamente
    await expect(page.locator('text="Pr√≥ximamente"')).toBeVisible();
  });

  test('deber√≠a navegar a Tags', async ({ page }) => {
    // Abrir sidebar
    const sidebarToggle = page.locator('button:has-text("Abrir men√∫")');
    if (await sidebarToggle.isVisible()) {
      await sidebarToggle.click();
    }
    
    // Navegar a Tags
    const tagsLink = page.locator('a:has-text("üè∑Ô∏è Tags")');
    await tagsLink.click();
    
    // Verificar URL
    await expect(page).toHaveURL(/\/tags$/);
    
    // Verificar mensaje de pr√≥ximamente
    await expect(page.locator('text="Pr√≥ximamente"')).toBeVisible();
  });

  test('deber√≠a navegar a Configuraci√≥n', async ({ page }) => {
    // Abrir sidebar
    const sidebarToggle = page.locator('button:has-text("Abrir men√∫")');
    if (await sidebarToggle.isVisible()) {
      await sidebarToggle.click();
    }
    
    // Navegar a Configuraci√≥n
    const settingsLink = page.locator('a:has-text("‚öôÔ∏è Configuraci√≥n")');
    await settingsLink.click();
    
    // Verificar URL
    await expect(page).toHaveURL(/\/settings$/);
    
    // Verificar mensaje de pr√≥ximamente
    await expect(page.locator('text="Pr√≥ximamente"')).toBeVisible();
  });

  test('deber√≠a mostrar/ocultar el sidebar en mobile', async ({ page }) => {
    // Forzar viewport mobile
    await page.setViewportSize({ width: 375, height: 667 });
    
    // Recargar para aplicar el cambio
    await page.goto('/');
    
    // Verificar que el bot√≥n de toggle est√© visible
    const toggleButton = page.locator('button:has(svg)');
    await expect(toggleButton).toBeVisible();
    
    // Verificar que el sidebar est√© oculto inicialmente
    const sidebar = page.locator('[class*="Sidebar"]');
    await expect(sidebar).not.toBeVisible();
    
    // Abrir sidebar
    await toggleButton.click();
    await expect(sidebar).toBeVisible();
    
    // Cerrar sidebar
    await toggleButton.click();
    await expect(sidebar).not.toBeVisible();
  });
});


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/tests/ui/search.spec.ts
üìè Tama√±o: 2.6 KB
================================================================================

// tests/ui/search.spec.ts - Tests para b√∫squeda
import { test, expect } from '../setup';

test.describe('B√∫squeda', () => {
  
  test.beforeEach(async ({ page }) => {
    await page.goto('/');
  });

  test('deber√≠a mostrar la barra de b√∫squeda', async ({ page }) => {
    // Verificar que la barra de b√∫squeda est√© visible
    const searchInput = page.locator('input[placeholder*="Buscar"]');
    await expect(searchInput).toBeVisible();
    
    // Verificar que el bot√≥n de b√∫squeda est√© visible
    const searchButton = page.locator('button:has-text("Buscar")');
    await expect(searchButton).toBeVisible();
  });

  test('deber√≠a permitir ingresar texto en la b√∫squeda', async ({ page }) => {
    const searchInput = page.locator('input[placeholder*="Buscar"]');
    
    // Escribir en el input
    await searchInput.fill('react');
    
    // Verificar que el texto se ingres√≥ correctamente
    await expect(searchInput).toHaveValue('react');
  });

  test('deber√≠a navegar a la p√°gina de b√∫squeda al hacer clic en buscar', async ({ page }) => {
    const searchInput = page.locator('input[placeholder*="Buscar"]');
    const searchButton = page.locator('button:has-text("Buscar")');
    
    // Ingresar texto y buscar
    await searchInput.fill('react');
    await searchButton.click();
    
    // Verificar que navegamos a la p√°gina de b√∫squeda
    await expect(page).toHaveURL(/\/search\?q=/);
  });

  test('deber√≠a limpiar la b√∫squeda', async ({ page }) => {
    const searchInput = page.locator('input[placeholder*="Buscar"]');
    const clearButton = page.locator('button[aria-label="Limpiar b√∫squeda"]');
    
    // Ingresar texto
    await searchInput.fill('test');
    
    // Verificar que el bot√≥n de limpiar aparece
    await expect(clearButton).toBeVisible();
    
    // Limpiar
    await clearButton.click();
    
    // Verificar que el input est√° vac√≠o
    await expect(searchInput).toHaveValue('');
  });

  test('deber√≠a mostrar resultados de b√∫squeda', async ({ page }) => {
    // Navegar directamente a la p√°gina de b√∫squeda
    await page.goto('/search?q=react');
    
    // Esperar a que carguen los resultados
    await page.waitForTimeout(1500);
    
    // Verificar que la p√°gina de b√∫squeda carg√≥
    await expect(page.locator('text="üîç B√∫squeda Avanzada"')).toBeVisible();
    
    // Verificar que hay resultados o mensaje apropiado
    const results = page.locator('[class*="BookmarkCard"]');
    const noResults = page.locator('text="No se encontraron resultados"');
    
    // Deber√≠a haber al menos uno de los dos
    expect(await results.count() > 0 || await noResults.isVisible()).toBe(true);
  });
});


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/tsconfig.app.json
üìè Tama√±o: 0.7 KB
================================================================================

{
  "compilerOptions": {
    "tsBuildInfoFile": "./node_modules/.tmp/tsconfig.app.tsbuildinfo",
    "target": "ES2022",
    "useDefineForClassFields": true,
    "lib": ["ES2022", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "types": ["vite/client"],
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "verbatimModuleSyntax": true,
    "moduleDetection": "force",
    "noEmit": true,
    "jsx": "react-jsx",

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "erasableSyntaxOnly": true,
    "noFallthroughCasesInSwitch": true,
    "noUncheckedSideEffectImports": true
  },
  "include": ["src"]
}



================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/tsconfig.json
üìè Tama√±o: 0.6 KB
================================================================================

{
  "compilerOptions": {
    "target": "ES2020",
    "useDefineForClassFields": true,
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "skipLibCheck": true,
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx",
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noFallthroughCasesInSwitch": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["src/*"]
    }
  },
  "include": ["src"],
  "references": [{ "path": "./tsconfig.node.json" }]
}


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/tsconfig.node.json
üìè Tama√±o: 0.2 KB
================================================================================

{
  "compilerOptions": {
    "composite": true,
    "skipLibCheck": true,
    "module": "ESNext",
    "moduleResolution": "bundler",
    "allowSyntheticDefaultImports": true
  },
  "include": ["vite.config.ts"]
}


================================================================================
üìÑ ARCHIVO: neural-bookmark-ui/vite.config.ts
üìè Tama√±o: 0.8 KB
================================================================================

// vite.config.ts
// FIXED ENV-01: hmr.host ya no es IP hardcodeada.
// Usa localhost por defecto; sobreescribible con VITE_HMR_HOST env var.
// Ejemplo para acceso LAN: VITE_HMR_HOST=192.168.1.40 npm run dev
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

export default defineConfig({
  plugins: [react()],
  server: {
    host: '0.0.0.0',       // Escuchar en todas las interfaces de red
    port: 5173,
    strictPort: true,
    hmr: {
      // FIXED: era '192.168.1.40' (hardcodeado). Ahora din√°mico.
      // localhost funciona en WSL2 desde el mismo host; para acceso LAN usa env var.
      host: process.env.VITE_HMR_HOST || 'localhost',
      port: 5173
    },
    cors: true,
    watch: {
      usePolling: true
    }
  },
  build: {
    outDir: 'dist',
    sourcemap: true
  }
})


================================================================================
üìÑ ARCHIVO: prototype.html
üìè Tama√±o: 31.7 KB
‚ö†Ô∏è  DATOS SENSIBLES ENMASCARADOS:
  ‚ö†Ô∏è  Encontrado 1 coincidencia(s) de tipo: https?://
================================================================================

<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Bookmark Brain - Semantic Memory</title>
    <link rel="stylesheet" href="https://user:xxxxxxxxxx@media (max-width: 1024px) {
            .sidebar {
                width: 220px;
            }
            .main-content {
                margin-left: 220px;
            }
            .bookmarks-grid {
                grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
            }
        }

        @media (max-width: 768px) {
            .sidebar {
                width: 70px;
                overflow: hidden;
            }
            .sidebar-header h1,
            .sidebar-section-title,
            .sidebar-nav-text,
            .category-count,
            .tag-count {
                display: none;
            }
            .sidebar-nav-link {
                justify-content: center;
                padding: 16px;
            }
            .sidebar-nav-link i {
                margin-right: 0;
                font-size: 1.25rem;
            }
            .main-content {
                margin-left: 70px;
            }
            .header {
                flex-direction: column;
                align-items: flex-start;
                gap: 15px;
            }
            .search-container {
                max-width: 100%;
            }
            .stats-grid {
                grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            }
            .bookmarks-grid {
                grid-template-columns: 1fr;
            }
            .modal {
                width: 95%;
                max-width: 500px;
            }
        }

        @media (max-width: 480px) {
            .sidebar {
                display: none;
            }
            .main-content {
                margin-left: 0;
            }
            .stats-grid {
                grid-template-columns: 1fr;
            }
            .bookmark-actions {
                flex-direction: column;
                gap: 6px;
            }
            .bookmark-action {
                width: 100%;
                justify-content: center;
            }
            .modal {
                width: 95%;
                max-width: 400px;
            }
        }

        /* Animations */
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .fade-in {
            animation: fadeIn 0.3s ease forwards;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .pulse {
            animation: pulse 2s ease-in-out infinite;
        }

        /* Toast Notification */
        .toast-container {
            position: fixed;
            top: 20px;
            right: 20px;
            z-index: 2000;
            display: flex;
            flex-direction: column;
            gap: 10px;
        }

        .toast {
            background-color: var(--bg-card);
            border-left: 4px solid var(--accent-primary);
            border-radius: var(--border-radius);
            padding: 16px 20px;
            box-shadow: 0 4px 12px var(--shadow-lg);
            min-width: 300px;
            transform: translateX(400px);
            transition: transform 0.3s ease;
        }

        .toast.show {
            transform: translateX(0);
        }

        .toast.success { border-left-color: var(--accent-success); }
        .toast.error { border-left-color: var(--accent-danger); }
        .toast.warning { border-left-color: var(--accent-warning); }

        .toast-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 8px;
        }

        .toast-title {
            font-weight: 700;
            font-size: 1rem;
        }

        .toast-close {
            background: none;
            border: none;
            color: var(--text-muted);
            cursor: pointer;
            font-size: 1.25rem;
        }

        .toast-message {
            font-size: 0.9375rem;
            color: var(--text-secondary);
        }

        /* Loading Spinner */
        .spinner {
            width: 24px;
            height: 24px;
            border: 3px solid var(--border);
            border-top-color: var(--accent-primary);
            border-radius: 50%;
            animation: spin 0.6s linear infinite;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        /* Badge */
        .badge {
            display: inline-block;
            padding: 4px 10px;
            border-radius: var(--border-radius-full);
            font-size: 0.75rem;
            font-weight: 600;
        }

        .badge.primary { background-color: var(--accent-primary); color: var(--text-on-accent); }
        .badge.success { background-color: var(--accent-success); color: var(--text-on-accent); }
        .badge.warning { background-color: var(--accent-warning); color: var(--text-primary); }
        .badge.danger { background-color: var(--accent-danger); color: var(--text-on-accent); }
    </style>
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar">
            <div class="sidebar-header">
                <h1><i class="fas fa-brain"></i> Neural Brain</h1>
            </div>
            
            <nav>
                <ul class="sidebar-nav">
                    <li class="sidebar-nav-item">
                        <a href="#" class="sidebar-nav-link active">
                            <i class="fas fa-home"></i>
                            <span class="sidebar-nav-text">Dashboard</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="#" class="sidebar-nav-link">
                            <i class="fas fa-search"></i>
                            <span class="sidebar-nav-text">B√∫squeda</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="#" class="sidebar-nav-link">
                            <i class="fas fa-bookmark"></i>
                            <span class="sidebar-nav-text">Bookmarks</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="#" class="sidebar-nav-link">
                            <i class="fas fa-chart-bar"></i>
                            <span class="sidebar-nav-text">Estad√≠sticas</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="#" class="sidebar-nav-link">
                            <i class="fas fa-file-import"></i>
                            <span class="sidebar-nav-text">Importar</span>
                        </a>
                    </li>
                    <li class="sidebar-nav-item">
                        <a href="#" class="sidebar-nav-link">
                            <i class="fas fa-cog"></i>
                            <span class="sidebar-nav-text">Configuraci√≥n</span>
                        </a>
                    </li>
                </ul>
            </nav>
            
            <div class="sidebar-section">
                <h3 class="sidebar-section-title">Categor√≠as</h3>
                <ul class="category-list">
                    <li class="category-item">
                        <span><i class="fas fa-code"></i> Tecnolog√≠a</span>
                        <span class="category-count">45</span>
                    </li>
                    <li class="category-item">
                        <span><i class="fas fa-book"></i> Educaci√≥n</span>
                        <span class="category-count">23</span>
                    </li>
                    <li class="category-item">
                        <span><i class="fas fa-briefcase"></i> Negocios</span>
                        <span class="category-count">18</span>
                    </li>
                    <li class="category-item">
                        <span><i class="fas fa-palette"></i> Dise√±o</span>
                        <span class="category-count">12</span>
                    </li>
                    <li class="category-item">
                        <span><i class="fas fa-newspaper"></i> Noticias</span>
                        <span class="category-count">8</span>
                    </li>
                </ul>
            </div>
            
            <div class="sidebar-section">
                <h3 class="sidebar-section-title">Tags Populares</h3>
                <ul class="tag-list">
                    <li class="tag-item">#python <span class="tag-count">45</span></li>
                    <li class="tag-item">#css <span class="tag-count">32</span></li>
                    <li class="tag-item">#javascript <span class="tag-count">28</span></li>
                    <li class="tag-item">#react <span class="tag-count">25</span></li>
                    <li class="tag-item">#ai <span class="tag-count">23</span></li>
                    <li class="tag-item">#machine-learning <span class="tag-count">19</span></li>
                    <li class="tag-item">#webdev <span class="tag-count">19</span></li>
                </ul>
            </div>
        </aside>
        
        <!-- Main Content -->
        <main class="main-content">
            <!-- Header -->
            <header class="header">
                <div class="search-container">
                    <i class="fas fa-search search-icon"></i>
                    <input 
                        type="text" 
                        class="search-input" 
                        placeholder="¬øQu√© quieres encontrar hoy? (B√∫squeda sem√°ntica...)" 
                        id="searchInput"
                    >
                </div>
                
                <div class="user-actions">
                    <button class="btn" id="addBookmarkBtn">
                        <i class="fas fa-plus"></i> A√±adir Bookmark
                    </button>
                    <div class="user-avatar">NB</div>
                </div>
            </header>
            
            <!-- Processing Progress -->
            <div class="processing-progress">
                <div class="progress-header">
                    <div class="progress-title">
                        <i class="fas fa-sync-alt"></i> Procesamiento en curso
                    </div>
                    <div class="progress-stats">
                        <span><i class="fas fa-check-circle"></i> 843 completados</span>
                        <span><i class="fas fa-hourglass-half"></i> 12 pendientes</span>
                        <span><i class="fas fa-times-circle"></i> 157 fallidos</span>
                    </div>
                </div>
                <div class="progress-bar-container">
                    <div class="progress-bar" style="width: 85%">
                        <span class="progress-text">85%</span>
                    </div>
                </div>
            </div>
            
            <!-- Stats Grid -->
            <div class="stats-grid">
                <div class="stat-card fade-in">
                    <div class="stat-card-header">
                        <div class="stat-title">Total Bookmarks</div>
                        <div class="stat-icon primary">
                            <i class="fas fa-bookmark"></i>
                        </div>
                    </div>
                    <div class="stat-value">1,050</div>
                    <div class="stat-trend positive">
                        <i class="fas fa-arrow-up"></i> 12 nuevos hoy
                    </div>
                </div>
                
                <div class="stat-card fade-in">
                    <div class="stat-card-header">
                        <div class="stat-title">Completados</div>
                        <div class="stat-icon success">
                            <i class="fas fa-check-circle"></i>
                        </div>
                    </div>
                    <div class="stat-value">85%</div>
                    <div class="stat-trend positive">
                        <i class="fas fa-arrow-up"></i> +5% esta semana
                    </div>
                </div>
                
                <div class="stat-card fade-in">
                    <div class="stat-card-header">
                        <div class="stat-title">Palabras Promedio</div>
                        <div class="stat-icon warning">
                            <i class="fas fa-text-height"></i>
                        </div>
                    </div>
                    <div class="stat-value">1,245</div>
                    <div class="stat-trend">
                        <i class="fas fa-equals"></i> Estable
                    </div>
                </div>
                
                <div class="stat-card fade-in">
                    <div class="stat-card-header">
                        <div class="stat-title">Tags √önicos</div>
                        <div class="stat-icon secondary">
                            <i class="fas fa-tags"></i>
                        </div>
                    </div>
                    <div class="stat-value">347</div>
                    <div class="stat-trend positive">
                        <i class="fas fa-arrow-up"></i> +23 nuevos
                    </div>
                </div>
            </div>
            
            <!-- Latest Bookmarks Section -->
            <h2 class="section-title">
                <i class="fas fa-history"></i> √öltimos Bookmarks
            </h2>
            
            <div class="bookmarks-grid" id="bookmarksContainer">
                <!-- Bookmarks se generar√°n din√°micamente con JavaScript -->
            </div>
        </main>
    </div>
    
    <!-- Add Bookmark Modal -->
    <div class="modal-overlay" id="addBookmarkModal">
        <div class="modal">
            <div class="modal-header">
                <h3 class="modal-title">
                    <i class="fas fa-plus-circle"></i> A√±adir Nuevo Bookmark
                </h3>
                <button class="modal-close" id="closeModalBtn">
                    <i class="fas fa-times"></i>
                </button>
            </div>
            <div class="modal-body">
                <form id="bookmarkForm">
                    <div class="form-group">
                        <label class="form-label" for="bookmarkUrl">URL:</label>
                        <input 
                            type="url" 
                            class="form-input" 
                            id="bookmarkUrl" 
                            placeholder="https://example.com/article"
                            required
                        >
                        <button type="button" class="btn btn-secondary" style="margin-top: 8px;">
                            <i class="fas fa-magic"></i> Detectar autom√°ticamente
                        </button>
                    </div>
                    
                    <div class="form-group">
                        <label class="form-label" for="bookmarkTitle">T√≠tulo Original:</label>
                        <input 
                            type="text" 
                            class="form-input" 
                            id="bookmarkTitle" 
                            placeholder="T√≠tulo del art√≠culo"
                            required
                        >
                    </div>
                    
                    <div class="form-group">
                        <label class="form-label" for="bookmarkCleanTitle">T√≠tulo Mejorado (AI):</label>
                        <input 
                            type="text" 
                            class="form-input" 
                            id="bookmarkCleanTitle" 
                            placeholder="La IA mejorar√° este t√≠tulo autom√°ticamente..."
                        >
                    </div>
                    
                    <div class="form-checkbox">
                        <input type="checkbox" id="useAi" checked>
                        <label for="useAi">Usar IA para mejorar t√≠tulo y generar resumen</label>
                    </div>
                    
                    <div class="form-group">
                        <label class="form-label" for="bookmarkCategory">Categor√≠a:</label>
                        <select class="form-input" id="bookmarkCategory">
                            <option value="">Seleccionar categor√≠a...</option>
                            <option value="tecnologia">Tecnolog√≠a</option>
                            <option value="educacion">Educaci√≥n</option>
                            <option value="negocios">Negocios</option>
                            <option value="diseno">Dise√±o</option>
                            <option value="noticias">Noticias</option>
                            <option value="otros">Otros</option>
                        </select>
                    </div>
                    
                    <div class="form-group">
                        <label class="form-label" for="bookmarkTags">Tags (separados por comas):</label>
                        <input 
                            type="text" 
                            class="form-input" 
                            id="bookmarkTags" 
                            placeholder="python, css, tutorial, webdev"
                        >
                    </div>
                    
                    <div class="form-group">
                        <label class="form-label" for="bookmarkSummary">Resumen:</label>
                        <textarea 
                            class="form-textarea" 
                            id="bookmarkSummary" 
                            placeholder="La IA generar√° un resumen autom√°tico de 3 oraciones..."
                            readonly
                        ></textarea>
                    </div>
                </form>
            </div>
            <div class="modal-footer">
                <button class="btn btn-secondary" id="cancelBtn">
                    <i class="fas fa-times"></i> Cancelar
                </button>
                <button class="btn" id="saveBtn">
                    <i class="fas fa-save"></i> Guardar Bookmark
                </button>
                <button class="btn btn-success" id="processWithAiBtn">
                    <i class="fas fa-robot"></i> Procesar con IA
                </button>
            </div>
        </div>
    </div>
    
    <!-- Toast Container -->
    <div class="toast-container" id="toastContainer"></div>
    
    <script>
        // Mock Data
        const mockBookmarks = [
            {
                id: 1,
                title: "CSS Animation Guide - Master Modern Animations",
                url: "https://cssanimation.io/guide-to-modern-css-animations",
                summary: "A comprehensive guide to CSS animations with keyframes, transitions, and practical examples for creating smooth, performant animations in modern web development.",
                tags: ["css", "animation", "frontend", "webdev"],
                category: "Tecnolog√≠a",
                relevance: 92,
                wordCount: 2531,
                date: "2026-02-09"
            },
            {
                id: 2,
                title: "Python Data Structures - Complete Tutorial",
                url: "https://realpython.com/python-data-structures",
                summary: "Learn about Python's built-in data structures like lists, dictionaries, sets, and tuples. This tutorial covers performance characteristics and best practices for each type.",
                tags: ["python", "programming", "data-structures", "tutorial"],
                category: "Educaci√≥n",
                relevance: 88,
                wordCount: 3127,
                date: "2026-02-08"
            },
            {
                id: 3,
                title: "React Hooks Tutorial - useState and useEffect Explained",
                url: "https://react.dev/learn/hooks",
                summary: "Master React Hooks with this comprehensive tutorial covering useState, useEffect, useContext, and custom hooks. Learn how to write cleaner, more reusable components.",
                tags: ["react", "javascript", "hooks", "frontend"],
                category: "Tecnolog√≠a",
                relevance: 85,
                wordCount: 1845,
                date: "2026-02-08"
            },
            {
                id: 4,
                title: "Machine Learning Fundamentals - A Beginner's Guide",
                url: "https://towardsdatascience.com/machine-learning-fundamentals",
                summary: "An introduction to machine learning concepts including supervised vs unsupervised learning, model training, and evaluation metrics. Perfect for beginners starting their ML journey.",
                tags: ["machine-learning", "ai", "data-science", "tutorial"],
                category: "Educaci√≥n",
                relevance: 82,
                wordCount: 2763,
                date: "2026-02-07"
            },
            {
                id: 5,
                title: "CSS Grid Layout - Complete Guide with Examples",
                url: "https://css-tricks.com/snippets/css/complete-guide-grid",
                summary: "Everything you need to know about CSS Grid Layout. This guide covers grid containers, tracks, areas, alignment, and responsive design patterns with practical examples.",
                tags: ["css", "grid", "layout", "frontend"],
                category: "Dise√±o",
                relevance: 79,
                wordCount: 1956,
                date: "2026-02-07"
            },
            {
                id: 6,
                title: "Building a REST API with FastAPI - Best Practices",
                url: "https://fastapi.tiangolo.com/tutorial",
                summary: "Learn how to build robust, production-ready REST APIs using FastAPI. This tutorial covers routing, validation, authentication, database integration, and deployment strategies.",
                tags: ["python", "fastapi", "api", "backend"],
                category: "Tecnolog√≠a",
                relevance: 76,
                wordCount: 2341,
                date: "2026-02-06"
            }
        ];

        // DOM Elements
        const bookmarksContainer = document.getElementById('bookmarksContainer');
        const searchInput = document.getElementById('searchInput');
        const addBookmarkBtn = document.getElementById('addBookmarkBtn');
        const addBookmarkModal = document.getElementById('addBookmarkModal');
        const closeModalBtn = document.getElementById('closeModalBtn');
        const cancelBtn = document.getElementById('cancelBtn');
        const saveBtn = document.getElementById('saveBtn');
        const toastContainer = document.getElementById('toastContainer');

        // Render Bookmarks
        function renderBookmarks(bookmarks) {
            bookmarksContainer.innerHTML = '';
            
            bookmarks.forEach(bookmark => {
                const card = document.createElement('div');
                card.className = 'bookmark-card fade-in';
                card.innerHTML = `
                    <div class="bookmark-header">
                        <h3 class="bookmark-title">${bookmark.title}</h3>
                        <div class="bookmark-url">${bookmark.url}</div>
                    </div>
                    <div class="bookmark-body">
                        <p class="bookmark-summary">${bookmark.summary}</p>
                        <div class="bookmark-meta">
                            ${bookmark.tags.map(tag => `<span class="bookmark-tag">#${tag}</span>`).join('')}
                        </div>
                        <div class="relevance-bar">
                            <div class="relevance-fill" style="width: ${bookmark.relevance}%"></div>
                        </div>
                    </div>
                    <div class="bookmark-footer">
                        <div class="bookmark-stats">
                            <span><i class="fas fa-chart-line"></i> ${bookmark.relevance}% relevancia</span>
                            <span><i class="fas fa-wordpress"></i> ${bookmark.wordCount} palabras</span>
                        </div>
                        <div class="bookmark-actions">
                            <button class="bookmark-action" title="Abrir">
                                <i class="fas fa-external-link-alt"></i>
                            </button>
                            <button class="bookmark-action" title="Editar">
                                <i class="fas fa-edit"></i>
                            </button>
                            <button class="bookmark-action" title="Eliminar">
                                <i class="fas fa-trash"></i>
                            </button>
                        </div>
                    </div>
                `;
                bookmarksContainer.appendChild(card);
            });
        }

        // Search Functionality
        searchInput.addEventListener('input', (e) => {
            const query = e.target.value.toLowerCase();
            
            if (query.length > 2) {
                const filtered = mockBookmarks.filter(bookmark => 
                    bookmark.title.toLowerCase().includes(query) ||
                    bookmark.summary.toLowerCase().includes(query) ||
                    bookmark.tags.some(tag => tag.includes(query))
                );
                
                renderBookmarks(filtered);
                
                if (filtered.length === 0) {
                    bookmarksContainer.innerHTML = `
                        <div style="grid-column: 1 / -1; text-align: center; padding: 40px; color: var(--text-muted);">
                            <i class="fas fa-search" style="font-size: 3rem; margin-bottom: 20px;"></i>
                            <p>No se encontraron resultados para "${query}"</p>
                            <p style="font-size: 0.875rem; margin-top: 10px;">Intenta con t√©rminos diferentes o m√°s generales</p>
                        </div>
                    `;
                }
            } else {
                renderBookmarks(mockBookmarks);
            }
        });

        // Modal Functionality
        addBookmarkBtn.addEventListener('click', () => {
            addBookmarkModal.classList.add('active');
        });

        [closeModalBtn, cancelBtn].forEach(btn => {
            btn.addEventListener('click', () => {
                addBookmarkModal.classList.remove('active');
            });
        });

        // Close modal when clicking outside
        addBookmarkModal.addEventListener('click', (e) => {
            if (e.target === addBookmarkModal) {
                addBookmarkModal.classList.remove('active');
            }
        });

        // Save Bookmark
        saveBtn.addEventListener('click', () => {
            const url = document.getElementById('bookmarkUrl').value;
            const title = document.getElementById('bookmarkTitle').value;
            
            if (url && title) {
                // Add to mock data
                const newBookmark = {
                    id: mockBookmarks.length + 1,
                    title: title,
                    url: url,
                    summary: "Nuevo bookmark a√±adido. Esperando procesamiento con IA...",
                    tags: ["nuevo"],
                    category: "Otros",
                    relevance: 100,
                    wordCount: 0,
                    date: new Date().toISOString().split('T')[0]
                };
                
                mockBookmarks.unshift(newBookmark);
                renderBookmarks(mockBookmarks);
                
                // Show toast
                showToast('success', 'Bookmark A√±adido', 'El bookmark ha sido a√±adido exitosamente');
                
                // Close modal
                addBookmarkModal.classList.remove('active');
                
                // Reset form
                document.getElementById('bookmarkForm').reset();
            } else {
                showToast('error', 'Error', 'Por favor completa todos los campos requeridos');
            }
        });

        // Toast Notifications
        function showToast(type, title, message) {
            const toast = document.createElement('div');
            toast.className = `toast ${type} show`;
            toast.innerHTML = `
                <div class="toast-header">
                    <div class="toast-title">${title}</div>
                    <button class="toast-close">&times;</button>
                </div>
                <div class="toast-message">${message}</div>
            `;
            
            toastContainer.appendChild(toast);
            
            // Auto remove after 5 seconds
            setTimeout(() => {
                toast.classList.remove('show');
                setTimeout(() => toast.remove(), 300);
            }, 5000);
            
            // Close button
            toast.querySelector('.toast-close').addEventListener('click', () => {
                toast.classList.remove('show');
                setTimeout(() => toast.remove(), 300);
            });
        }

        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            renderBookmarks(mockBookmarks);
            
            // Simulate processing progress
            let progress = 85;
            const progressBar = document.querySelector('.progress-bar');
            const progressText = document.querySelector('.progress-text');
            
            const interval = setInterval(() => {
                if (progress < 87) {
                    progress += 0.1;
                    progressBar.style.width = `${progress.toFixed(1)}%`;
                    progressText.textContent = `${progress.toFixed(1)}%`;
                } else {
                    clearInterval(interval);
                }
            }, 500);
        });

        // Simulate AI Processing
        document.getElementById('processWithAiBtn').addEventListener('click', () => {
            const titleInput = document.getElementById('bookmarkTitle');
            const summaryTextarea = document.getElementById('bookmarkSummary');
            const cleanTitleInput = document.getElementById('bookmarkCleanTitle');
            
            if (!titleInput.value) {
                showToast('warning', 'Advertencia', 'Por favor ingresa una URL o t√≠tulo primero');
                return;
            }
            
            // Show loading state
            const originalText = document.getElementById('processWithAiBtn').innerHTML;
            document.getElementById('processWithAiBtn').innerHTML = '<i class="fas fa-spinner fa-spin"></i> Procesando...';
            document.getElementById('processWithAiBtn').disabled = true;
            
            // Simulate AI processing delay
            setTimeout(() => {
                // Mock AI improvements
                const improvedTitle = `Gu√≠a completa de ${titleInput.value.toLowerCase()}`;
                const mockSummary = "Este art√≠culo proporciona una visi√≥n detallada y ejemplos pr√°cticos sobre el tema. Cubre conceptos fundamentales, mejores pr√°cticas y casos de uso avanzados para ayudarte a dominar esta tecnolog√≠a.";
                
                cleanTitleInput.value = improvedTitle;
                summaryTextarea.value = mockSummary;
                
                // Restore button
                document.getElementById('processWithAiBtn').innerHTML = originalText;
                document.getElementById('processWithAiBtn').disabled = false;
                
                showToast('success', 'IA Completada', 'T√≠tulo y resumen mejorados autom√°ticamente');
            }, 1500);
        });
    </script>
</body>
</html>


================================================================================
üìÑ ARCHIVO: pytest.ini
üìè Tama√±o: 0.2 KB
================================================================================

[pytest]
testpaths = tests
python_files = test_*.py
python_functions = test_*
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function
addopts = -v



================================================================================
üìÑ ARCHIVO: requirements.txt
üìè Tama√±o: 0.7 KB
================================================================================

# Core Framework
fastapi>=0.109.1
uvicorn[standard]==0.27.0
slowapi>=0.1.9
pydantic==2.5.3
pydantic-settings==2.1.0

# Database & ORM
sqlalchemy[asyncio]==2.0.25
asyncpg==0.29.0
psycopg2-binary==2.9.9
pgvector==0.2.4

# AI & Embeddings
groq>=0.9.0
openai==1.10.0
sentence-transformers>=3.1.0
numpy==1.26.3

# Web Scraping
trafilatura==1.6.3
requests>=2.32.4
beautifulsoup4==4.12.3
lxml==5.1.0
chardet==5.2.0

# Async HTTP
httpx>=0.27.0
aiohttp>=3.13.3

# Utilities
python-dotenv==1.0.0
python-multipart>=0.0.22
validators==0.22.0
tldextract==5.1.1

# Security & NSFW Detection
Pillow>=10.3.0

# Logging & Monitoring
loguru==0.7.2

# CSV Processing
pandas==2.1.4

# Testing
pytest==7.4.3
pytest-asyncio==0.23.3


================================================================================
üìÑ ARCHIVO: scripts/__init__.py
üìè Tama√±o: 0.0 KB
================================================================================

"""
Scripts de administraci√≥n y mantenimiento
"""



================================================================================
üìÑ ARCHIVO: scripts/analyze_tracking.py
üìè Tama√±o: 1.7 KB
================================================================================

from app.database import get_db_context
import asyncio
from app.models import Bookmark
from sqlalchemy import select, func

async def tracking_stats():
    async with get_db_context() as db:
        # 1. Contar total con tracking
        result = await db.execute(
            select(Bookmark.tracking_params).where(
                Bookmark.status == 'completed',
                Bookmark.tracking_params.isnot(None)
            )
        )
        all_tracking = result.scalars().all()
        
        print('\n=== AN√ÅLISIS DE PRIVACIDAD Y TRACKING ===')
        print(f'Total marcadores analizados : {len(all_tracking)}')
        
        if all_tracking:
            print('\nEjemplos de par√°metros detectados y eliminados:')
            for i, params in enumerate(all_tracking[:5], 1):
                if params:
                    keys = list(params.keys())
                    print(f'  [{i}] {", ".join(keys[:4])}{"..." if len(keys) > 4 else ""}')
        
        # 2. Top dominios con m√°s basura de tracking
        result = await db.execute(
            select(Bookmark.domain, func.count()).where(
                Bookmark.status == 'completed',
                Bookmark.tracking_params.isnot(None)
            ).group_by(Bookmark.domain).order_by(func.count().desc()).limit(10)
        )
        top_domains = result.fetchall()
        
        if top_domains:
            print('\nTop dominios con mayor carga de tracking:')
            print(f'  {"Dominio":30} | {"Casos":5}')
            print(f'  {"-"*30}-|-------')
            for domain, count in top_domains:
                print(f'  {domain:30} | {count:5}')

if __name__ == "__main__":
    asyncio.run(tracking_stats())


================================================================================
üìÑ ARCHIVO: scripts/check_env.py
üìè Tama√±o: 3.9 KB
================================================================================

#!/usr/bin/env python3
"""
Script para verificar que todas las variables de entorno necesarias est√°n configuradas
"""
import os
import sys
from pathlib import Path

# A√±adir el directorio ra√≠z al path
root_dir = Path(__file__).parent.parent
sys.path.insert(0, str(root_dir))

def check_env_file():
    """Verifica que el archivo .env existe"""
    env_file = root_dir / ".env"
    
    if not env_file.exists():
        print("‚ùå Error: No se encontr√≥ el archivo .env")
        print(f"   Ubicaci√≥n esperada: {env_file}")
        print("\nüí° Soluci√≥n:")
        print(f"   cp .env.example .env")
        print("   Luego edita el archivo .env con tus valores\n")
        return False
    
    print("‚úÖ Archivo .env encontrado")
    return True

def check_configuration():
    """Verifica que la configuraci√≥n se puede cargar"""
    try:
        from app.config import get_settings
        
        print("\nüìã Verificando configuraci√≥n...")
        settings = get_settings()
        
        print("‚úÖ Configuraci√≥n cargada correctamente")
        
        # Verificar variables cr√≠ticas
        print("\nüîë Variables de entorno cr√≠ticas:")
        print(f"   ‚Ä¢ GROQ_API_KEY: {'‚úÖ Configurada' if settings.GROQ_API_KEY else '‚ùå No configurada'}")
        print(f"   ‚Ä¢ DATABASE_URL: ‚úÖ Configurada")
        print(f"   ‚Ä¢ GROQ_MODEL: {settings.GROQ_MODEL}")
        print(f"   ‚Ä¢ EMBEDDING_MODEL: {settings.EMBEDDING_MODEL}")
        
        return True
        
    except ValueError as e:
        print("\n‚ùå Error de validaci√≥n:")
        print(f"   {e}")
        return False
        
    except Exception as e:
        print(f"\n‚ùå Error cargando configuraci√≥n: {e}")
        return False

def check_database_connection():
    """Verifica la conexi√≥n a la base de datos"""
    try:
        print("\nüóÑÔ∏è  Verificando conexi√≥n a base de datos...")
        
        import asyncio
        from sqlalchemy import text
        from app.database import engine
        
        async def test_connection():
            try:
                async with engine.begin() as conn:
                    result = await conn.execute(text("SELECT 1"))
                    await conn.execute(text("SELECT version()"))
                    return True
            except Exception as e:
                print(f"   ‚ùå Error de conexi√≥n: {e}")
                return False
        
        result = asyncio.run(test_connection())
        
        if result:
            print("   ‚úÖ Conexi√≥n a PostgreSQL exitosa")
            return True
        else:
            return False
            
    except Exception as e:
        print(f"   ‚ùå Error verificando base de datos: {e}")
        return False

def main():
    """Funci√≥n principal"""
    print("="*60)
    print("üîç VERIFICACI√ìN DE CONFIGURACI√ìN")
    print("="*60)
    
    checks = []
    
    # 1. Verificar archivo .env
    checks.append(("Archivo .env", check_env_file()))
    
    # 2. Verificar configuraci√≥n
    if checks[0][1]:  # Solo si .env existe
        checks.append(("Configuraci√≥n", check_configuration()))
        
        # 3. Verificar base de datos
        if checks[1][1]:  # Solo si configuraci√≥n es v√°lida
            checks.append(("Base de datos", check_database_connection()))
    
    # Resumen
    print("\n" + "="*60)
    print("üìä RESUMEN")
    print("="*60)
    
    all_passed = all(check[1] for check in checks)
    
    for name, passed in checks:
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        print(f"   {status} - {name}")
    
    print("="*60)
    
    if all_passed:
        print("\nüéâ ¬°Todas las verificaciones pasaron!")
        print("   Puedes iniciar la aplicaci√≥n con: uvicorn app.main:app --reload\n")
        return 0
    else:
        print("\n‚ö†Ô∏è  Algunas verificaciones fallaron")
        print("   Revisa los errores arriba y corr√≠gelos antes de continuar\n")
        return 1

if __name__ == "__main__":
    sys.exit(main())



================================================================================
üìÑ ARCHIVO: scripts/check_security.py
üìè Tama√±o: 7.5 KB
‚ö†Ô∏è  DATOS SENSIBLES ENMASCARADOS:
  ‚ö†Ô∏è  Encontrado 1 coincidencia(s) de tipo: (?i)(password|passwd|pwd)
================================================================================

#!/usr/bin/env python3
"""
Script para verificar la seguridad del proyecto
"""
import os
import sys
import subprocess
from pathlib import Path

root_dir = Path(__file__).parent.parent


def check_env_in_gitignore():
    """Verifica que .env est√° en .gitignore"""
    print("üîí Verificando que .env est√° protegido...")
    
    gitignore_path = root_dir / ".gitignore"
    
    if not gitignore_path.exists():
        print("   ‚ùå No existe archivo .gitignore")
        return False
    
    with open(gitignore_path) as f:
        content = f.read()
    
    if ".env" in content:
        print("   ‚úÖ .env est√° en .gitignore")
        
        # Verificar con git
        try:
            result = subprocess.run(
                ["git", "check-ignore", "-v", ".env"],
                cwd=root_dir,
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                print(f"   ‚úÖ Git confirma que .env est√° ignorado:")
                print(f"      {result.stdout.strip()}")
                return True
            else:
                print("   ‚ö†Ô∏è  Git no confirma que .env est√© ignorado")
                print("      (Esto puede ser normal si no es un repo git)")
                return True
        except FileNotFoundError:
            print("   ‚ö†Ô∏è  Git no est√° instalado (verificaci√≥n manual)")
            return True
    else:
        print("   ‚ùå .env NO est√° en .gitignore")
        print("   üí° A√±ade '.env' al archivo .gitignore")
        return False


def check_env_not_committed():
    """Verifica que .env no est√° en el repositorio"""
    print("\nüìÇ Verificando que .env no est√° en git...")
    
    try:
        # Verificar si .env est√° trackeado por git
        result = subprocess.run(
            ["git", "ls-files", ".env"],
            cwd=root_dir,
            capture_output=True,
            text=True
        )
        
        if result.stdout.strip():
            print("   ‚ùå PELIGRO: .env est√° committeado en git!")
            print("   üö® Tu archivo .env con secretos est√° en el repositorio")
            print("\n   üí° Para removerlo:")
            print("      git rm --cached .env")
            print("      git commit -m 'Remove .env from git'")
            return False
        else:
            print("   ‚úÖ .env no est√° committeado (correcto)")
            return True
    
    except FileNotFoundError:
        print("   ‚ö†Ô∏è  Git no est√° instalado (no se puede verificar)")
        return True
    except subprocess.CalledProcessError:
        print("   ‚ö†Ô∏è  No es un repositorio git")
        return True


def check_env_example_exists():
    """Verifica que existe .env.example"""
    print("\nüìù Verificando .env.example...")
    
    env_example = root_dir / ".env.example"
    
    if env_example.exists():
        print("   ‚úÖ .env.example existe")
        
        # Verificar que no tenga valores reales
        with open(env_example) as f:
            content = f.read()
        
        dangerous_patterns = [
            "gsk_",  # Groq API keys empiezan con gsk_
            "sk-",   # OpenAI keys empiezan con sk-
            "postgresql://.*:.*@",  # URLs de DB con passwords reales
        ]
        
        import re
        has_secrets = False
        for pattern in dangerous_patterns:
            if re.search(pattern, content):
                print(f"   ‚ö†Ô∏è  .env.example podr√≠a contener secretos reales (patr√≥n: {pattern})")
                has_secrets = True
        
        if not has_secrets:
            print("   ‚úÖ .env.example no parece contener secretos reales")
        
        return True
    else:
        print("   ‚ö†Ô∏è  .env.example no existe")
        print("      Considera crear uno como template")
        return False


def check_env_variables_in_code():
    """Verifica que no hay secretos hardcodeados en el c√≥digo"""
    print("\nüîç Buscando secretos hardcodeados en el c√≥digo...")
    
    dangerous_patterns = {
        "API key hardcoded": r'api[_-]?key\s*=\s*["\'][a-zA-Z0-9]{20,}["\']',
        "Password hardcoded": r'password\s*=\s*["\'][^"\']{8,}["\']',
        "Groq key": r'gsk_[a-zA-Z0-9]{40,}',
        "Database URL with password: "xxxxxxxxxx"
    }
    
    found_issues = False
    
    for py_file in root_dir.rglob("*.py"):
        # Ignorar tests y venv
        if "venv" in str(py_file) or "test" in str(py_file):
            continue
        
        try:
            with open(py_file) as f:
                content = f.read()
            
            for name, pattern in dangerous_patterns.items():
                import re
                if re.search(pattern, content, re.IGNORECASE):
                    print(f"   ‚ö†Ô∏è  Posible {name} en: {py_file.relative_to(root_dir)}")
                    found_issues = True
        except:
            pass
    
    if not found_issues:
        print("   ‚úÖ No se encontraron secretos hardcodeados obvios")
        return True
    else:
        print("   ‚ö†Ô∏è  Se encontraron posibles secretos - revisar manualmente")
        return False


def check_rate_limiting_enabled():
    """Verifica que el rate limiting est√° habilitado"""
    print("\nüö¶ Verificando rate limiting...")
    
    env_file = root_dir / ".env"
    
    if not env_file.exists():
        print("   ‚ö†Ô∏è  .env no existe")
        return False
    
    with open(env_file) as f:
        content = f.read()
    
    if "RATE_LIMIT_ENABLED=true" in content or "RATE_LIMIT_ENABLED" not in content:
        print("   ‚úÖ Rate limiting est√° habilitado")
        
        # Verificar l√≠mites configurados
        if "RATE_LIMIT_SEARCH" in content:
            print("   ‚úÖ L√≠mites de b√∫squeda configurados")
        if "RATE_LIMIT_CREATE" in content:
            print("   ‚úÖ L√≠mites de creaci√≥n configurados")
        
        return True
    else:
        print("   ‚ö†Ô∏è  Rate limiting parece estar deshabilitado")
        print("      Considera habilitarlo en producci√≥n")
        return False


def main():
    """Funci√≥n principal"""
    print("="*60)
    print("üîê VERIFICACI√ìN DE SEGURIDAD")
    print("="*60)
    
    checks = []
    
    # 1. .env en .gitignore
    checks.append(("'.env' en .gitignore", check_env_in_gitignore()))
    
    # 2. .env no committeado
    checks.append(("'.env' no committeado", check_env_not_committed()))
    
    # 3. .env.example existe
    checks.append((".env.example existe", check_env_example_exists()))
    
    # 4. No secretos hardcodeados
    checks.append(("No secretos hardcoded", check_env_variables_in_code()))
    
    # 5. Rate limiting
    checks.append(("Rate limiting habilitado", check_rate_limiting_enabled()))
    
    # Resumen
    print("\n" + "="*60)
    print("üìä RESUMEN DE SEGURIDAD")
    print("="*60)
    
    for name, passed in checks:
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        print(f"   {status} - {name}")
    
    print("="*60)
    
    all_passed = all(check[1] for check in checks)
    critical_passed = checks[0][1] and checks[1][1]  # .gitignore y no committeado
    
    if all_passed:
        print("\n‚úÖ Todas las verificaciones de seguridad pasaron!")
        return 0
    elif critical_passed:
        print("\n‚ö†Ô∏è  Algunas verificaciones fallaron, pero las cr√≠ticas pasaron")
        print("   Tu .env est√° protegido, revisa las advertencias arriba")
        return 0
    else:
        print("\nüö® VERIFICACIONES CR√çTICAS FALLARON!")
        print("   Tu archivo .env podr√≠a estar expuesto")
        print("   Revisa y corrige los errores inmediatamente")
        return 1


if __name__ == "__main__":
    sys.exit(main())



================================================================================
üìÑ ARCHIVO: scripts/check_url_clean.py
üìè Tama√±o: 0.7 KB
================================================================================

import asyncio
from sqlalchemy import select, func
from app.database import get_db_context
from app.models import Bookmark

async def check_stats():
    async with get_db_context() as db:
        # Contamos cu√°ntos han completado la limpieza de URL
        query = (
            select(func.count())
            .where(Bookmark.status == 'completed')
            .where(Bookmark.url_clean.isnot(None))
        )
        result = await db.execute(query)
        count = result.scalar()
        
        print(f"\n" + "="*40)
        print(f"‚úÖ Marcadores con url_clean: {count}")
        print("="*40 + "\n")

if __name__ == "__main__":
    asyncio.run(check_stats())


================================================================================
üìÑ ARCHIVO: scripts/example_api_usage.py
üìè Tama√±o: 5.4 KB
================================================================================

#!/usr/bin/env python3
"""
Script de ejemplo para interactuar con la Neural Bookmark Brain API
"""
import requests
import json
from typing import List, Dict


class NeuralBookmarkClient:
    """Cliente de ejemplo para la API"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
    
    def health_check(self) -> Dict:
        """Verifica el estado del sistema"""
        response = requests.get(f"{self.base_url}/health")
        return response.json()
    
    def search(
        self,
        query: str,
        limit: int = 10,
        include_nsfw: bool = False,
        category: str = None
    ) -> Dict:
        """B√∫squeda sem√°ntica"""
        payload = {
            "query": query,
            "limit": limit,
            "include_nsfw": include_nsfw
        }
        
        if category:
            payload["category"] = category
        
        response = requests.post(
            f"{self.base_url}/search",
            json=payload
        )
        
        return response.json()
    
    def get_bookmarks(
        self,
        skip: int = 0,
        limit: int = 50,
        status_filter: str = None,
        category: str = None
    ) -> List[Dict]:
        """Lista bookmarks"""
        params = {
            "skip": skip,
            "limit": limit
        }
        
        if status_filter:
            params["status_filter"] = status_filter
        
        if category:
            params["category"] = category
        
        response = requests.get(
            f"{self.base_url}/bookmarks",
            params=params
        )
        
        return response.json()
    
    def get_bookmark(self, bookmark_id: int) -> Dict:
        """Obtiene un bookmark espec√≠fico"""
        response = requests.get(f"{self.base_url}/bookmarks/{bookmark_id}")
        return response.json()
    
    def reprocess_bookmark(self, bookmark_id: int) -> Dict:
        """Re-procesa un bookmark"""
        response = requests.post(f"{self.base_url}/process/{bookmark_id}")
        return response.json()
    
    def get_processing_stats(self) -> Dict:
        """Obtiene estad√≠sticas de procesamiento"""
        response = requests.get(f"{self.base_url}/stats/processing")
        return response.json()
    
    def get_category_stats(self) -> Dict:
        """Estad√≠sticas por categor√≠a"""
        response = requests.get(f"{self.base_url}/stats/categories")
        return response.json()
    
    def get_tag_stats(self, limit: int = 20) -> Dict:
        """Top tags"""
        response = requests.get(
            f"{self.base_url}/stats/tags",
            params={"limit": limit}
        )
        return response.json()


def main():
    """Ejemplos de uso"""
    client = NeuralBookmarkClient()
    
    print("=" * 60)
    print("üß† Neural Bookmark Brain - Cliente de Ejemplo")
    print("=" * 60)
    
    # 1. Health Check
    print("\n1Ô∏è‚É£  Health Check...")
    health = client.health_check()
    print(f"   Status: {health['status']}")
    print(f"   Database: {health['database']}")
    
    # 2. Estad√≠sticas de procesamiento
    print("\n2Ô∏è‚É£  Estad√≠sticas de Procesamiento...")
    stats = client.get_processing_stats()
    print(f"   Total: {stats['total']}")
    print(f"   Completados: {stats['completed']}")
    print(f"   Pendientes: {stats['pending']}")
    print(f"   Fallidos: {stats['failed']}")
    
    # 3. Top Categor√≠as
    print("\n3Ô∏è‚É£  Top Categor√≠as...")
    categories = client.get_category_stats()
    for cat in categories['categories'][:5]:
        print(f"   - {cat['category']}: {cat['count']}")
    
    # 4. Top Tags
    print("\n4Ô∏è‚É£  Top Tags...")
    tags = client.get_tag_stats(limit=10)
    for tag in tags['tags'][:10]:
        print(f"   - #{tag['tag']}: {tag['count']}")
    
    # 5. B√∫squeda sem√°ntica
    print("\n5Ô∏è‚É£  B√∫squeda Sem√°ntica: 'machine learning tutorials'...")
    results = client.search("machine learning tutorials", limit=3)
    
    print(f"   Query: {results['query']}")
    print(f"   Resultados: {results['total']}")
    print(f"   Tiempo: {results['execution_time']:.3f}s")
    print("\n   Top 3 Resultados:")
    
    for i, result in enumerate(results['results'][:3], 1):
        bookmark = result['bookmark']
        score = result['similarity_score']
        print(f"\n   {i}. {bookmark['clean_title']}")
        print(f"      URL: {bookmark['url'][:60]}...")
        print(f"      Categor√≠a: {bookmark.get('category', 'N/A')}")
        print(f"      Tags: {', '.join(bookmark.get('tags', [])[:3])}")
        print(f"      Score: {score:.3f}")
    
    # 6. Listar bookmarks recientes
    print("\n6Ô∏è‚É£  √öltimos 5 Bookmarks Completados...")
    bookmarks = client.get_bookmarks(
        limit=5,
        status_filter="completed"
    )
    
    for i, bookmark in enumerate(bookmarks, 1):
        print(f"\n   {i}. {bookmark['clean_title']}")
        print(f"      URL: {bookmark['url'][:60]}...")
        print(f"      Categor√≠a: {bookmark.get('category', 'N/A')}")
    
    print("\n" + "=" * 60)
    print("‚úÖ Ejemplos completados!")
    print("=" * 60)


if __name__ == "__main__":
    try:
        main()
    except requests.exceptions.ConnectionError:
        print("‚ùå Error: No se pudo conectar a la API")
        print("   Aseg√∫rate de que el servidor est√© corriendo:")
        print("   docker-compose up -d")
    except Exception as e:
        print(f"‚ùå Error: {e}")



================================================================================
üìÑ ARCHIVO: scripts/import_csv.py
üìè Tama√±o: 9.4 KB
================================================================================

#!/usr/bin/env python3
"""
Script para importar bookmarks desde CSV
"""
import asyncio
import sys
from pathlib import Path
import pandas as pd
from loguru import logger
from datetime import datetime
from typing import List, Dict

# A√±adir directorio ra√≠z al path
sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy import select
from app.database import get_db_context, init_db
from app.models import Bookmark, ProcessingLog
from app.schemas import ImportStats
from app.agents import orchestrator
from app.utils.validators import URLValidator
from app.config import get_settings

settings = get_settings()


class BookmarkImporter:
    """Importador de bookmarks desde CSV"""
    
    def __init__(self, csv_path: str, batch_size: int = 10):
        self.csv_path = Path(csv_path)
        self.batch_size = batch_size
        self.stats = {
            "total_bookmarks": 0,
            "imported": 0,
            "duplicates": 0,
            "failed": 0,
            "nsfw_detected": 0,
            "local_detected": 0,
            "errors": []
        }
    
    async def import_bookmarks(self):
        """Importa bookmarks desde CSV"""
        logger.info(f"üì• Importando bookmarks desde: {self.csv_path}")
        
        # Verificar que el archivo existe
        if not self.csv_path.exists():
            logger.error(f"‚ùå Archivo no encontrado: {self.csv_path}")
            return self.stats
        
        try:
            # Leer CSV
            df = pd.read_csv(self.csv_path)
            logger.info(f"üìä CSV cargado: {len(df)} filas")
            
            # Validar columnas
            if 'url' not in df.columns or 'title' not in df.columns:
                logger.error("‚ùå CSV debe contener columnas 'url' y 'title'")
                return self.stats
            
            # Limpiar datos
            df = df.dropna(subset=['url'])  # Eliminar URLs vac√≠as
            df['title'] = df['title'].fillna('Sin t√≠tulo')  # Rellenar t√≠tulos vac√≠os
            
            self.stats["total_bookmarks"] = len(df)
            
            logger.info(f"üöÄ Procesando {len(df)} bookmarks...")
            
            # Procesar en batches
            for i in range(0, len(df), self.batch_size):
                batch = df.iloc[i:i + self.batch_size]
                logger.info(f"üì¶ Batch {i // self.batch_size + 1}/{(len(df) - 1) // self.batch_size + 1}")
                
                await self._process_batch(batch)
                
                # Pausa entre batches para no saturar
                await asyncio.sleep(1)
            
            # Resumen final
            logger.info("=" * 60)
            logger.info("üìä RESUMEN DE IMPORTACI√ìN")
            logger.info("=" * 60)
            logger.info(f"Total procesados:  {self.stats['total_bookmarks']}")
            logger.info(f"‚úÖ Importados:     {self.stats['imported']}")
            logger.info(f"üîÑ Duplicados:     {self.stats['duplicates']}")
            logger.info(f"‚ùå Fallidos:       {self.stats['failed']}")
            logger.info(f"üîû NSFW:           {self.stats['nsfw_detected']}")
            logger.info(f"üè† Locales:        {self.stats['local_detected']}")
            logger.info("=" * 60)
            
            if self.stats["errors"]:
                logger.warning(f"‚ö†Ô∏è  {len(self.stats['errors'])} errores registrados")
            
            return self.stats
        
        except Exception as e:
            logger.error(f"‚ùå Error importando CSV: {e}")
            self.stats["errors"].append(str(e))
            return self.stats
    
    async def _process_batch(self, batch: pd.DataFrame):
        """Procesa un batch de bookmarks"""
        async with get_db_context() as db:
            for _, row in batch.iterrows():
                url = row['url']
                title = row['title']
                
                try:
                    # Validar y normalizar URL
                    is_valid, normalized_url, error = URLValidator.validate_and_normalize(url)
                    
                    if not is_valid:
                        logger.warning(f"‚ö†Ô∏è  URL inv√°lida: {url} ({error})")
                        self.stats["failed"] += 1
                        self.stats["errors"].append(f"URL inv√°lida: {url}")
                        continue
                    
                    # Verificar duplicados
                    result = await db.execute(
                        select(Bookmark).where(Bookmark.url == normalized_url)
                    )
                    existing = result.scalar_one_or_none()
                    
                    if existing:
                        logger.info(f"üîÑ Duplicado: {normalized_url}")
                        self.stats["duplicates"] += 1
                        continue
                    
                    # Crear bookmark inicial
                    bookmark = Bookmark(
                        url=normalized_url,
                        original_title=title,
                        status="pending"
                    )
                    
                    db.add(bookmark)
                    await db.commit()
                    await db.refresh(bookmark)
                    
                    logger.info(f"‚úÖ Bookmark creado: {bookmark.id} - {normalized_url}")
                    
                    # Procesar con agentes
                    await self._process_bookmark(db, bookmark)
                
                except Exception as e:
                    logger.error(f"‚ùå Error procesando {url}: {e}")
                    self.stats["failed"] += 1
                    self.stats["errors"].append(f"{url}: {str(e)}")
    
    async def _process_bookmark(self, db, bookmark: Bookmark):
        """Procesa un bookmark con los agentes"""
        try:
            # Marcar como procesando
            bookmark.status = "processing"
            await db.commit()
            
            # Procesar con orquestador
            result = await orchestrator.process_bookmark(
                bookmark.url,
                bookmark.original_title
            )
            
            # Actualizar bookmark con resultados
            bookmark.clean_title = result.get("clean_title")
            bookmark.summary = result.get("summary")
            bookmark.full_text = result.get("full_text")
            bookmark.tags = result.get("tags", [])
            bookmark.category = result.get("category")
            bookmark.is_nsfw = result.get("is_nsfw", False)
            bookmark.nsfw_reason = result.get("nsfw_reason")
            bookmark.is_local = result.get("is_local", False)
            bookmark.domain = result.get("domain")
            bookmark.language = result.get("language")
            bookmark.word_count = result.get("word_count", 0)
            bookmark.embedding = result.get("embedding")
            bookmark.status = result.get("status", "failed")
            bookmark.error_message = result.get("error")
            bookmark.scraped_at = datetime.now()
            
            await db.commit()
            
            # Actualizar estad√≠sticas
            if result.get("success"):
                self.stats["imported"] += 1
                
                if bookmark.is_nsfw:
                    self.stats["nsfw_detected"] += 1
                
                if bookmark.is_local:
                    self.stats["local_detected"] += 1
                
                logger.info(
                    f"‚úÖ Procesado: {bookmark.id} - {bookmark.clean_title} "
                    f"(Status: {bookmark.status})"
                )
            else:
                self.stats["failed"] += 1
                logger.error(
                    f"‚ùå Fallo: {bookmark.id} - {bookmark.url} "
                    f"(Error: {bookmark.error_message})"
                )
            
            # Log de procesamiento
            log = ProcessingLog(
                bookmark_id=bookmark.id,
                url=bookmark.url,
                agent_name="orchestrator",
                success=result.get("success", False),
                error_message=result.get("error"),
                processing_time=result.get("processing_time", 0)
            )
            db.add(log)
            await db.commit()
        
        except Exception as e:
            logger.error(f"‚ùå Error procesando bookmark {bookmark.id}: {e}")
            bookmark.status = "failed"
            bookmark.error_message = str(e)
            await db.commit()
            
            self.stats["failed"] += 1
            self.stats["errors"].append(f"{bookmark.url}: {str(e)}")


async def main():
    """Funci√≥n principal"""
    # Argumentos
    if len(sys.argv) < 2:
        logger.error("‚ùå Uso: python import_csv.py <archivo.csv> [batch_size]")
        logger.info("Ejemplo: python import_csv.py data/bookmarks.csv 10")
        sys.exit(1)
    
    csv_path = sys.argv[1]
    batch_size = int(sys.argv[2]) if len(sys.argv) > 2 else 10
    
    logger.info("üß† Neural Bookmark Brain - Importador CSV")
    logger.info("=" * 60)
    
    try:
        # Inicializar DB
        logger.info("üîß Inicializando base de datos...")
        await init_db()
        logger.info("‚úÖ Base de datos lista")
        
        # Importar bookmarks
        importer = BookmarkImporter(csv_path, batch_size)
        stats = await importer.import_bookmarks()
        
        logger.info("üéâ Importaci√≥n completada!")
        
    except Exception as e:
        logger.error(f"‚ùå Error fatal: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())



================================================================================
üìÑ ARCHIVO: scripts/init_db.py
üìè Tama√±o: 0.9 KB
================================================================================

#!/usr/bin/env python3
"""
Script para inicializar la base de datos
"""
import asyncio
import sys
from pathlib import Path

# A√±adir directorio ra√≠z al path
sys.path.insert(0, str(Path(__file__).parent.parent))

from loguru import logger
from app.database import init_db, engine
from app.config import get_settings

settings = get_settings()


async def main():
    """Inicializa la base de datos"""
    logger.info("üîß Inicializando base de datos...")
    
    try:
        # Inicializar DB
        await init_db()
        
        logger.info("‚úÖ Base de datos inicializada correctamente")
        logger.info(f"   Database: {settings.DATABASE_URL.split('@')[1]}")
        
        # Cerrar conexi√≥n
        await engine.dispose()
        
    except Exception as e:
        logger.error(f"‚ùå Error inicializando base de datos: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())



================================================================================
üìÑ ARCHIVO: scripts/init_db.sql
üìè Tama√±o: 0.4 KB
================================================================================

-- Script de inicializaci√≥n de PostgreSQL
-- Este script se ejecuta autom√°ticamente al crear el container

-- Habilitar extensi√≥n pgvector
CREATE EXTENSION IF NOT EXISTS vector;

-- Verificar instalaci√≥n
SELECT extname, extversion FROM pg_extension WHERE extname = 'vector';

-- Mensaje de confirmaci√≥n
DO $$
BEGIN
    RAISE NOTICE 'pgvector extension enabled successfully!';
END $$;



================================================================================
üìÑ ARCHIVO: scripts/quick_stats.py
üìè Tama√±o: 0.8 KB
================================================================================

import asyncio
from sqlalchemy import select, func
from app.database import get_db_context
from app.models import Bookmark

async def get_summary():
    async with get_db_context() as db:
        # Ejecutamos las dos consultas que te interesan
        q_tracking = select(func.count()).where(Bookmark.tracking_params.isnot(None))
        q_clean = select(func.count()).where(Bookmark.url_clean.isnot(None))
        
        res_t = await db.execute(q_tracking)
        res_c = await db.execute(q_clean)
        
        print("\n" + "üìä REPORTE DE PROCESAMIENTO ".center(40, "="))
        print(f"üîç Con tracking_params : {res_t.scalar()}")
        print(f"‚ú® Con url_clean       : {res_c.scalar()}")
        print("="*40 + "\n")

if __name__ == "__main__":
    asyncio.run(get_summary())


================================================================================
üìÑ ARCHIVO: scripts/reprocess_failed.py
üìè Tama√±o: 7.3 KB
================================================================================

#!/usr/bin/env python3
"""
Script para re-procesar bookmarks fallidos de forma resiliente
"""
import asyncio
import sys
import argparse
from pathlib import Path
from loguru import logger
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy import select, func, text
from sqlalchemy.orm.attributes import flag_modified
from app.database import get_db_context, init_db
from app.models import Bookmark
from app.agents import orchestrator


async def reprocess_failed_bookmarks(limit: int = None, batch_size: int = 5):
    """
    Re-procesa bookmarks con status 'failed' o 'pending'.
    Si se proporciona un limit, solo procesar√° esa cantidad.
    """
    logger.info("üîÑ Iniciando re-procesamiento resiliente...")
    
    async with get_db_context() as db:
        # 1. Construcci√≥n de la consulta con l√≠mite real en SQL
        query = select(Bookmark).where(
            Bookmark.status.in_(['failed', 'pending'])
        ).order_by(Bookmark.created_at)
        
        if limit:
            query = query.limit(limit)
            logger.info(f"üî¢ L√≠mite de seguridad activado: {limit} registros")
        
        result = await db.execute(query)
        # Scalars().all() ahora solo traer√° el n√∫mero definido en limit
        bookmarks = result.scalars().all()
        
        total = len(bookmarks)
        
        if total == 0:
            logger.info("‚úÖ No hay bookmarks pendientes para procesar")
            return

        logger.info(f"üìä {total} bookmarks cargados para esta sesi√≥n")
        
        processed = 0
        success_count = 0
        failed_count = 0
        
        # 2. Bucle por batches (segmentando la lista ya limitada)
        for i in range(0, total, batch_size):
            batch = bookmarks[i:i + batch_size]
            current_batch_num = i // batch_size + 1
            total_batches = (total - 1) // batch_size + 1
            
            logger.info(f"üì¶ Batch {current_batch_num}/{total_batches} (Tama√±o: {len(batch)})")
            
            for bookmark in batch:
                try:
                    logger.info(f"  üîÑ Procesando [{processed + 1}/{total}]: ID {bookmark.id} - {bookmark.url[:50]}...")
                    
                    # Estado intermedio para evitar colisiones
                    bookmark.status = "processing"
                    await db.commit()
                    
                    # Llamada al orquestador
                    res = await orchestrator.process_bookmark(
                        bookmark.url,
                        bookmark.original_title
                    )
                    
                    # Actualizaci√≥n de campos
                    bookmark.clean_title = res.get("clean_title") or bookmark.original_title
                    bookmark.summary = res.get("summary")
                    bookmark.full_text = res.get("full_text")
                    bookmark.tags = res.get("tags", []) or []
                    bookmark.category = res.get("category")
                    bookmark.is_nsfw = bool(res.get("is_nsfw", False))
                    bookmark.nsfw_reason = res.get("nsfw_reason")
                    bookmark.is_local = bool(res.get("is_local", False))
                    bookmark.domain = res.get("domain")
                    bookmark.language = res.get("language")
                    bookmark.word_count = int(res.get("word_count", 0))
                    bookmark.embedding = res.get("embedding")
                    bookmark.status = res.get("status", "failed")
                    bookmark.error_message = res.get("error")
                    bookmark.scraped_at = datetime.now()
                    
                    # Campos de limpieza de URL
                    bookmark.url_clean = res.get("url_clean") if res.get("url_clean") is not None else bookmark.url
                    bookmark.tracking_params = res.get("tracking_params")
                    
                    # Forzar detecci√≥n de cambios en SQLAlchemy
                    flag_modified(bookmark, "url_clean")
                    flag_modified(bookmark, "tracking_params")
                    flag_modified(bookmark, "tags")
                    
                    await db.commit()
                    processed += 1
                    
                    if res.get("success"):
                        success_count += 1
                        logger.info(f"    ‚úÖ √âXITO ID {bookmark.id}: {bookmark.category}")
                    else:
                        failed_count += 1
                        logger.warning(f"    ‚ùå FALLO ID {bookmark.id}: {bookmark.error_message[:60]}")
                        
                        # Inserci√≥n en tabla de fallidos (SQL puro para velocidad)
                        try:
                            await db.execute(text('''
                                INSERT INTO failed_bookmarks 
                                (url_original, url_clean, domain, failure_reason, error_message, word_count, processing_time, bookmark_id)
                                VALUES (:url, :url_clean, :domain, :reason, :error, :words, :time, :bookmark_id)
                            '''), {
                                'url': bookmark.url,
                                'url_clean': res.get('url_clean'),
                                'domain': res.get('domain'),
                                'reason': 'timeout' if 'timeout' in str(res.get('error','')).lower() else 'http_error',
                                'error': res.get('error'),
                                'words': res.get('word_count', 0),
                                'time': res.get('processing_time', 0),
                                'bookmark_id': bookmark.id
                            })
                            await db.commit()
                        except Exception:
                            await db.rollback() # Evitar que un error aqu√≠ rompa el bucle
                
                except Exception as e:
                    logger.error(f"  ‚ö†Ô∏è Error cr√≠tico en bookmark {bookmark.id}: {str(e)}")
                    bookmark.status = "failed"
                    bookmark.error_message = str(e)
                    await db.commit()
                    failed_count += 1
                    continue

            # Pausa anti-bloqueo entre batches
            if i + batch_size < total:
                wait_time = 3
                logger.info(f"‚è≥ Esperando {wait_time}s para el siguiente batch...")
                await asyncio.sleep(wait_time)
        
        # Resumen final
        logger.info("=" * 60)
        logger.info(f"üìä RESUMEN: {success_count} exitosos, {failed_count} fallidos de {total} intentados")
        logger.info("=" * 60)


async def main():
    # 1. Configurar el lector de argumentos
    parser = argparse.ArgumentParser(description="Re-procesar marcadores fallidos")
    parser.add_argument('--limit', type=int, help='Cantidad m√°xima a procesar')
    
    # 2. Leer los argumentos de la terminal
    args = parser.parse_args()  # <--- AQU√ç ES DONDE SE DEFINE 'args'

    logger.info("üß† Neural Bookmark Brain - Re-procesamiento Resiliente")
    logger.info("=" * 60)
    
    try:
        # 3. Pasar el l√≠mite a la funci√≥n
        await reprocess_failed_bookmarks(limit=args.limit)
    except Exception as e:
        logger.error(f"‚ùå Error fatal: {e}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())


================================================================================
üìÑ ARCHIVO: scripts/stats.py
üìè Tama√±o: 1.1 KB
================================================================================

import asyncio
from sqlalchemy import select, func
from app.database import get_db_context
from app.models import Bookmark

async def get_stats():
    async with get_db_context() as db:
        # Consulta 1: Con tracking_params
        q1 = select(func.count()).where(Bookmark.tracking_params.isnot(None))
        res1 = await db.execute(q1)
        tracking_count = res1.scalar()

        # Consulta 2: Con url_clean
        q2 = select(func.count()).where(Bookmark.url_clean.isnot(None))
        res2 = await db.execute(q2)
        clean_count = res2.scalar()

        # Consulta 3: Total procesados
        q3 = select(func.count()).where(Bookmark.status == 'completed')
        res3 = await db.execute(q3)
        completed_count = res3.scalar()

        print("\n" + "üìä ESTADO DE LA BASE DE DATOS ".center(40, "="))
        print(f"‚úÖ Total completados:      {completed_count}")
        print(f"‚úÖ Con URL limpia:         {clean_count}")
        print(f"‚úÖ Con par√°metros detectados: {tracking_count}")
        print("="*40 + "\n")

if __name__ == "__main__":
    asyncio.run(get_stats())


================================================================================
üìÑ ARCHIVO: scripts/test_scraper_limits.py
üìè Tama√±o: 4.3 KB
================================================================================

#!/usr/bin/env python3
"""
Script para probar las limitaciones del scraper
"""
import asyncio
import sys
from pathlib import Path
from datetime import datetime

# A√±adir el directorio ra√≠z al path
root_dir = Path(__file__).parent.parent
sys.path.insert(0, str(root_dir))

from app.services.scraper import ResilientScraper
from app.config import get_settings

settings = get_settings()


async def test_rate_limiting():
    """Test b√°sico de rate limiting"""
    print("üïê Testeando rate limiting...\n")
    
    scraper = ResilientScraper()
    
    print(f"‚öôÔ∏è  Configuraci√≥n actual:")
    print(f"   ‚Ä¢ Delay entre peticiones: {scraper.delay_between_requests}s")
    print(f"   ‚Ä¢ Timeout: {scraper.timeout}s")
    print(f"   ‚Ä¢ Max redirects: {scraper.max_redirects}")
    print(f"   ‚Ä¢ Max retries: {scraper.max_retries}\n")
    
    # Simular 3 peticiones
    print("üì° Simulando 3 peticiones consecutivas...\n")
    
    for i in range(1, 4):
        start = datetime.now()
        await scraper._rate_limit()
        duration = (datetime.now() - start).total_seconds()
        
        print(f"   Petici√≥n {i}: {duration:.3f}s de espera")
    
    print("\n‚úÖ Rate limiting funcionando correctamente")


async def test_real_url(url: str):
    """Test con URL real"""
    print(f"\nüåê Testeando scraping de URL real: {url}\n")
    
    scraper = ResilientScraper()
    
    start = datetime.now()
    result = await scraper.scrape_url(url)
    duration = (datetime.now() - start).total_seconds()
    
    print(f"\nüìä Resultado del scraping ({duration:.2f}s):")
    print(f"   ‚Ä¢ Success: {result['success']}")
    print(f"   ‚Ä¢ Strategy: {result.get('strategy', 'N/A')}")
    print(f"   ‚Ä¢ Attempts: {result.get('attempts', 0)}")
    print(f"   ‚Ä¢ Error type: {result.get('error_type', 'N/A')}")
    
    if result['success']:
        print(f"   ‚Ä¢ Title: {result.get('title', 'N/A')[:50]}...")
        print(f"   ‚Ä¢ Word count: {result.get('word_count', 0)}")
        print(f"   ‚Ä¢ Domain: {result.get('domain', 'N/A')}")
    else:
        print(f"   ‚Ä¢ Error: {result.get('error_message', 'N/A')[:100]}")


async def test_multiple_urls():
    """Test con m√∫ltiples URLs para verificar rate limiting"""
    urls = [
        "https://example.com",
        "https://httpbin.org/html",
        "https://www.python.org",
    ]
    
    print(f"\nüîÑ Testeando {len(urls)} URLs con rate limiting...\n")
    
    scraper = ResilientScraper()
    
    overall_start = datetime.now()
    
    for i, url in enumerate(urls, 1):
        print(f"[{i}/{len(urls)}] Scraping: {url}")
        start = datetime.now()
        
        result = await scraper.scrape_url(url)
        
        duration = (datetime.now() - start).total_seconds()
        status = "‚úÖ" if result['success'] else "‚ùå"
        
        print(f"    {status} {duration:.2f}s - {result.get('strategy', 'N/A')}")
    
    total_duration = (datetime.now() - overall_start).total_seconds()
    expected_minimum = scraper.delay_between_requests * (len(urls) - 1)
    
    print(f"\n‚è±Ô∏è  Tiempo total: {total_duration:.2f}s")
    print(f"    (m√≠nimo esperado con rate limiting: {expected_minimum:.2f}s)")
    
    if total_duration >= expected_minimum * 0.9:
        print("‚úÖ Rate limiting est√° funcionando correctamente")
    else:
        print("‚ö†Ô∏è  Rate limiting podr√≠a no estar funcionando como esperado")


def main():
    """Funci√≥n principal"""
    print("="*60)
    print("üß™ TEST DE LIMITACIONES DEL SCRAPER")
    print("="*60)
    
    # Test 1: Rate limiting b√°sico
    asyncio.run(test_rate_limiting())
    
    # Test 2: URL real (opcional)
    if len(sys.argv) > 1:
        url = sys.argv[1]
        asyncio.run(test_real_url(url))
    
    # Test 3: M√∫ltiples URLs
    asyncio.run(test_multiple_urls())
    
    print("\n" + "="*60)
    print("‚úÖ Tests completados")
    print("="*60)


if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] in ["-h", "--help"]:
        print("Uso:")
        print("  python scripts/test_scraper_limits.py              # Tests b√°sicos")
        print("  python scripts/test_scraper_limits.py <URL>        # Incluir test con URL espec√≠fica")
        print("\nEjemplo:")
        print("  python scripts/test_scraper_limits.py https://example.com")
        sys.exit(0)
    
    main()



================================================================================
üìÑ ARCHIVO: scripts/verify_installation.py
üìè Tama√±o: 5.0 KB
‚ö†Ô∏è  DATOS SENSIBLES ENMASCARADOS:
  ‚ö†Ô∏è  Encontrado 1 coincidencia(s) de tipo: (?i)(api
================================================================================

#!/usr/bin/env python3
"""
Script de verificaci√≥n de instalaci√≥n y dependencias
"""
import sys
import subprocess
from pathlib import Path


def check_python_version():
    """Verifica versi√≥n de Python"""
    print("üêç Verificando Python...")
    version = sys.version_info
    
    if version.major == 3 and version.minor >= 11:
        print(f"   ‚úÖ Python {version.major}.{version.minor}.{version.micro}")
        return True
    else:
        print(f"   ‚ùå Python {version.major}.{version.minor}.{version.micro} - Se requiere 3.11+")
        return False


def check_docker():
    """Verifica Docker"""
    print("\nüê≥ Verificando Docker...")
    try:
        result = subprocess.run(
            ["docker", "--version"],
            capture_output=True,
            text=True,
            check=True
        )
        print(f"   ‚úÖ {result.stdout.strip()}")
        return True
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("   ‚ùå Docker no encontrado")
        return False


def check_docker_compose():
    """Verifica Docker Compose"""
    print("\nüê≥ Verificando Docker Compose...")
    try:
        result = subprocess.run(
            ["docker-compose", "--version"],
            capture_output=True,
            text=True,
            check=True
        )
        print(f"   ‚úÖ {result.stdout.strip()}")
        return True
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("   ‚ùå Docker Compose no encontrado")
        return False


def check_env_file():
    """Verifica archivo .env"""
    print("\n‚öôÔ∏è  Verificando configuraci√≥n...")
    env_file = Path(".env")
    
    if env_file.exists():
        print("   ‚úÖ Archivo .env encontrado")
        
        # Verificar GROQ_API_KEY
        with open(env_file) as f:
            content = f.read()
            if "GROQ_API_KEY: "xxxxxxxxxx"" in content:
                print("   ‚ö†Ô∏è  ADVERTENCIA: GROQ_API_KEY no configurada")
                print("      Edita .env y a√±ade tu API key de Groq")
                return False
            elif "GROQ_API_KEY=" in content:
                print("   ‚úÖ GROQ_API_KEY configurada")
                return True
    else:
        print("   ‚ùå Archivo .env no encontrado")
        print("      Copia .env.example a .env y configura las variables")
        return False


def check_data_directory():
    """Verifica directorio de datos"""
    print("\nüìÅ Verificando directorio de datos...")
    data_dir = Path("data")
    
    if data_dir.exists():
        print("   ‚úÖ Directorio data/ existe")
        
        # Buscar archivos CSV
        csv_files = list(data_dir.glob("*.csv"))
        if csv_files:
            print(f"   ‚ÑπÔ∏è  {len(csv_files)} archivo(s) CSV encontrado(s):")
            for csv_file in csv_files[:5]:
                print(f"      - {csv_file.name}")
        else:
            print("   ‚ÑπÔ∏è  No hay archivos CSV en data/")
            print("      Copia tu bookmarks.csv a data/ para importar")
        
        return True
    else:
        print("   ‚ö†Ô∏è  Directorio data/ no existe")
        data_dir.mkdir()
        print("   ‚úÖ Directorio data/ creado")
        return True


def check_requirements():
    """Verifica requirements.txt"""
    print("\nüì¶ Verificando dependencias...")
    req_file = Path("requirements.txt")
    
    if req_file.exists():
        print("   ‚úÖ requirements.txt encontrado")
        
        # Contar dependencias
        with open(req_file) as f:
            packages = [line.strip() for line in f if line.strip() and not line.startswith("#")]
        
        print(f"   ‚ÑπÔ∏è  {len(packages)} paquetes listados")
        return True
    else:
        print("   ‚ùå requirements.txt no encontrado")
        return False


def main():
    """Verificaci√≥n principal"""
    print("=" * 60)
    print("üß† Neural Bookmark Brain - Verificaci√≥n de Instalaci√≥n")
    print("=" * 60)
    
    checks = {
        "Python 3.11+": check_python_version(),
        "Docker": check_docker(),
        "Docker Compose": check_docker_compose(),
        "Configuraci√≥n (.env)": check_env_file(),
        "Directorio de datos": check_data_directory(),
        "Dependencias": check_requirements(),
    }
    
    print("\n" + "=" * 60)
    print("üìä RESUMEN")
    print("=" * 60)
    
    for check_name, result in checks.items():
        status = "‚úÖ" if result else "‚ùå"
        print(f"{status} {check_name}")
    
    all_passed = all(checks.values())
    
    print("\n" + "=" * 60)
    
    if all_passed:
        print("‚úÖ ¬°Todo listo! Puedes continuar con:")
        print("\n   docker-compose up -d")
        print("   make import-csv FILE=data/bookmarks.csv")
        print("\n   O consulta el README.md para m√°s informaci√≥n")
    else:
        print("‚ö†Ô∏è  Algunas verificaciones fallaron")
        print("   Revisa los errores arriba y corrige antes de continuar")
        print("   Consulta README.md para m√°s ayuda")
    
    print("=" * 60)
    
    return 0 if all_passed else 1


if __name__ == "__main__":
    sys.exit(main())



================================================================================
üìÑ ARCHIVO: scripts/verify_pipeline.py
üìè Tama√±o: 2.4 KB
================================================================================

from app.database import get_db_context
import asyncio
from app.models import Bookmark
from sqlalchemy import select, func
import numpy as np

async def verify():
    async with get_db_context() as db:
        # 1. Obtener total completados
        total_res = await db.execute(select(func.count()).where(Bookmark.status == 'completed'))
        completed = total_res.scalar() or 0

        # 2. Obtener 5 ejemplos
        result = await db.execute(
            select(Bookmark).where(Bookmark.status == 'completed').limit(5)
        )
        bookmarks = result.scalars().all()
        
        print(f'\n=== VERIFICACI√ìN DE CAMPOS CR√çTICOS ({len(bookmarks)} ejemplos) ===')
        for i, bm in enumerate(bookmarks, 1):
            # Verificaci√≥n segura de embedding
            emb_status = "‚ùå NULL"
            if bm.embedding is not None:
                emb_len = len(bm.embedding)
                emb_status = "‚úÖ" if emb_len == 384 else f"‚ùå {emb_len}d"

            print(f'\n[{i}] {bm.url[:60]}...')
            print(f'    url_clean       : {"‚úÖ" if bm.url_clean else "‚ùå NULL"}')
            print(f'    clean_title     : {"‚úÖ" if bm.clean_title and len(bm.clean_title) > 5 else "‚ùå Vac√≠o/corto"}')
            print(f'    summary         : {"‚úÖ" if bm.summary and len(bm.summary) > 20 else "‚ùå Vac√≠o/corto"}')
            print(f'    embedding       : {emb_status}')
            print(f'    category        : {bm.category or "N/A"}')
        
        # 3. Estad√≠sticas agregadas
        print('\n=== ESTAD√çSTICAS AGREGADAS ===')
        if completed > 0:
            # Simplificamos la query para evitar problemas de tipos en el conteo
            print(f'Total completados   : {completed}')
            
            # Contar embeddings reales
            emb_res = await db.execute(select(func.count()).where(Bookmark.status == 'completed', Bookmark.embedding.isnot(None)))
            emb_ok = emb_res.scalar() or 0
            
            # Contar categor√≠as
            cat_res = await db.execute(select(func.count()).where(Bookmark.status == 'completed', Bookmark.category.isnot(None)))
            cat_ok = cat_res.scalar() or 0

            print(f'Embeddings (384d)   : {emb_ok} / {completed}')
            print(f'Categor√≠as asignadas: {cat_ok} / {completed}')
        else:
            print("No hay marcadores con status 'completed' todav√≠a.")

if __name__ == "__main__":
    asyncio.run(verify())


================================================================================
üìÑ ARCHIVO: scripts/verify_urls.py
üìè Tama√±o: 0.6 KB
================================================================================

import asyncio
from sqlalchemy import select
from app.database import get_db_context
from app.models import Bookmark

async def test_view():
    async with get_db_context() as db:
        # Traemos 3 ejemplos que tengan URL limpia
        query = select(Bookmark.url, Bookmark.url_clean).where(Bookmark.url_clean.isnot(None)).limit(3)
        result = await db.execute(query)
        
        print("\n" + "üîç MUESTRA DE LIMPIEZA DE URLS ".center(60, "="))
        for url, clean in result:
            print(f"üîπ ORIGINAL: {url}")
            print(f"‚ú® LIMPIA:   {clean}")
            print("-" * 60)

if __name__ == "__main__":
    asyncio.run(test_view())


================================================================================
üìÑ ARCHIVO: sprint1/agents_resilient.py
üìè Tama√±o: 24.1 KB
================================================================================

# app/agents.py - VERSI√ìN CON RESILIENCIA Y ESTADOS PARCIALES

from groq import AsyncGroq
from typing import Dict, List, Optional, Tuple
from loguru import logger
import json
import re
from datetime import datetime
from urllib.parse import urlparse
import tldextract

from app.config import get_settings
from app.services.scraper import scraper
from app.services.classifier import classifier
from app.services.embeddings import get_embedding_service

settings = get_settings()


class ArchivistAgent:
    """
    Agente 1: El Archivista (The Gatekeeper) - VERSI√ìN RESILIENTE
    
    Responsabilidades:
    - Validar URLs
    - Scraping resiliente con m√∫ltiples estrategias
    - Clasificaci√≥n de seguridad (NSFW)
    - Limpieza de t√≠tulos gen√©ricos
    - Detecci√≥n de URLs locales
    - Clasificaci√≥n de errores
    """
    
    def __init__(self):
        self.name = "Archivist"
        self.groq_client = AsyncGroq(api_key=settings.GROQ_API_KEY)
        self.embedding_service = get_embedding_service()
    
    async def process(self, url: str, original_title: str) -> Dict:
        """
        Procesa un bookmark a trav√©s del Agente Archivista
        
        Returns:
            Dict con: clean_title, full_text, is_nsfw, scraping_status, error_type, etc.
        """
        logger.info(f"[{self.name}] Procesando: {url}")
        
        result = {
            "success": False,
            "clean_title": original_title,
            "full_text": None,
            "is_nsfw": False,
            "nsfw_reason": None,
            "is_local": False,
            "domain": None,
            "language": None,
            "word_count": 0,
            "error": None,
            # Nuevos campos de resiliencia
            "scraping_status": "pending",
            "scraping_strategy": None,
            "scraping_error_type": None,
            "scraping_attempts": 0,
        }
        
        try:
            # 1. Scraping del contenido con estrategias resilientes
            scraped = await scraper.scrape_url(url)
            
            result["domain"] = scraped.get("domain")
            result["language"] = scraped.get("language")
            result["word_count"] = scraped.get("word_count", 0)
            result["scraping_strategy"] = scraped.get("strategy")
            result["scraping_error_type"] = scraped.get("error_type")
            result["scraping_attempts"] = scraped.get("attempts", 0)
            
            # Si es URL local
            if scraped.get("error_type") == "local_url":
                result["is_local"] = True
                result["scraping_status"] = "skipped"
                result["error"] = scraped["error_message"]
                logger.warning(f"[{self.name}] URL local detectada: {url}")
                return result
            
            # Si scraping fue exitoso
            if scraped["success"]:
                result["scraping_status"] = "success"
                result["full_text"] = scraped.get("text", "")
                
                # 2. Obtener t√≠tulo limpio
                scraped_title = scraped.get("title", original_title)
                clean_title = scraper.extract_clean_title(
                    scraped_title or original_title,
                    result["domain"]
                )
                result["clean_title"] = clean_title
                
                # 3. Clasificaci√≥n de seguridad (NSFW)
                is_nsfw, nsfw_reason = classifier.classify(
                    url=url,
                    title=clean_title,
                    text=result["full_text"]
                )
                
                result["is_nsfw"] = is_nsfw
                result["nsfw_reason"] = nsfw_reason
                
                if is_nsfw:
                    logger.warning(
                        f"[{self.name}] Contenido NSFW detectado: {url} "
                        f"(Raz√≥n: {nsfw_reason})"
                    )
                
                # 4. Si el t√≠tulo sigue siendo gen√©rico, mejorar con AI
                if self._is_generic_title(clean_title) and result["full_text"]:
                    logger.info(f"[{self.name}] Mejorando t√≠tulo gen√©rico con AI")
                    enhanced_title = await self._enhance_title_with_ai(
                        clean_title, result["full_text"][:1000]
                    )
                    if enhanced_title:
                        result["clean_title"] = enhanced_title
                
                result["success"] = True
                logger.info(
                    f"[{self.name}] ‚úÖ Procesamiento exitoso: {url} "
                    f"({result['word_count']} palabras, estrategia: {result['scraping_strategy']})"
                )
            
            else:
                # Scraping fall√≥ pero tenemos metadata de error
                result["scraping_status"] = "failed"
                result["error"] = scraped.get("error_message", "Error desconocido en scraping")
                
                logger.warning(
                    f"[{self.name}] ‚ö†Ô∏è Scraping fallido: {url} "
                    f"(Tipo: {result['scraping_error_type']}, Intentos: {result['scraping_attempts']})"
                )
                
                # A√∫n as√≠ intentamos limpiar el t√≠tulo original
                result["clean_title"] = scraper.extract_clean_title(
                    original_title,
                    result["domain"]
                )
        
        except Exception as e:
            result["error"] = str(e)
            result["scraping_status"] = "failed"
            result["scraping_error_type"] = "unexpected_error"
            logger.error(f"[{self.name}] Error procesando {url}: {e}")
        
        return result
    
    def _is_generic_title(self, title: str) -> bool:
        """Verifica si el t√≠tulo sigue siendo gen√©rico"""
        generic_patterns = [
            r"p√°gina principal",
            r"main page",
            r"home",
            r"index",
            r"welcome",
            r"^[a-z0-9\-]+\.(com|net|org)",  # Solo dominio
        ]
        
        title_lower = title.lower()
        
        for pattern in generic_patterns:
            if re.search(pattern, title_lower):
                return True
        
        return False
    
    async def _enhance_title_with_ai(
        self,
        original_title: str,
        text_sample: str
    ) -> Optional[str]:
        """Mejora el t√≠tulo usando AI si es gen√©rico"""
        try:
            prompt = f"""Analiza el siguiente contenido web y genera un t√≠tulo descriptivo y conciso (m√°ximo 60 caracteres).

T√≠tulo original: {original_title}

Contenido:
{text_sample}

Responde SOLO con el nuevo t√≠tulo, nada m√°s."""

            response = await self.groq_client.chat.completions.create(
                model=settings.GROQ_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=getattr(settings, 'GROQ_TEMPERATURE', 0.3),
                max_tokens=100,
            )
            
            enhanced_title = response.choices[0].message.content.strip()
            
            # Validar que no sea muy largo
            if len(enhanced_title) > 100:
                enhanced_title = enhanced_title[:97] + "..."
            
            logger.info(f"[{self.name}] T√≠tulo mejorado: {enhanced_title}")
            return enhanced_title
        
        except Exception as e:
            logger.error(f"[{self.name}] Error mejorando t√≠tulo con AI: {e}")
            return None


class CuratorAgent:
    """
    Agente 2: El Curador (The Librarian) - VERSI√ìN CON MODO FALLBACK
    
    Responsabilidades:
    - Generar resumen (3 oraciones)
    - Crear tags tem√°ticos
    - Asignar categor√≠a
    - Generar embeddings sem√°nticos
    - NUEVO: Modo fallback para URLs sin contenido
    """
    
    def __init__(self):
        self.name = "Curator"
        self.groq_client = AsyncGroq(api_key=settings.GROQ_API_KEY)
        self.embedding_service = get_embedding_service()
    
    async def process(
        self,
        clean_title: str,
        full_text: Optional[str],
        url: str
    ) -> Dict:
        """
        Procesa contenido a trav√©s del Agente Curador
        AUTOM√ÅTICAMENTE decide entre modo full_text o url_only
        
        Returns:
            Dict con: summary, tags, category, embedding, curation_mode, confidence
        """
        logger.info(f"[{self.name}] Curando contenido de: {url}")
        
        result = {
            "success": False,
            "summary": None,
            "tags": [],
            "category": None,
            "embedding": None,
            "error": None,
            "curation_status": "pending",
            "curation_mode": None,
            "confidence": 0.0,
        }
        
        try:
            # Decidir modo basado en disponibilidad de texto
            if full_text and len(full_text.strip()) >= 50:
                # MODO NORMAL: Texto completo disponible
                logger.info(f"[{self.name}] Modo: full_text ({len(full_text)} chars)")
                ai_result = await self._process_full_text(clean_title, full_text, url)
                result["curation_mode"] = "full_text"
                result["confidence"] = 1.0  # Alta confianza
            else:
                # MODO FALLBACK: Solo URL + t√≠tulo
                logger.warning(f"[{self.name}] Modo: url_only (texto insuficiente)")
                ai_result = await self._process_url_only(clean_title, url)
                result["curation_mode"] = "url_only"
                result["confidence"] = ai_result.get("confidence", 0.5)
            
            if ai_result and ai_result.get("success"):
                result["summary"] = ai_result.get("summary")
                result["tags"] = ai_result.get("tags", [])
                result["category"] = ai_result.get("category")
                
                # Generar embedding
                text_for_embedding = f"{clean_title}. {result['summary']}"
                embedding = self.embedding_service.generate_embedding(text_for_embedding)
                result["embedding"] = embedding
                
                result["success"] = True
                result["curation_status"] = "success" if result["curation_mode"] == "full_text" else "fallback"
                
                logger.info(
                    f"[{self.name}] ‚úÖ Curaci√≥n exitosa: {url} "
                    f"(Modo: {result['curation_mode']}, Categor√≠a: {result['category']}, "
                    f"Confidence: {result['confidence']:.2f})"
                )
            else:
                result["error"] = ai_result.get("error", "Error en an√°lisis AI")
                result["curation_status"] = "failed"
                logger.error(f"[{self.name}] Error en an√°lisis AI: {url}")
        
        except Exception as e:
            result["error"] = str(e)
            result["curation_status"] = "failed"
            logger.error(f"[{self.name}] Error curando {url}: {e}")
        
        return result
    
    async def _process_full_text(
        self,
        title: str,
        text: str,
        url: str
    ) -> Optional[Dict]:
        """Modo normal: an√°lisis con texto completo"""
        try:
            # Truncar texto para no exceder l√≠mites
            text_truncated = text[:3000]
            
            prompt = f"""Analiza el siguiente contenido web y genera metadata estructurada.

T√≠tulo: {title}

Contenido:
{text_truncated}

Responde en formato JSON con esta estructura exacta:
{{
  "summary": "Resumen de exactamente 3 oraciones que capture la esencia del contenido",
  "tags": ["tag1", "tag2", "tag3", "tag4", "tag5"],
  "category": "una categor√≠a principal"
}}

Categor√≠as v√°lidas: Tecnolog√≠a, Negocios, Educaci√≥n, Entretenimiento, Salud, Ciencia, Arte, Deportes, Noticias, Programaci√≥n, Dise√±o, Marketing, Finanzas, Productividad, Transporte, Otros

Tags: Genera 5-7 tags relevantes, espec√≠ficos y descriptivos.

Responde SOLO con el JSON, sin explicaciones adicionales."""

            response = await self.groq_client.chat.completions.create(
                model=settings.GROQ_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=getattr(settings, 'GROQ_TEMPERATURE', 0.3),
                max_tokens=getattr(settings, 'GROQ_MAX_TOKENS', 2048),
            )
            
            content = response.choices[0].message.content.strip()
            
            # Extraer JSON del contenido
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                analysis = json.loads(json_str)
                
                # Validar estructura
                if all(key in analysis for key in ["summary", "tags", "category"]):
                    # Limpiar tags (lowercase, sin duplicados)
                    analysis["tags"] = list(set(
                        tag.lower().strip() for tag in analysis["tags"]
                    ))
                    
                    analysis["success"] = True
                    logger.info(f"[{self.name}] An√°lisis AI completado (full_text)")
                    return analysis
            
            logger.error(f"[{self.name}] JSON inv√°lido en respuesta AI")
            return {"success": False, "error": "JSON inv√°lido"}
        
        except json.JSONDecodeError as e:
            logger.error(f"[{self.name}] Error parseando JSON: {e}")
            return {"success": False, "error": f"JSON parse error: {e}"}
        
        except Exception as e:
            logger.error(f"[{self.name}] Error en an√°lisis AI: {e}")
            return {"success": False, "error": str(e)}
    
    async def _process_url_only(
        self,
        title: str,
        url: str
    ) -> Optional[Dict]:
        """
        MODO FALLBACK: Categorizaci√≥n solo con URL + t√≠tulo
        Usa an√°lisis estructurado de la URL y conocimiento de dominios
        """
        try:
            # Analizar URL de forma estructurada
            domain_info = self._analyze_domain(url)
            path_info = self._analyze_path(url)
            
            prompt = f"""Analiza esta informaci√≥n limitada de un bookmark:

URL: {url}
T√≠tulo original: {title}

Informaci√≥n del dominio:
- Dominio: {domain_info['domain']}
- TLD: {domain_info['tld']}
- Subdominios: {domain_info['subdomains']}

Informaci√≥n del path:
- Segmentos: {path_info['segments']}
- Keywords detectadas: {path_info['keywords']}

CONTEXTO IMPORTANTE: No pudimos acceder al contenido de la p√°gina (bloqueado, timeout o error).
Usa tu conocimiento previo sobre este dominio y los patrones en la URL para hacer una inferencia educada.

Genera metadata en formato JSON:
{{
  "summary": "Resumen de 2 oraciones sobre qu√© probablemente contiene esta p√°gina",
  "tags": ["tag1", "tag2", "tag3", "tag4"],
  "category": "una categor√≠a principal",
  "confidence": 0.7
}}

Categor√≠as v√°lidas: Tecnolog√≠a, Negocios, Educaci√≥n, Entretenimiento, Salud, Ciencia, Arte, Deportes, Noticias, Programaci√≥n, Dise√±o, Marketing, Finanzas, Productividad, Transporte, Otros

EJEMPLOS de buenas inferencias:
- URL "https://www.tmb.cat/es/horarios-metro" ‚Üí Category: "Transporte", Tags: ["transporte p√∫blico", "metro", "barcelona"], Confidence: 0.8
- URL "https://www.coursera.org/learn/machine-learning" ‚Üí Category: "Educaci√≥n", Tags: ["educaci√≥n online", "machine learning"], Confidence: 0.9
- URL "https://github.com/user/awesome-python" ‚Üí Category: "Programaci√≥n", Tags: ["python", "github", "recursos"], Confidence: 0.9

Confidence:
- 0.9-1.0: Dominio muy conocido (google.com, github.com, wikipedia.org)
- 0.7-0.8: Dominio reconocible o path muy descriptivo
- 0.5-0.6: Dominio desconocido pero path informativo
- 0.3-0.4: Muy poca informaci√≥n disponible

Responde SOLO con el JSON."""

            response = await self.groq_client.chat.completions.create(
                model=settings.GROQ_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,  # M√°s conservadora para inferencias
                max_tokens=500,
            )
            
            content = response.choices[0].message.content.strip()
            
            # Parsear JSON
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                analysis = json.loads(json_str)
                
                if all(key in analysis for key in ["summary", "tags", "category"]):
                    analysis["tags"] = list(set(
                        tag.lower().strip() for tag in analysis["tags"]
                    ))
                    analysis["success"] = True
                    
                    logger.info(
                        f"[{self.name}] An√°lisis AI completado (url_only) - "
                        f"Confidence: {analysis.get('confidence', 0.5):.2f}"
                    )
                    return analysis
            
            return {"success": False, "error": "JSON inv√°lido"}
        
        except Exception as e:
            logger.error(f"[{self.name}] Error en an√°lisis url_only: {e}")
            return {"success": False, "error": str(e)}
    
    def _analyze_domain(self, url: str) -> Dict:
        """Extrae informaci√≥n estructurada del dominio"""
        extracted = tldextract.extract(url)
        
        return {
            "domain": extracted.domain,
            "tld": extracted.suffix,
            "subdomains": extracted.subdomain.split('.') if extracted.subdomain else [],
            "full_domain": f"{extracted.domain}.{extracted.suffix}"
        }
    
    def _analyze_path(self, url: str) -> Dict:
        """Analiza el path de la URL para extraer keywords"""
        parsed = urlparse(url)
        segments = [s for s in parsed.path.split('/') if s]
        
        # Keywords comunes en URLs por categor√≠a
        category_keywords = {
            'transporte': ['bus', 'metro', 'tren', 'transport', 'horario', 'schedule', 'tmb', 'renfe'],
            'educaci√≥n': ['curso', 'clase', 'university', 'edu', 'learning', 'tutorial', 'coursera'],
            'programaci√≥n': ['github', 'code', 'dev', 'api', 'docs', 'python', 'javascript'],
            'noticias': ['news', 'noticias', 'article', 'post', 'blog'],
        }
        
        found_keywords = []
        for segment in segments:
            segment_lower = segment.lower()
            for category, keywords in category_keywords.items():
                if any(kw in segment_lower for kw in keywords):
                    found_keywords.append(category)
                    break
        
        return {
            "segments": segments,
            "keywords": list(set(found_keywords))  # Sin duplicados
        }


class AgentOrchestrator:
    """
    Orquestador de Agentes - VERSI√ìN CON ESTADOS PARCIALES
    
    Coordina el flujo de procesamiento entre Archivista y Curador
    Permite procesamiento parcial exitoso
    """
    
    def __init__(self):
        self.archivist = ArchivistAgent()
        self.curator = CuratorAgent()
    
    async def process_bookmark(
        self,
        url: str,
        original_title: str
    ) -> Dict:
        """
        Procesa un bookmark completo a trav√©s de ambos agentes
        GARANTIZA que siempre se intenta la curaci√≥n, incluso si scraping falla
        
        Returns:
            Dict completo con todos los campos procesados y estados parciales
        """
        start_time = datetime.now()
        
        logger.info(f"[Orchestrator] Iniciando procesamiento: {url}")
        
        result = {
            "success": False,
            "url": url,
            "original_title": original_title,
            "clean_title": original_title,
            "summary": None,
            "full_text": None,
            "tags": [],
            "category": None,
            "is_nsfw": False,
            "nsfw_reason": None,
            "is_local": False,
            "domain": None,
            "language": None,
            "word_count": 0,
            "embedding": None,
            # Estados
            "status": "failed",
            "scraping_status": "pending",
            "scraping_strategy": None,
            "scraping_error_type": None,
            "scraping_attempts": 0,
            "curation_status": "pending",
            "curation_mode": None,
            "confidence_score": 0.0,
            # Metadata
            "error": None,
            "processing_time": 0,
        }
        
        try:
            # FASE 1: Agente Archivista
            archivist_result = await self.archivist.process(url, original_title)
            
            # Actualizar resultado
            result.update({
                "clean_title": archivist_result.get("clean_title", original_title),
                "full_text": archivist_result.get("full_text"),
                "is_nsfw": archivist_result.get("is_nsfw", False),
                "nsfw_reason": archivist_result.get("nsfw_reason"),
                "is_local": archivist_result.get("is_local", False),
                "domain": archivist_result.get("domain"),
                "language": archivist_result.get("language"),
                "word_count": archivist_result.get("word_count", 0),
                "scraping_status": archivist_result.get("scraping_status", "failed"),
                "scraping_strategy": archivist_result.get("scraping_strategy"),
                "scraping_error_type": archivist_result.get("scraping_error_type"),
                "scraping_attempts": archivist_result.get("scraping_attempts", 0),
            })
            
            # Si es local, marcar para manual
            if result["is_local"]:
                result["status"] = "manual_required"
                result["error"] = archivist_result.get("error")
                logger.warning(f"[Orchestrator] URL local - Manual requerido: {url}")
                return result
            
            # FASE 2: Agente Curador (SIEMPRE se ejecuta, incluso si scraping fall√≥)
            curator_result = await self.curator.process(
                result["clean_title"],
                result["full_text"],  # Puede ser None
                url
            )
            
            if curator_result["success"]:
                result.update({
                    "summary": curator_result.get("summary"),
                    "tags": curator_result.get("tags", []),
                    "category": curator_result.get("category"),
                    "embedding": curator_result.get("embedding"),
                    "curation_status": curator_result.get("curation_status"),
                    "curation_mode": curator_result.get("curation_mode"),
                    "confidence_score": curator_result.get("confidence", 0.0),
                })
                
                # Determinar estado final
                if result["scraping_status"] == "success":
                    result["status"] = "completed"
                    result["success"] = True
                else:
                    # Scraping fall√≥ pero curaci√≥n exitosa
                    result["status"] = "completed_partial"
                    result["success"] = True
                    result["error"] = archivist_result.get("error")
                
                logger.info(
                    f"[Orchestrator] ‚úÖ Procesamiento exitoso: {url} "
                    f"(Status: {result['status']}, Confidence: {result['confidence_score']:.2f})"
                )
            else:
                # Tanto scraping como curaci√≥n fallaron
                result["status"] = "failed"
                result["curation_status"] = "failed"
                result["error"] = curator_result.get("error") or archivist_result.get("error")
                logger.error(f"[Orchestrator] ‚ùå Procesamiento fallido: {url}")
        
        except Exception as e:
            result["status"] = "failed"
            result["error"] = str(e)
            logger.error(f"[Orchestrator] Error general: {e}")
        
        finally:
            # Calcular tiempo de procesamiento
            end_time = datetime.now()
            result["processing_time"] = (end_time - start_time).total_seconds()
            
            logger.info(
                f"[Orchestrator] Procesamiento completado: {url} "
                f"(Status: {result['status']}, Tiempo: {result['processing_time']:.2f}s)"
            )
        
        return result


# Singleton
orchestrator = AgentOrchestrator()


================================================================================
üìÑ ARCHIVO: sprint1/migration_001_add_resilience_fields.sql
üìè Tama√±o: 2.0 KB
================================================================================

-- Migration 001: Add Resilience Fields
-- Ejecutar: docker-compose exec postgres psql -U bookmark_user -d neural_bookmarks -f /tmp/migration.sql

-- 1. Agregar campos de estado de scraping
ALTER TABLE bookmarks ADD COLUMN IF NOT EXISTS scraping_status VARCHAR(50);
ALTER TABLE bookmarks ADD COLUMN IF NOT EXISTS scraping_strategy VARCHAR(50);
ALTER TABLE bookmarks ADD COLUMN IF NOT EXISTS scraping_error_type VARCHAR(50);
ALTER TABLE bookmarks ADD COLUMN IF NOT EXISTS scraping_attempts INTEGER DEFAULT 0;

-- 2. Agregar campos de estado de curaci√≥n
ALTER TABLE bookmarks ADD COLUMN IF NOT EXISTS curation_status VARCHAR(50);
ALTER TABLE bookmarks ADD COLUMN IF NOT EXISTS curation_mode VARCHAR(50);

-- 3. Agregar m√©tricas de calidad
ALTER TABLE bookmarks ADD COLUMN IF NOT EXISTS confidence_score FLOAT DEFAULT 0.0;

-- 4. Actualizar registros existentes con valores por defecto
UPDATE bookmarks 
SET 
    scraping_status = CASE 
        WHEN status = 'completed' THEN 'success'
        WHEN status = 'failed' THEN 'failed'
        ELSE 'pending'
    END,
    curation_status = CASE 
        WHEN status = 'completed' THEN 'success'
        WHEN status = 'failed' THEN 'failed'
        ELSE 'pending'
    END,
    curation_mode = CASE 
        WHEN full_text IS NOT NULL THEN 'full_text'
        ELSE 'url_only'
    END,
    confidence_score = CASE 
        WHEN status = 'completed' AND full_text IS NOT NULL THEN 1.0
        WHEN status = 'completed' AND full_text IS NULL THEN 0.6
        ELSE 0.0
    END
WHERE scraping_status IS NULL;

-- 5. Crear √≠ndices para nuevos campos
CREATE INDEX IF NOT EXISTS idx_scraping_status ON bookmarks(scraping_status);
CREATE INDEX IF NOT EXISTS idx_confidence_score ON bookmarks(confidence_score DESC);
CREATE INDEX IF NOT EXISTS idx_scraping_error_type ON bookmarks(scraping_error_type) WHERE scraping_error_type IS NOT NULL;

-- Verificaci√≥n
SELECT 
    scraping_status,
    COUNT(*) as count,
    AVG(confidence_score) as avg_confidence
FROM bookmarks
GROUP BY scraping_status;


================================================================================
üìÑ ARCHIVO: sprint1/models_updated.py
üìè Tama√±o: 6.4 KB
================================================================================

# app/models.py - VERSI√ìN ACTUALIZADA CON RESILIENCIA

from sqlalchemy import Column, Integer, String, Text, DateTime, Boolean, Float, Index
from sqlalchemy.dialects.postgresql import ARRAY
from sqlalchemy.sql import func
from pgvector.sqlalchemy import Vector
from datetime import datetime

from app.database import Base
from app.config import get_settings

settings = get_settings()


class Bookmark(Base):
    """Modelo principal de Bookmarks con b√∫squeda sem√°ntica y resiliencia"""
    
    __tablename__ = "bookmarks"
    
    # Identificaci√≥n
    id = Column(Integer, primary_key=True, index=True)
    url = Column(String(2048), unique=True, nullable=False, index=True)
    original_title = Column(String(512), nullable=False)
    
    # Contenido procesado
    clean_title = Column(String(512))
    summary = Column(Text)
    full_text = Column(Text)
    
    # Clasificaci√≥n
    tags = Column(ARRAY(String), default=list)
    category = Column(String(100))
    
    # Safety & Privacy
    is_nsfw = Column(Boolean, default=False, index=True)
    is_local = Column(Boolean, default=False, index=True)
    nsfw_reason = Column(String(256))
    
    # ========== NUEVO: Estados de Resiliencia ==========
    
    # Estado general (mantiene compatibilidad)
    status = Column(
        String(50),
        default="pending",
        index=True,
        # Valores: pending, processing, completed, completed_partial, 
        #          failed, manual_required
    )
    error_message = Column(Text)
    
    # Estado de Scraping
    scraping_status = Column(String(50))  
    # Valores: pending, success, partial, failed, skipped
    
    scraping_strategy = Column(String(50))
    # Valores: trafilatura, trafilatura_retry, beautifulsoup, 
    #          archive_org, none
    
    scraping_error_type = Column(String(50))
    # Valores: bot_detection, timeout, connection_refused, 
    #          rate_limited, dns_error, ssl_error, unknown
    
    scraping_attempts = Column(Integer, default=0)
    # N√∫mero de intentos de scraping realizados
    
    # Estado de Curaci√≥n IA
    curation_status = Column(String(50))
    # Valores: pending, success, fallback, failed
    
    curation_mode = Column(String(50))
    # Valores: full_text, url_only, enhanced_url
    
    # M√©tricas de Calidad
    confidence_score = Column(Float, default=0.0)
    # 0.0-1.0: Nivel de confianza en la metadata generada
    # 1.0 = scraping exitoso + curaci√≥n completa
    # 0.7 = scraping exitoso + curaci√≥n parcial
    # 0.5 = solo URL + t√≠tulo procesado con IA
    # 0.3 = fallback b√°sico
    # 0.0 = completamente fallido
    
    # ====================================================
    
    # Embeddings (Vector Sem√°ntico)
    embedding = Column(Vector(settings.EMBEDDING_DIMENSION))
    
    # Metadata
    domain = Column(String(256), index=True)
    favicon_url = Column(String(512))
    language = Column(String(10))
    word_count = Column(Integer)
    
    # M√©tricas (legacy)
    relevance_score = Column(Float, default=0.0)
    
    # Timestamps
    created_at = Column(DateTime(timezone=True), server_default=func.now(), index=True)
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    scraped_at = Column(DateTime(timezone=True))
    
    # √çndices para b√∫squeda
    __table_args__ = (
        Index('ix_bookmarks_embedding_cosine', 'embedding', postgresql_using='ivfflat'),
        Index('ix_bookmarks_tags_gin', 'tags', postgresql_using='gin'),
        Index('ix_bookmarks_category', 'category'),
        Index('ix_bookmarks_domain', 'domain'),
        Index('ix_bookmarks_created_at_desc', created_at.desc()),
        # Nuevos √≠ndices
        Index('ix_bookmarks_scraping_status', 'scraping_status'),
        Index('ix_bookmarks_confidence_score', confidence_score.desc()),
    )
    
    def __repr__(self):
        return f"<Bookmark(id={self.id}, url={self.url[:50]}, status={self.status}, confidence={self.confidence_score:.2f})>"
    
    def to_dict(self):
        """Convierte el modelo a diccionario para API"""
        return {
            "id": self.id,
            "url": self.url,
            "original_title": self.original_title,
            "clean_title": self.clean_title,
            "summary": self.summary,
            "tags": self.tags or [],
            "category": self.category,
            "is_nsfw": self.is_nsfw,
            "is_local": self.is_local,
            "status": self.status,
            "domain": self.domain,
            "language": self.language,
            "word_count": self.word_count,
            "confidence_score": self.confidence_score,
            # Nuevos campos
            "scraping_status": self.scraping_status,
            "scraping_strategy": self.scraping_strategy,
            "curation_mode": self.curation_mode,
            "created_at": self.created_at.isoformat() if self.created_at else None,
            "updated_at": self.updated_at.isoformat() if self.updated_at else None,
        }


class ProcessingLog(Base):
    """Log de procesamiento para debugging y monitoreo"""
    
    __tablename__ = "processing_logs"
    
    id = Column(Integer, primary_key=True, index=True)
    bookmark_id = Column(Integer, index=True)
    url = Column(String(2048))
    
    # Agente que proces√≥
    agent_name = Column(String(50), index=True)  # archivist, curator
    
    # Resultado
    success = Column(Boolean, default=False)
    error_message = Column(Text)
    
    # Metadata de procesamiento
    processing_time = Column(Float)  # segundos
    tokens_used = Column(Integer)
    
    # ========== NUEVO: Detalles de Resiliencia ==========
    scraping_attempts = Column(Integer, default=1)
    scraping_strategy_used = Column(String(50))
    fallback_triggered = Column(Boolean, default=False)
    # ====================================================
    
    # Timestamp
    created_at = Column(DateTime(timezone=True), server_default=func.now(), index=True)
    
    def __repr__(self):
        return f"<ProcessingLog(id={self.id}, agent={self.agent_name}, success={self.success})>"


class SearchHistory(Base):
    """Historial de b√∫squedas para analytics"""
    
    __tablename__ = "search_history"
    
    id = Column(Integer, primary_key=True, index=True)
    query = Column(String(512), index=True)
    results_count = Column(Integer)
    
    # Timestamp
    created_at = Column(DateTime(timezone=True), server_default=func.now(), index=True)
    
    def __repr__(self):
        return f"<SearchHistory(id={self.id}, query={self.query})>"


================================================================================
üìÑ ARCHIVO: sprint1/scraper_resilient.py
üìè Tama√±o: 13.7 KB
================================================================================

# app/services/scraper.py - VERSI√ìN RESILIENTE

import trafilatura
import httpx
from typing import Optional, Dict, Tuple
from loguru import logger
from datetime import datetime
import tldextract
from urllib.parse import urlparse
import random
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    RetryError
)

from app.config import get_settings

settings = get_settings()


class ScrapingError(Exception):
    """Error base de scraping"""
    pass


class BotDetectionError(ScrapingError):
    """Error 403 - Detectado como bot"""
    pass


class RateLimitError(ScrapingError):
    """Error 429 - Rate limited"""
    pass


class TimeoutError(ScrapingError):
    """Timeout de conexi√≥n"""
    pass


class UserAgentRotator:
    """Rotaci√≥n de User-Agents realistas"""
    
    AGENTS = [
        # Chrome Windows (m√°s com√∫n)
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        # Firefox Windows
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
        # Edge Windows
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.2210.133",
        # Safari macOS (menos com√∫n pero realista)
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15",
    ]
    
    @classmethod
    def get_random_agent(cls) -> str:
        """Obtiene un User-Agent aleatorio"""
        return random.choice(cls.AGENTS)
    
    @classmethod
    def get_realistic_headers(cls) -> Dict[str, str]:
        """Headers completos que parecen navegador real"""
        return {
            "User-Agent": cls.get_random_agent(),
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "Accept-Language": "es-ES,es;q=0.9,en;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "DNT": "1",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1",
            "Cache-Control": "max-age=0",
        }


class ResilientScraper:
    """Scraper con m√∫ltiples estrategias y reintentos"""
    
    def __init__(self):
        self.timeout = settings.SCRAPER_TIMEOUT
        self.max_retries = settings.SCRAPER_MAX_RETRIES
        self.user_agent_rotator = UserAgentRotator()
    
    async def scrape_url(self, url: str) -> Dict:
        """
        Scraping resiliente con m√∫ltiples estrategias
        
        Returns:
            Dict con: success, text, title, strategy, error_type, attempts, etc.
        """
        result = {
            "success": False,
            "title": None,
            "text": None,
            "html": None,
            "language": None,
            "word_count": 0,
            "domain": None,
            "strategy": None,
            "error_type": None,
            "error_message": None,
            "attempts": 0,
        }
        
        try:
            # Extraer dominio
            extracted = tldextract.extract(url)
            result["domain"] = f"{extracted.domain}.{extracted.suffix}"
            
            # Verificar si es URL local
            if self._is_local_url(url):
                result["error_type"] = "local_url"
                result["error_message"] = "URL local detectada - requiere captura manual"
                return result
            
            # Estrategia 1: Trafilatura con reintentos
            logger.info(f"[Scraper] Estrategia 1: Trafilatura con reintentos")
            strategy_result = await self._trafilatura_with_retry(url)
            result["attempts"] += strategy_result["attempts"]
            
            if strategy_result["success"]:
                result.update(strategy_result)
                result["strategy"] = "trafilatura_retry"
                logger.info(f"‚úÖ Scraping exitoso con trafilatura: {url}")
                return result
            
            # Si falla con bot detection, intentar con BeautifulSoup b√°sico
            if strategy_result.get("error_type") == "bot_detection":
                logger.warning(f"[Scraper] Bot detection - Intentando estrategia 2: BeautifulSoup")
                bs_result = await self._beautifulsoup_fallback(url)
                result["attempts"] += 1
                
                if bs_result["success"]:
                    result.update(bs_result)
                    result["strategy"] = "beautifulsoup"
                    logger.info(f"‚úÖ Scraping exitoso con BeautifulSoup: {url}")
                    return result
            
            # Si todas las estrategias fallan
            result["error_type"] = strategy_result.get("error_type", "unknown")
            result["error_message"] = strategy_result.get("error_message", "Todas las estrategias fallaron")
            logger.error(f"‚ùå Scraping fallido: {url} - {result['error_type']}")
        
        except Exception as e:
            result["error_type"] = "unexpected_error"
            result["error_message"] = str(e)
            logger.error(f"‚ùå Error inesperado en scraping {url}: {e}")
        
        return result
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((httpx.TimeoutException, httpx.ConnectError)),
        reraise=True
    )
    async def _fetch_with_retry(self, url: str, headers: Dict) -> httpx.Response:
        """Descarga HTML con reintentos autom√°ticos para errores temporales"""
        async with httpx.AsyncClient(
            timeout=self.timeout,
            follow_redirects=True,
        ) as client:
            response = await client.get(url, headers=headers)
            
            # Clasificar errores HTTP
            if response.status_code == 403:
                raise BotDetectionError(f"403 Forbidden - Bot detection: {url}")
            elif response.status_code == 429:
                raise RateLimitError(f"429 Too Many Requests: {url}")
            elif response.status_code >= 500:
                raise httpx.HTTPStatusError(f"Server error {response.status_code}", request=response.request, response=response)
            
            response.raise_for_status()
            return response
    
    async def _trafilatura_with_retry(self, url: str) -> Dict:
        """Estrategia 1: Trafilatura con reintentos inteligentes"""
        result = {
            "success": False,
            "attempts": 0,
            "error_type": None,
            "error_message": None,
        }
        
        for attempt in range(1, self.max_retries + 1):
            result["attempts"] = attempt
            
            try:
                logger.info(f"  Intento {attempt}/{self.max_retries}: Descargando {url}")
                
                # Rotar headers en cada intento
                headers = self.user_agent_rotator.get_realistic_headers()
                
                # Descargar con reintentos
                response = await self._fetch_with_retry(url, headers)
                html = response.text
                
                # Extraer contenido con Trafilatura
                text = trafilatura.extract(
                    html,
                    include_comments=False,
                    include_tables=True,
                    no_fallback=False,
                )
                
                # Extraer metadata
                metadata = trafilatura.extract_metadata(html)
                
                if text and len(text.strip()) > 50:
                    result["success"] = True
                    result["text"] = text
                    result["html"] = html[:10000]  # Limitar tama√±o
                    result["word_count"] = len(text.split())
                    
                    if metadata:
                        result["title"] = metadata.title
                        result["language"] = metadata.language
                    
                    return result
                else:
                    logger.warning(f"  Texto extra√≠do muy corto ({len(text) if text else 0} chars)")
                    result["error_type"] = "insufficient_content"
                    result["error_message"] = "Contenido extra√≠do insuficiente"
            
            except BotDetectionError as e:
                result["error_type"] = "bot_detection"
                result["error_message"] = str(e)
                logger.warning(f"  Bot detection detectado en intento {attempt}")
                # No reintentar si es bot detection - pasar a siguiente estrategia
                break
            
            except RateLimitError as e:
                result["error_type"] = "rate_limited"
                result["error_message"] = str(e)
                logger.warning(f"  Rate limited en intento {attempt}")
                # Esperar m√°s tiempo antes de siguiente intento
                if attempt < self.max_retries:
                    import asyncio
                    await asyncio.sleep(10 * attempt)
            
            except httpx.TimeoutException as e:
                result["error_type"] = "timeout"
                result["error_message"] = f"Timeout despu√©s de {self.timeout}s"
                logger.warning(f"  Timeout en intento {attempt}")
            
            except httpx.ConnectError as e:
                result["error_type"] = "connection_refused"
                result["error_message"] = "No se pudo conectar al servidor"
                logger.warning(f"  Connection refused en intento {attempt}")
            
            except httpx.HTTPStatusError as e:
                result["error_type"] = "http_error"
                result["error_message"] = f"HTTP {e.response.status_code}"
                logger.warning(f"  HTTP error {e.response.status_code} en intento {attempt}")
            
            except Exception as e:
                result["error_type"] = "unknown"
                result["error_message"] = str(e)
                logger.error(f"  Error inesperado en intento {attempt}: {e}")
        
        return result
    
    async def _beautifulsoup_fallback(self, url: str) -> Dict:
        """Estrategia 2: BeautifulSoup b√°sico (menos detectable)"""
        try:
            from bs4 import BeautifulSoup
            
            headers = self.user_agent_rotator.get_realistic_headers()
            
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.get(url, headers=headers)
                response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'lxml')
            
            # Eliminar scripts y styles
            for script in soup(["script", "style"]):
                script.decompose()
            
            # Extraer texto
            text = soup.get_text(separator=' ', strip=True)
            title = soup.find('title').text if soup.find('title') else ""
            
            # Limpiar texto
            lines = (line.strip() for line in text.splitlines())
            text = '\n'.join(line for line in lines if line)
            
            return {
                "success": True,
                "text": text[:10000],  # Limitar
                "title": title,
                "html": response.text[:10000],
                "word_count": len(text.split()),
            }
        
        except Exception as e:
            return {
                "success": False,
                "error_type": "beautifulsoup_failed",
                "error_message": str(e),
            }
    
    def _is_local_url(self, url: str) -> bool:
        """Verifica si la URL es local (.test, .local, localhost, etc.)"""
        try:
            parsed = urlparse(url.lower())
            hostname = parsed.hostname or parsed.netloc
            
            # Verificar contra dominios locales configurados
            for local_domain in settings.local_domains_list:
                if local_domain in hostname:
                    return True
            
            return False
        
        except Exception as e:
            logger.warning(f"Error verificando URL local {url}: {e}")
            return False
    
    def extract_clean_title(self, original_title: str, domain: str = None) -> str:
        """
        Limpia t√≠tulos gen√©ricos como 'Home', 'Index', etc.
        
        Args:
            original_title: T√≠tulo original del bookmark
            domain: Dominio para mejorar el t√≠tulo
        
        Returns:
            T√≠tulo limpio y descriptivo
        """
        generic_titles = {
            "home", "index", "welcome", "inicio", "p√°gina principal",
            "main page", "default", "untitled", "new tab", "homepage"
        }
        
        title_lower = original_title.lower().strip()
        
        # Si el t√≠tulo es gen√©rico y tenemos dominio
        if title_lower in generic_titles and domain:
            # Capitalizar dominio como t√≠tulo
            clean_domain = domain.replace("-", " ").replace("_", " ").title()
            return f"{clean_domain} - P√°gina Principal"
        
        # Si el t√≠tulo est√° vac√≠o
        if not original_title.strip():
            return domain.title() if domain else "T√≠tulo Desconocido"
        
        # Limpiar separadores comunes
        title_clean = original_title.strip()
        
        # Remover pipes y guiones al final
        for separator in ["|", "-", "‚Äî", "‚Äì"]:
            if separator in title_clean:
                parts = title_clean.split(separator)
                # Tomar la parte m√°s larga
                title_clean = max(parts, key=len).strip()
        
        return title_clean


# Singleton
scraper = ResilientScraper()


================================================================================
üìÑ ARCHIVO: sprint1/test_sprint1_resilient.py
üìè Tama√±o: 3.0 KB
‚ö†Ô∏è  DATOS SENSIBLES ENMASCARADOS:
  ‚ö†Ô∏è  Encontrado 2 coincidencia(s) de tipo: https?://
================================================================================

# tests/test_sprint1_resilience.py
"""
Tests unitarios para Sprint 1: Resiliencia

Ejecutar:
    pytest tests/test_sprint1_resilience.py -v
"""
import pytest
import asyncio
from unittest.mock import Mock, patch, AsyncMock

# Importar las nuevas clases
from app.services.scraper import ResilientScraper, UserAgentRotator
from app.agents import CuratorAgent


class TestUserAgentRotator:
    """Tests para rotaci√≥n de User-Agents"""
    
    def test_get_random_agent(self):
        """Debe retornar un User-Agent v√°lido"""
        agent = UserAgentRotator.get_random_agent()
        
        assert isinstance(agent, str)
        assert len(agent) > 50
        assert "Mozilla" in agent
    
    def test_get_realistic_headers(self):
        """Debe generar headers completos"""
        headers = UserAgentRotator.get_realistic_headers()
        
        assert "User-Agent" in headers
        assert "Accept" in headers
        assert "Accept-Language" in headers
        assert "DNT" in headers
        
        # Verificar que Accept-Language incluye espa√±ol
        assert "es" in headers["Accept-Language"]


class TestResilientScraper:
    """Tests para scraper resiliente"""
    
    @pytest.mark.asyncio
    async def test_is_local_url(self):
        """Debe detectar URLs locales correctamente"""
        scraper = ResilientScraper()
        
        # URLs locales
        assert scraper._is_local_url("https://user:xxxxxxxxxx@pytest.mark.asyncio
    async def test_scraping_with_error_classification(self):
        """Debe clasificar errores correctamente"""
        scraper = ResilientScraper()
        
        # Simular error 403 (bot detection)
        with patch('httpx.AsyncClient.get') as mock_get:
            mock_response = Mock()
            mock_response.status_code = 403
            mock_get.return_value = mock_response
            
            result = await scraper.scrape_url("https://user:xxxxxxxxxx@pytest.mark.asyncio
    async def test_scraping_returns_expected_fields(self):
        """Scraping debe retornar todos los campos esperados"""
        scraper = ResilientScraper()
        
        # Mock de respuesta exitosa
        with patch('httpx.AsyncClient.get') as mock_get:
            mock_response = Mock()
            mock_response.status_code = 200
            mock_response.text = "<html><head><title>Test</title></head><body>Content</body></html>"
            mock_get.return_value = mock_response
            
            result = await scraper.scrape_url("https://example.com")
            
            # Campos obligatorios
            assert "success" in result
            assert "error_type" in result
            assert "attempts" in result
            assert "strategy" in result
            
            # Campos de contenido
            assert "title" in result
            assert "text" in result or result["success"] == False


if __name__ == "__main__":
    # Ejecutar tests b√°sicos
    print("üß™ Ejecutando tests de Sprint 1...")
    pytest.main([__file__, "-v", "--tb=short"])


================================================================================
üìÑ ARCHIVO: tests/__init__.py
üìè Tama√±o: 0.0 KB
================================================================================




================================================================================
üìÑ ARCHIVO: tests/conftest.py
üìè Tama√±o: 4.3 KB
‚ö†Ô∏è  DATOS SENSIBLES ENMASCARADOS:
  ‚ö†Ô∏è  Encontrado 1 coincidencia(s) de tipo: https?://
================================================================================

# tests/conftest.py
import pytest
import pytest_asyncio
import asyncio
from sqlalchemy import text
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from httpx import AsyncClient, ASGITransport
from app.database import Base, get_db
from app.main import app
from app.config import get_settings

settings = get_settings()

TEST_DATABASE_URL = (
    "postgresql+asyncpg://bookmark_user:bookmark_pass_2024"
    "@localhost:5432/neural_bookmarks_test"
)


@pytest.fixture(scope="session")
def event_loop():
    """Event loop para tests async"""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()


@pytest_asyncio.fixture(scope="function")
async def db_session():
    """Session de DB limpia para cada test"""
    engine = create_async_engine(TEST_DATABASE_URL, echo=False)
    
    async with engine.begin() as conn:
        # FIX: Dropear TODO en orden correcto - primero √≠ndices, luego tablas
        # Usar CASCADE para forzar eliminaci√≥n de dependencias
        
        # 1. Dropear √≠ndices manualmente primero (evita errores de "already exists")
        await conn.execute(text("""
            DO $$ 
            BEGIN
                -- Dropear todos los √≠ndices de bookmarks si existen
                IF EXISTS (SELECT 1 FROM pg_indexes WHERE indexname = 'ix_bookmarks_domain') THEN
                    EXECUTE 'DROP INDEX IF EXISTS ix_bookmarks_domain CASCADE';
                END IF;
                
                IF EXISTS (SELECT 1 FROM pg_indexes WHERE indexname = 'ix_bookmarks_status') THEN
                    EXECUTE 'DROP INDEX IF EXISTS ix_bookmarks_status CASCADE';
                END IF;
                
                IF EXISTS (SELECT 1 FROM pg_indexes WHERE indexname = 'ix_bookmarks_category') THEN
                    EXECUTE 'DROP INDEX IF EXISTS ix_bookmarks_category CASCADE';
                END IF;
                
                IF EXISTS (SELECT 1 FROM pg_indexes WHERE indexname = 'ix_bookmarks_nsfw') THEN
                    EXECUTE 'DROP INDEX IF EXISTS ix_bookmarks_nsfw CASCADE';
                END IF;
                
                IF EXISTS (SELECT 1 FROM pg_indexes WHERE indexname = 'ix_bookmarks_created_at') THEN
                    EXECUTE 'DROP INDEX IF EXISTS ix_bookmarks_created_at CASCADE';
                END IF;
            END $$;
        """))
        
        # 2. Dropear tablas en orden correcto (dependencias primero)
        await conn.execute(text("DROP TABLE IF EXISTS processing_log CASCADE"))
        await conn.execute(text("DROP TABLE IF EXISTS search_history CASCADE"))
        await conn.execute(text("DROP TABLE IF EXISTS bookmarks CASCADE"))
        await conn.execute(text("DROP TABLE IF EXISTS alembic_version CASCADE"))
        
        # 3. Limpiar cualquier tabla residual que pueda quedar
        await conn.execute(text("""
            DO $$
            DECLARE
                r RECORD;
            BEGIN
                FOR r IN (SELECT tablename FROM pg_tables WHERE schemaname = 'public') LOOP
                    EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.tablename) || ' CASCADE';
                END LOOP;
            END $$;
        """))
        
        # 4. Crear extensi√≥n vector primero
        await conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))
        
        # 5. Crear todo el schema fresco
        def create_all_safe(conn):
            # Sin checkfirst - queremos crear todo de cero
            Base.metadata.create_all(conn)
        
        await conn.run_sync(create_all_safe)
    
    async_session = async_sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)
    async with async_session() as session:
        yield session
    
    await engine.dispose()


@pytest_asyncio.fixture
async def client(db_session):
    """Cliente HTTP que usa la base de datos de test."""
    async def override_get_db():
        yield db_session

    app.dependency_overrides[get_db] = override_get_db
    
    async with AsyncClient(
        transport=ASGITransport(app=app),
        base_url="https://user:xxxxxxxxxx@pytest.fixture
def sample_bookmark_data():
    """Datos de prueba reutilizables"""
    return {
        "url": "https://example.com/test",
        "title": "Test Article",
        "text": "This is a sample text about machine learning and Python.",
    }


================================================================================
üìÑ ARCHIVO: tests/e2e/__init__.py
üìè Tama√±o: 0.0 KB
================================================================================




================================================================================
üìÑ ARCHIVO: tests/e2e/test_import_flow.py
üìè Tama√±o: 0.0 KB
================================================================================




================================================================================
üìÑ ARCHIVO: tests/integration/__init__.py
üìè Tama√±o: 0.0 KB
================================================================================




================================================================================
üìÑ ARCHIVO: tests/integration/test_agents.py
üìè Tama√±o: 1.3 KB
‚ö†Ô∏è  DATOS SENSIBLES ENMASCARADOS:
  ‚ö†Ô∏è  Encontrado 2 coincidencia(s) de tipo: https?://
================================================================================

# tests/integration/test_agents.py
import pytest
from app.agents import ArchivistAgent, CuratorAgent, AgentOrchestrator

class TestArchivistAgent:
    @pytest.mark.asyncio
    async def test_process_valid_url(self):
        agent = ArchivistAgent()
        result = await agent.process(
            url="https://user:xxxxxxxxxx@pytest.mark.asyncio
    async def test_process_with_valid_text(self):
        agent = CuratorAgent()
        result = await agent.process(
            clean_title="Introduction to Machine Learning",
            full_text="Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.",
            url="https://user:xxxxxxxxxx@pytest.mark.asyncio
    async def test_full_processing_flow(self):
        orchestrator = AgentOrchestrator()
        result = await orchestrator.process_bookmark(
            url="https://www.python.org",
            original_title="Python"
        )
        
        # Verificar que pase por ambos agentes
        assert "clean_title" in result
        assert "summary" in result or result["status"] == "failed"
        assert "processing_time" in result
        assert result["processing_time"] > 0


================================================================================
üìÑ ARCHIVO: tests/integration/test_api.py
üìè Tama√±o: 3.7 KB
‚ö†Ô∏è  DATOS SENSIBLES ENMASCARADOS:
  ‚ö†Ô∏è  Encontrado 9 coincidencia(s) de tipo: https?://
================================================================================

# tests/integration/test_api.py
"""
Tests de integraci√≥n para la API REST
"""
import pytest
from httpx import AsyncClient
from app.main import app
@pytest.mark.asyncio
async def test_health_endpoint():
    """Test del endpoint de health check"""
    async with AsyncClient(app=app, base_url="https://user:xxxxxxxxxx@pytest.mark.asyncio
async def test_root_endpoint():
    """Test del endpoint ra√≠z"""
    async with AsyncClient(app=app, base_url="https://user:xxxxxxxxxx@pytest.mark.asyncio
async def test_search_endpoint_basic(client, db_session):
    """Test b√°sico del endpoint de b√∫squeda"""
    from app.models import Bookmark
    from app.services.embeddings import get_embedding_service
    
    embedding_service = get_embedding_service()
    
    bookmark = Bookmark(
        url="https://user:xxxxxxxxxx@pytest.mark.asyncio
async def test_search_with_filters(client, db_session):
    """Test de b√∫squeda con filtros de categor√≠a y tags"""
    from app.models import Bookmark
    from app.services.embeddings import get_embedding_service
    
    embedding_service = get_embedding_service()
    
    # Crear m√∫ltiples bookmarks con diferentes categor√≠as
    bookmarks = [
        Bookmark(
            url="https://user:xxxxxxxxxx@pytest.mark.asyncio
async def test_search_nsfw_filter(client, db_session):
    """Test de filtrado de contenido NSFW en b√∫squeda"""
    from app.models import Bookmark
    from app.services.embeddings import get_embedding_service
    
    embedding_service = get_embedding_service()
    
    bookmarks = [
        Bookmark(
            url="https://user:xxxxxxxxxx@pytest.mark.asyncio
async def test_stats_processing_endpoint():
    """Test del endpoint de estad√≠sticas de procesamiento"""
    async with AsyncClient(app=app, base_url="https://user:xxxxxxxxxx@pytest.mark.asyncio
async def test_stats_categories_endpoint(client, db_session):
    """Test del endpoint de estad√≠sticas de categor√≠as"""
    from app.models import Bookmark
    
    # Crear bookmarks con categor√≠as
    bookmarks = [
        Bookmark(url=f"https://user:xxxxxxxxxx@pytest.mark.asyncio
async def test_get_bookmark_by_id(client, db_session):
    """Test de obtener bookmark por ID"""
    from app.models import Bookmark
    
    bookmark = Bookmark(
        url="https://user:xxxxxxxxxx@pytest.mark.asyncio
async def test_get_bookmark_not_found(client):
    """Test de bookmark no encontrado"""

    response = await client.get("/bookmarks/99999")
    assert response.status_code == 404
@pytest.mark.asyncio
async def test_list_bookmarks(client, db_session):
    """Test de listar bookmarks con paginaci√≥n"""
    from app.models import Bookmark
    
    # Crear m√∫ltiples bookmarks
    for i in range(5):
        bookmark = Bookmark(
            url=f"https://user:xxxxxxxxxx@pytest.mark.asyncio
async def test_search_similarity_scores(client, db_session):
    """Test de que los scores de similitud est√°n en el rango correcto"""
    from app.models import Bookmark
    from app.services.embeddings import get_embedding_service
    
    embedding_service = get_embedding_service()
    
    bookmark = Bookmark(
        url="https://test.com/similarity",
        original_title="Machine Learning Tutorial",
        clean_title="Machine Learning Tutorial",
        status="completed",
        embedding=embedding_service.generate_embedding("Machine Learning Tutorial")
    )
    db_session.add(bookmark)
    await db_session.commit()

    response = await client.post(
        "/search",
        json={"query": "machine learning", "limit": 5}
    )
    assert response.status_code == 200
    data = response.json()
    for result in data["results"]:
        score = result["similarity_score"]
        assert 0.0 <= score <= 1.0
if __name__ == "__main__":
    pytest.main([__file__, "-v"])


================================================================================
üìÑ ARCHIVO: tests/integration/test_database.py
üìè Tama√±o: 3.1 KB
‚ö†Ô∏è  DATOS SENSIBLES ENMASCARADOS:
  ‚ö†Ô∏è  Encontrado 4 coincidencia(s) de tipo: https?://
================================================================================

# tests/integration/test_database.py
"""
Tests de integraci√≥n para la base de datos
"""
import pytest
from sqlalchemy import text, select
from sqlalchemy.ext.asyncio import AsyncSession
from app.models import Bookmark, SearchHistory, ProcessingLog
from app.services.embeddings import get_embedding_service


@pytest.mark.asyncio
async def test_database_connection(db_session: AsyncSession):
    """Test b√°sico de conexi√≥n a la base de datos"""
    result = await db_session.execute(text("SELECT 1"))
    assert result.scalar() == 1


@pytest.mark.asyncio
async def test_pgvector_extension(db_session: AsyncSession):
    """Verifica que la extensi√≥n pgvector est√° instalada"""
    result = await db_session.execute(
        text("SELECT * FROM pg_extension WHERE extname = 'vector'")
    )
    extension = result.first()
    assert extension is not None, "Extensi√≥n pgvector no est√° instalada"


@pytest.mark.asyncio
async def test_create_bookmark(db_session: AsyncSession):
    """Test de creaci√≥n de bookmark en la BD"""
    embedding_service = get_embedding_service()
    
    bookmark = Bookmark(
        url="https://user:xxxxxxxxxx@pytest.mark.asyncio
async def test_query_bookmarks(db_session: AsyncSession):
    """Test de consulta de bookmarks"""
    embedding_service = get_embedding_service()
    
    # Crear varios bookmarks
    bookmarks = [
        Bookmark(
            url=f"https://user:xxxxxxxxxx@pytest.mark.asyncio
async def test_search_history(db_session: AsyncSession):
    """Test de historial de b√∫squedas"""
    search = SearchHistory(
        query="test query",
        results_count=5
    )
    
    db_session.add(search)
    await db_session.commit()
    await db_session.refresh(search)
    
    assert search.id is not None
    assert search.query == "test query"
    assert search.results_count == 5
    assert search.created_at is not None


@pytest.mark.asyncio
async def test_processing_log(db_session: AsyncSession):
    """Test de log de procesamiento"""
    # Crear bookmark primero
    bookmark = Bookmark(
        url="https://user:xxxxxxxxxx@pytest.mark.asyncio
async def test_bookmark_status_workflow(db_session: AsyncSession):
    """Test del flujo de estados de un bookmark"""
    bookmark = Bookmark(
        url="https://user:xxxxxxxxxx@pytest.mark.asyncio
async def test_bookmark_tags_array(db_session: AsyncSession):
    """Test de manejo de tags como array PostgreSQL"""
    bookmark = Bookmark(
        url="https://test.com/tags",
        original_title="Tags Test",
        tags=["python", "testing", "database"],
        status="completed"
    )
    
    db_session.add(bookmark)
    await db_session.commit()
    await db_session.refresh(bookmark)
    
    assert len(bookmark.tags) == 3
    assert "python" in bookmark.tags
    assert "testing" in bookmark.tags
    
    # Verificar que se puede buscar por tags
    result = await db_session.execute(
        select(Bookmark).where(Bookmark.tags.contains(["python"]))
    )
    found = result.scalar_one_or_none()
    assert found is not None
    assert found.url == "https://test.com/tags"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])



================================================================================
üìÑ ARCHIVO: tests/test_rate_limiting.py
üìè Tama√±o: 3.1 KB
================================================================================

"""
Tests para verificar rate limiting y configuraci√≥n del scraper
"""
import pytest
import asyncio
from datetime import datetime
from app.services.scraper import ResilientScraper
from app.config import get_settings

settings = get_settings()


@pytest.mark.asyncio
async def test_rate_limiting():
    """Verifica que el rate limiting funciona correctamente"""
    scraper = ResilientScraper()
    
    # Primera petici√≥n - no deber√≠a esperar
    start1 = datetime.now()
    await scraper._rate_limit()
    duration1 = (datetime.now() - start1).total_seconds()
    
    assert duration1 < 0.1, "Primera petici√≥n no deber√≠a tener delay"
    
    # Segunda petici√≥n - deber√≠a esperar el delay configurado
    start2 = datetime.now()
    await scraper._rate_limit()
    duration2 = (datetime.now() - start2).total_seconds()
    
    expected_delay = settings.SCRAPER_DELAY_BETWEEN_REQUESTS
    assert duration2 >= expected_delay * 0.9, f"Deber√≠a esperar al menos {expected_delay}s"
    assert duration2 <= expected_delay * 1.2, f"No deber√≠a esperar m√°s de {expected_delay * 1.2}s"


def test_scraper_configuration():
    """Verifica que todas las configuraciones del scraper est√°n presentes"""
    scraper = ResilientScraper()
    
    # Verificar que todas las configuraciones est√°n cargadas
    assert scraper.timeout > 0, "Timeout debe ser > 0"
    assert scraper.max_retries > 0, "Max retries debe ser > 0"
    assert scraper.max_redirects > 0, "Max redirects debe ser > 0"
    assert scraper.delay_between_requests >= 0, "Delay debe ser >= 0"
    
    # Verificar valores por defecto razonables
    assert scraper.timeout <= 60, "Timeout no deber√≠a ser excesivo"
    assert scraper.max_retries <= 10, "Max retries no deber√≠a ser excesivo"
    assert scraper.max_redirects <= 20, "Max redirects no deber√≠a ser excesivo"
    
    print(f"‚úÖ Configuraci√≥n del scraper:")
    print(f"   ‚Ä¢ Timeout: {scraper.timeout}s")
    print(f"   ‚Ä¢ Max retries: {scraper.max_retries}")
    print(f"   ‚Ä¢ Max redirects: {scraper.max_redirects}")
    print(f"   ‚Ä¢ Delay entre peticiones: {scraper.delay_between_requests}s")


@pytest.mark.asyncio
async def test_multiple_rate_limited_calls():
    """Verifica rate limiting con m√∫ltiples llamadas consecutivas"""
    scraper = ResilientScraper()
    
    start = datetime.now()
    
    # Hacer 3 llamadas
    for i in range(3):
        await scraper._rate_limit()
    
    total_duration = (datetime.now() - start).total_seconds()
    expected_minimum = settings.SCRAPER_DELAY_BETWEEN_REQUESTS * 2  # 2 delays (entre 3 calls)
    
    assert total_duration >= expected_minimum * 0.9, \
        f"Deber√≠a tomar al menos {expected_minimum}s, tom√≥ {total_duration}s"
    
    print(f"‚úÖ 3 peticiones con rate limiting tomaron {total_duration:.2f}s")


if __name__ == "__main__":
    # Ejecutar tests manualmente
    print("üß™ Ejecutando tests de rate limiting...\n")
    
    test_scraper_configuration()
    print()
    
    asyncio.run(test_rate_limiting())
    print("‚úÖ Test de rate limiting b√°sico pasado\n")
    
    asyncio.run(test_multiple_rate_limited_calls())
    print("\n‚úÖ Todos los tests pasaron!")



================================================================================
üìÑ ARCHIVO: tests/test_rate_limiting_api.py
üìè Tama√±o: 6.2 KB
================================================================================

"""
Test para verificar rate limiting en la API
"""
import asyncio
import httpx
import pytest
from datetime import datetime


BASE_URL = "http://localhost:8000"


async def test_search_rate_limit():
    """
    Test que verifica que el rate limit de b√∫squeda funciona
    Configurado: 10/minute
    """
    print("\nüß™ Testeando rate limit de b√∫squeda (10/minute)...")
    
    async with httpx.AsyncClient(base_url=BASE_URL) as client:
        # Hacer 10 peticiones (deber√≠a funcionar)
        successful = 0
        for i in range(1, 11):
            try:
                response = await client.post("/search", json={
                    "query": f"test query {i}",
                    "limit": 5,
                    "include_nsfw": False
                })
                if response.status_code == 200:
                    successful += 1
                    print(f"   ‚úÖ Petici√≥n {i}/10: OK")
                else:
                    print(f"   ‚ùå Petici√≥n {i}/10: {response.status_code}")
            except Exception as e:
                print(f"   ‚ùå Petici√≥n {i}/10: Error - {e}")
        
        print(f"\n   üìä {successful}/10 peticiones exitosas")
        
        # Hacer una petici√≥n m√°s (deber√≠a ser bloqueada)
        print("\n   üö´ Intentando petici√≥n #11 (deber√≠a fallar)...")
        try:
            response = await client.post("/search", json={
                "query": "test over limit",
                "limit": 5
            })
            
            if response.status_code == 429:
                print(f"   ‚úÖ Correctamente bloqueada con 429 Too Many Requests")
                print(f"   üìù Mensaje: {response.json()}")
                return True
            else:
                print(f"   ‚ö†Ô∏è  Deber√≠a haber sido bloqueada pero obtuvo: {response.status_code}")
                return False
        except Exception as e:
            print(f"   ‚ùå Error: {e}")
            return False


async def test_create_rate_limit():
    """
    Test que verifica que el rate limit de creaci√≥n funciona
    Configurado: 5/minute
    """
    print("\nüß™ Testeando rate limit de creaci√≥n (5/minute)...")
    
    async with httpx.AsyncClient(base_url=BASE_URL) as client:
        # Hacer 5 peticiones
        successful = 0
        for i in range(1, 6):
            try:
                response = await client.post("/bookmarks", json={
                    "url": f"https://example.com/page{i}",
                    "original_title": f"Test Page {i}"
                })
                # 409 es tambi√©n aceptable (bookmark duplicado)
                if response.status_code in [200, 201, 409]:
                    successful += 1
                    status = "OK" if response.status_code in [200, 201] else "Duplicado"
                    print(f"   ‚úÖ Petici√≥n {i}/5: {status}")
                else:
                    print(f"   ‚ùå Petici√≥n {i}/5: {response.status_code}")
            except Exception as e:
                print(f"   ‚ùå Petici√≥n {i}/5: Error - {e}")
        
        print(f"\n   üìä {successful}/5 peticiones exitosas")
        
        # Hacer una m√°s (deber√≠a ser bloqueada)
        print("\n   üö´ Intentando petici√≥n #6 (deber√≠a fallar)...")
        try:
            response = await client.post("/bookmarks", json={
                "url": "https://example.com/over-limit",
                "original_title": "Over Limit"
            })
            
            if response.status_code == 429:
                print(f"   ‚úÖ Correctamente bloqueada con 429 Too Many Requests")
                return True
            else:
                print(f"   ‚ö†Ô∏è  Deber√≠a haber sido bloqueada pero obtuvo: {response.status_code}")
                return False
        except Exception as e:
            print(f"   ‚ùå Error: {e}")
            return False


async def test_health_no_rate_limit():
    """
    Verifica que endpoints sin rate limit espec√≠fico funcionan
    """
    print("\nüß™ Testeando endpoint sin rate limit (/health)...")
    
    async with httpx.AsyncClient(base_url=BASE_URL) as client:
        # Health check no deber√≠a tener rate limit espec√≠fico
        # Solo el global (100/minute)
        for i in range(1, 11):
            response = await client.get("/health")
            if response.status_code == 200:
                print(f"   ‚úÖ Petici√≥n {i}/10: OK")
            else:
                print(f"   ‚ùå Petici√≥n {i}/10: {response.status_code}")
                return False
    
    print("   ‚úÖ Todas las peticiones pasaron (sin rate limit espec√≠fico)")
    return True


def main():
    """Funci√≥n principal"""
    print("="*60)
    print("üîí TEST DE RATE LIMITING DE LA API")
    print("="*60)
    print("\n‚ö†Ô∏è  IMPORTANTE: Aseg√∫rate de que la API est√© corriendo en")
    print(f"   {BASE_URL}")
    print("\n   Inicia la API con: uvicorn app.main:app --reload\n")
    
    input("Presiona Enter para continuar...")
    
    try:
        # Test 1: Health check
        result1 = asyncio.run(test_health_no_rate_limit())
        
        # Test 2: Search rate limit
        result2 = asyncio.run(test_search_rate_limit())
        
        # Esperar un poco antes del siguiente test
        print("\n‚è≥ Esperando 5 segundos antes del siguiente test...")
        asyncio.run(asyncio.sleep(5))
        
        # Test 3: Create rate limit
        result3 = asyncio.run(test_create_rate_limit())
        
        print("\n" + "="*60)
        print("üìä RESUMEN DE TESTS")
        print("="*60)
        print(f"   Health endpoint: {'‚úÖ PASS' if result1 else '‚ùå FAIL'}")
        print(f"   Search rate limit: {'‚úÖ PASS' if result2 else '‚ùå FAIL'}")
        print(f"   Create rate limit: {'‚úÖ PASS' if result3 else '‚ùå FAIL'}")
        print("="*60)
        
        if all([result1, result2, result3]):
            print("\n‚úÖ Todos los tests pasaron!")
            return 0
        else:
            print("\n‚ö†Ô∏è  Algunos tests fallaron")
            return 1
    
    except httpx.ConnectError:
        print("\n‚ùå Error: No se pudo conectar a la API")
        print(f"   Verifica que la API est√© corriendo en {BASE_URL}")
        return 1
    except Exception as e:
        print(f"\n‚ùå Error inesperado: {e}")
        return 1


if __name__ == "__main__":
    import sys
    sys.exit(main())



================================================================================
üìÑ ARCHIVO: tests/unit/__init__.py
üìè Tama√±o: 0.0 KB
================================================================================




================================================================================
üìÑ ARCHIVO: tests/unit/test_classifier.py
üìè Tama√±o: 1.4 KB
================================================================================

# tests/unit/test_classifier.py
import pytest
from app.services.classifier import SafetyClassifier

class TestSafetyClassifier:
    @pytest.fixture
    def classifier(self):
        return SafetyClassifier()
    
    def test_nsfw_domain_detection(self, classifier):
        is_nsfw, reason = classifier.classify(
            url="https://pornhub.com/video",
            title="Video",
            text=""
        )
        assert is_nsfw is True
        assert "Dominio NSFW" in reason
    
    def test_nsfw_keyword_in_url(self, classifier):
        is_nsfw, reason = classifier.classify(
            url="https://example.com/adult/content",
            title="Content",
            text=""
        )
        assert is_nsfw is True
        assert "Keyword NSFW en URL" in reason
    
    def test_clean_content(self, classifier):
        is_nsfw, reason = classifier.classify(
            url="https://example.com",
            title="Clean Article",
            text="This is a normal article about technology."
        )
        assert is_nsfw is False
        assert reason is None
    
    def test_keyword_threshold(self, classifier):
        # 1 keyword no deber√≠a marcar como NSFW
        is_nsfw, _ = classifier._check_text("This mentions adult once", "test")
        assert is_nsfw is False
        
        # 2+ keywords s√≠
        is_nsfw, reason = classifier._check_text("This has adult and xxx content", "test")
        assert is_nsfw is True


================================================================================
üìÑ ARCHIVO: tests/unit/test_embeddings.py
üìè Tama√±o: 1.5 KB
================================================================================

# tests/unit/test_embeddings.py
import pytest
import numpy as np
from app.services.embeddings import EmbeddingService

class TestEmbeddingService:
    @pytest.fixture
    def service(self):
        return EmbeddingService()
    
    def test_generate_embedding(self, service):
        text = "Machine learning is a subset of artificial intelligence"
        embedding = service.generate_embedding(text)
        
        assert isinstance(embedding, list)
        assert len(embedding) == service.dimension  # 384
        assert all(isinstance(x, float) for x in embedding)
    
    def test_empty_text_returns_zero_vector(self, service):
        embedding = service.generate_embedding("")
        assert embedding == [0.0] * service.dimension
    
    def test_similarity_calculation(self, service):
        emb1 = service.generate_embedding("Python programming language")
        emb2 = service.generate_embedding("Python for developers")
        emb3 = service.generate_embedding("Cooking recipes")
        
        sim_similar = service.calculate_similarity(emb1, emb2)
        sim_different = service.calculate_similarity(emb1, emb3)
        
        assert 0 <= sim_similar <= 1
        assert 0 <= sim_different <= 1
        assert sim_similar > sim_different  # Textos similares = mayor score
    
    def test_batch_embeddings(self, service):
        texts = ["Text 1", "Text 2", "Text 3"]
        embeddings = service.generate_batch_embeddings(texts)
        
        assert len(embeddings) == 3
        assert all(len(emb) == service.dimension for emb in embeddings)


================================================================================
üìÑ ARCHIVO: tests/unit/test_scraper.py
üìè Tama√±o: 0.0 KB
================================================================================




================================================================================
üìÑ ARCHIVO: tests/unit/test_validators.py
üìè Tama√±o: 1.5 KB
================================================================================

# tests/unit/test_validators.py
import pytest
from app.utils.validators import URLValidator, TextValidator

class TestURLValidator:
    def test_valid_url(self):
        is_valid, normalized, error = URLValidator.validate_and_normalize("https://example.com")
        assert is_valid is True
        assert normalized == "https://example.com"
        assert error is None
    
    def test_url_without_scheme(self):
        is_valid, normalized, error = URLValidator.validate_and_normalize("example.com")
        assert is_valid is True
        assert normalized == "https://example.com"
    
    def test_invalid_url(self):
        is_valid, _, error = URLValidator.validate_and_normalize("not a url")
        assert is_valid is False
        assert error is not None
    
    def test_local_url_detection(self):
        domain = URLValidator.extract_domain("http://localhost:8080")
        assert domain == "localhost:8080"

class TestTextValidator:
    def test_clean_text(self):
        dirty = "Text  with\tmultiple\nspaces"
        clean = TextValidator.clean_text(dirty)
        assert clean == "Text with multiple spaces"
    
    def test_truncate(self):
        long_text = "a" * 100
        truncated = TextValidator.truncate(long_text, 50)
        assert len(truncated) == 50
        assert truncated.endswith("...")
    
    def test_meaningful_text(self):
        assert TextValidator.is_meaningful_text("This is a test sentence with enough words", min_words=5)
        assert not TextValidator.is_meaningful_text("Short", min_words=5)

